{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tempfile import mkdtemp\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import r2_score,make_scorer\n",
    "from sklearn.preprocessing import StandardScaler,scale as scaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import Convolution1D, MaxPooling1D, LeakyReLU\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from collections import namedtuple\n",
    "from keras import losses\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(data, train, predict, step, binary=True, scale=False):\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(data), step):\n",
    "        try:\n",
    "            x_i = data[i:i+train]\n",
    "            y_i = data[i+train+predict]\n",
    "            \n",
    "            # Use it only for daily return time series\n",
    "            if binary:\n",
    "                if y_i > 0.:\n",
    "                    y_i = [1., 0.]\n",
    "                else:\n",
    "                    y_i = [0., 1.]\n",
    "\n",
    "                if scale: x_i = scaler(x_i)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                timeseries =np.array(data[i:i+train+predict])\n",
    "                \n",
    "                if scale: \n",
    "                    timeseries = scaler(timeseries)\n",
    "                x_i = timeseries[:-1]\n",
    "                y_i = timeseries[-1]\n",
    "            \n",
    "        except  Exception as e:\n",
    "            print (str(e))\n",
    "            break\n",
    "\n",
    "        X.append(x_i)\n",
    "        Y.append(y_i)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def train_test_split(X, y, train_percentage):\n",
    "    rows=len(X)\n",
    "    train_size=int(rows*train_percentage)\n",
    "    X_train=X[:train_size]\n",
    "    y_train=y[:train_size]\n",
    "    X_test=X[train_size:]\n",
    "    y_test=y[train_size:]\n",
    "    return X_train,y_train,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset=namedtuple('Dataset','exchange df')\n",
    "DatasetMLModel= namedtuple('DatasetMLModel','exchange  train_size tscv_split test_size X_train y_train X_test y_test scaler_features scaler_target')\n",
    "Regressor= namedtuple('Regressor','name regressor_class params type')\n",
    "FeatureSelection= namedtuple('FeatureSelection','dataset regressor params RFECV')\n",
    "TRAIN_PERCENTAGE=0.8\n",
    "TRAIN_SIZE_FEATURES = 20\n",
    "EVALUATION_PERCENT=0.2\n",
    "TARGET_TIME = 1\n",
    "LAG_SIZE = 1\n",
    "EMB_SIZE = 1\n",
    "\n",
    "\n",
    "with open('datasets/log_divided_close_datasets.pkl', 'rb') as input4:\n",
    "    log_divided_close_datasets = pickle.load(input4)\n",
    "\n",
    "\n",
    "    \n",
    "dataset=log_divided_close_datasets['btc_brl']\n",
    "data=dataset.df['log_return']\n",
    "\n",
    "rows,=data.shape\n",
    "train_size=int(rows*TRAIN_PERCENTAGE)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data[:train_size+TRAIN_SIZE_FEATURES].values.reshape(-1, 1))\n",
    "data=scaler.transform(data.values.reshape(-1, 1))\n",
    "data=data.reshape(1,-1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.281966288117148"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X,Y =split_into_chunks(data, TRAIN_SIZE_FEATURES,TARGET_TIME, LAG_SIZE, binary=False, scale=False)\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "X_train,y_train,X_test,y_test=train_test_split(X, Y, TRAIN_PERCENTAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.28196629,  6.70878824, -5.11171855, ...,  0.0928846 ,\n",
       "       -0.09352972,  0.06764178])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tscv_split=int(rows//(train_size*EVALUATION_PERCENT)-1)\n",
    "\n",
    "tscv_split=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_deep_learning():  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(TRAIN_SIZE_FEATURES,),activity_regularizer=regularizers.l2(0.01))) \n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(LeakyReLU()) \n",
    "    model.add(Dense(16,activity_regularizer=regularizers.l2(0.01))) \n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(LeakyReLU()) \n",
    "    model.add(Dense(1)) \n",
    "    model.add(Activation('linear'))\n",
    "    opt = Nadam(lr=0.001)\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='mse')\n",
    "    return model\n",
    "\n",
    "def create_model_deep_learning2(size1=64,size2=64,size3=64,activation='relu', lr=0.01,loss=losses.mse):  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(size1, input_shape=(TRAIN_SIZE_FEATURES,),activation=activation)) \n",
    "    model.add(Dense(size2,activation=activation) )\n",
    "    model.add(Dense(size3,activation=activation) )\n",
    "    model.add(Dense(1)) \n",
    "    model.add(Activation('linear'))\n",
    "    opt = Adam(lr=lr)\n",
    "    model.compile(optimizer=opt, \n",
    "              loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    score = r2_score(y_true,y_predict)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model_deep_learning2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keras_model': [<keras.wrappers.scikit_learn.KerasRegressor at 0x10c8c9dd8>],\n",
       " 'keras_model__activation': ['relu', 'sigmoid', 'tanh', 'linear'],\n",
       " 'keras_model__batch_size': [10],\n",
       " 'keras_model__epochs': [20],\n",
       " 'keras_model__loss': [<function keras.losses.logcosh>,\n",
       "  <function keras.losses.mean_squared_error>],\n",
       " 'keras_model__lr': [0.001],\n",
       " 'keras_model__size1': [64],\n",
       " 'keras_model__size2': [64],\n",
       " 'keras_model__size3': [64]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = [10,50]\n",
    "epochs = [10,20,30]\n",
    "lr=[0.01,0.1]\n",
    "size1=[64,128]\n",
    "size2=[64,128]\n",
    "size3=[64,128]\n",
    "activation=['relu', 'sigmoid','tanh','linear']\n",
    "loss=[losses.logcosh,losses.mse]\n",
    "\n",
    "param_grid = dict(keras_model=[KerasRegressor(build_fn=create_model_deep_learning2)],\n",
    "                  keras_model__batch_size=batch_size,\n",
    "                  keras_model__epochs=epochs,\n",
    "                  keras_model__lr=lr,\n",
    "                  keras_model__size1=size1,\n",
    "                  keras_model__size2=size2,\n",
    "                  keras_model__size3=size3,\n",
    "                  keras_model__activation=activation,\n",
    "                  keras_model__loss=loss\n",
    "                 )\n",
    "\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'keras_model', 'keras_model__build_fn'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cachedir = mkdtemp()\n",
    "estimators= [('keras_model',KerasRegressor(build_fn=create_model_deep_learning2))]\n",
    "params=[param_grid,]\n",
    "pipe = Pipeline(estimators, memory=cachedir)\n",
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.6115\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5212\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 243us/step - loss: 0.4811\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.4461\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 231us/step - loss: 0.4040\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.3734\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 235us/step - loss: 0.3369\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 233us/step - loss: 0.3065\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.2677\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 287us/step - loss: 0.2334\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.2185\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 242us/step - loss: 0.1962\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 229us/step - loss: 0.1830\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.1605\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.1520\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.1341\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 236us/step - loss: 0.1466\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 237us/step - loss: 0.1315\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 233us/step - loss: 0.1150\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 245us/step - loss: 0.1184\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.7034411227516388, total=   5.7s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "665/665 [==============================] - 1s 780us/step - loss: 0.4209\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 211us/step - loss: 0.3811\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 208us/step - loss: 0.3516\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 212us/step - loss: 0.3306\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 204us/step - loss: 0.3028\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 213us/step - loss: 0.2757\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 212us/step - loss: 0.2489\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 214us/step - loss: 0.2304\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 194us/step - loss: 0.2093\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 210us/step - loss: 0.1996\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 210us/step - loss: 0.1821\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 203us/step - loss: 0.1597\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 212us/step - loss: 0.1543\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 213us/step - loss: 0.1457\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.1388\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 206us/step - loss: 0.1363\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 207us/step - loss: 0.1214\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 206us/step - loss: 0.1123\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 210us/step - loss: 0.0994\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 211us/step - loss: 0.0975\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.5133397549248686, total=   4.0s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    9.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "996/996 [==============================] - 1s 558us/step - loss: 0.3286\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.3044\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 203us/step - loss: 0.2860\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.2680\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.2518\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.2309\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 183us/step - loss: 0.2196\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 225us/step - loss: 0.1988\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.1796\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.1655\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.1584\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.1420\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.1317\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.1256\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.1199\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.1114\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 203us/step - loss: 0.1085\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 227us/step - loss: 0.1089\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 202us/step - loss: 0.0929\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.0801\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.3713263509943232, total=   5.1s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   14.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 2.4613\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 214us/step - loss: 2.0483\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 221us/step - loss: 1.8250\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 219us/step - loss: 1.5880\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 220us/step - loss: 1.3962\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 227us/step - loss: 1.2359\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 232us/step - loss: 1.0505\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 221us/step - loss: 0.9342\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 217us/step - loss: 0.8164\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 227us/step - loss: 0.7332\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.6600\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 221us/step - loss: 0.5664\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 212us/step - loss: 0.5078\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 227us/step - loss: 0.4709\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 219us/step - loss: 0.4099\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 212us/step - loss: 0.3677\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 210us/step - loss: 0.3681\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 214us/step - loss: 0.3415\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 234us/step - loss: 0.2933\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 205us/step - loss: 0.2781\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.7439609079059255, total=   2.4s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   17.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "665/665 [==============================] - 1s 810us/step - loss: 1.7149\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 213us/step - loss: 1.4725\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 210us/step - loss: 1.3547\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 207us/step - loss: 1.1848\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 207us/step - loss: 1.0336\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 214us/step - loss: 0.8963\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 210us/step - loss: 0.7801\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.6688\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 243us/step - loss: 0.5953\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 207us/step - loss: 0.5243\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4846\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4325\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.3856\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 209us/step - loss: 0.3472\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 210us/step - loss: 0.3251\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 204us/step - loss: 0.3503\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 204us/step - loss: 0.3294\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.2885\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.2743\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 213us/step - loss: 0.2756\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.4351075508936755, total=   3.9s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   21.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "996/996 [==============================] - 1s 638us/step - loss: 1.2226\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 207us/step - loss: 1.0359\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.9136\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.8057\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 202us/step - loss: 0.7326\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.6633\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.5963\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 203us/step - loss: 0.5273\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.4743\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 204us/step - loss: 0.4632\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.4315\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 202us/step - loss: 0.4261\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 201us/step - loss: 0.3846\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3339\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.2969\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.2826\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 202us/step - loss: 0.2991\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 201us/step - loss: 0.3040\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.2789\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 201us/step - loss: 0.2330\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=relu, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.2706905069338106, total=   5.1s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5658\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 240us/step - loss: 0.5720\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5650\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5602\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 233us/step - loss: 0.5616\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 235us/step - loss: 0.5622\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 239us/step - loss: 0.5669\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 232us/step - loss: 0.5559\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 240us/step - loss: 0.5583\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5533\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 235us/step - loss: 0.5534\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 235us/step - loss: 0.5465\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 227us/step - loss: 0.5477\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 241us/step - loss: 0.5452\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 230us/step - loss: 0.5412\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 233us/step - loss: 0.5409\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 230us/step - loss: 0.5448\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 241us/step - loss: 0.5394\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 242us/step - loss: 0.5413\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5373\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0542219967387092, total=   2.9s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 1s 1ms/step - loss: 0.4315\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4079\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4088\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4114\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4078\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4062\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4024\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 215us/step - loss: 0.4010\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4001\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4037\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4012\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3960\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3975\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.3972\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 234us/step - loss: 0.3967\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3965\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.3979\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.3965\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 234us/step - loss: 0.3944\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3944\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.024537502313087378, total=   4.2s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 1s 785us/step - loss: 0.3246\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 228us/step - loss: 0.3198\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3202\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 223us/step - loss: 0.3191\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3191\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3187\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3151\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3161\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3158\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 233us/step - loss: 0.3132\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3153\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 225us/step - loss: 0.3135\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 229us/step - loss: 0.3122\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 231us/step - loss: 0.3166\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3124\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3110\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3110\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 223us/step - loss: 0.3113\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 228us/step - loss: 0.3111\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 227us/step - loss: 0.3114\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.02118059649625348, total=   5.8s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2.4324\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 250us/step - loss: 2.4145\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 243us/step - loss: 2.4219\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 246us/step - loss: 2.4151\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 257us/step - loss: 2.3975\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 246us/step - loss: 2.3720\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 2.3682\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 247us/step - loss: 2.3081\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 245us/step - loss: 2.3332\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 245us/step - loss: 2.2706\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 241us/step - loss: 2.2106\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 234us/step - loss: 2.1919\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 230us/step - loss: 2.1561\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 221us/step - loss: 2.1410\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 242us/step - loss: 2.1691\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 243us/step - loss: 2.1430\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 231us/step - loss: 2.1286\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 231us/step - loss: 2.1038\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 242us/step - loss: 2.0842\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 237us/step - loss: 2.0451\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.23414797961945655, total=   2.8s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 1s 1ms/step - loss: 1.6151\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 237us/step - loss: 1.6051\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 231us/step - loss: 1.5991\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 223us/step - loss: 1.5801\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 233us/step - loss: 1.5595\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 223us/step - loss: 1.5572\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 240us/step - loss: 1.5866\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 222us/step - loss: 1.5406\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 215us/step - loss: 1.5227\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 227us/step - loss: 1.5328\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 224us/step - loss: 1.4987\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 221us/step - loss: 1.5025\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 223us/step - loss: 1.4799\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 230us/step - loss: 1.4873\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 228us/step - loss: 1.4866\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 229us/step - loss: 1.4903\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 218us/step - loss: 1.4619\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 217us/step - loss: 1.4719\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 223us/step - loss: 1.4721\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 225us/step - loss: 1.4477\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.06368244531384737, total=   4.3s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 1s 855us/step - loss: 1.2127\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 228us/step - loss: 1.1930\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 236us/step - loss: 1.1882\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 222us/step - loss: 1.1812\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 238us/step - loss: 1.1811\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 223us/step - loss: 1.1762\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 217us/step - loss: 1.1590\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 225us/step - loss: 1.1455\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 226us/step - loss: 1.1348\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 227us/step - loss: 1.1334\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 222us/step - loss: 1.1265\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 229us/step - loss: 1.1233\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 222us/step - loss: 1.1156\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 223us/step - loss: 1.1162\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 231us/step - loss: 1.1145\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 227us/step - loss: 1.1114\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 220us/step - loss: 1.1099\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 221us/step - loss: 1.1013\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 227us/step - loss: 1.0855\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 224us/step - loss: 1.0825\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=sigmoid, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.10235178469878936, total=   5.9s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.6215\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5547\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5407\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5261\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5228\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.4947\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.4771\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.4559\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.4418\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.4104\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.3863\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.3680\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.3396\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.3272\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.2936\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.2841\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.2707\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.2357\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.2239\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.2207\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.4418472929803323, total=   3.2s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 1s 1ms/step - loss: 0.4440\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 238us/step - loss: 0.4088\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3991\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.346 - 0s 226us/step - loss: 0.3875\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 244us/step - loss: 0.3816\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 242us/step - loss: 0.3620\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 244us/step - loss: 0.3587\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 243us/step - loss: 0.3422\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.3286\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 237us/step - loss: 0.3106\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 243us/step - loss: 0.3036\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 249us/step - loss: 0.2827\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 242us/step - loss: 0.2768\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 238us/step - loss: 0.2603\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.2334\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.2223\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 238us/step - loss: 0.2209\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.2066\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 248us/step - loss: 0.1883\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.1810\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.4565376068105256, total=   4.6s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 1s 1ms/step - loss: 0.3387\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 244us/step - loss: 0.3176\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 238us/step - loss: 0.3116\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 242us/step - loss: 0.3109\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 235us/step - loss: 0.2960\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 231us/step - loss: 0.2872\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 234us/step - loss: 0.2776\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 234us/step - loss: 0.2703\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 229us/step - loss: 0.2589\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 245us/step - loss: 0.2505\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 238us/step - loss: 0.2392\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 234us/step - loss: 0.2281\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 248us/step - loss: 0.2209\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 240us/step - loss: 0.2033\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 248us/step - loss: 0.1926\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 231us/step - loss: 0.1933\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 241us/step - loss: 0.1824\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 243us/step - loss: 0.1628\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 231us/step - loss: 0.1571\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 241us/step - loss: 0.1457\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.34013241984348364, total=   6.5s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 2.5723\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 264us/step - loss: 2.2629\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 255us/step - loss: 2.1255\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 264us/step - loss: 2.0037\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 274us/step - loss: 1.8896\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 281us/step - loss: 1.7439\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 258us/step - loss: 1.6473\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 235us/step - loss: 1.4838\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 262us/step - loss: 1.4022\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 254us/step - loss: 1.1882\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 309us/step - loss: 1.0623\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.9867\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.8607\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 267us/step - loss: 0.7761\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 312us/step - loss: 0.6811\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.6448\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 289us/step - loss: 0.5640\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 275us/step - loss: 0.4782\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 273us/step - loss: 0.4456\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 313us/step - loss: 0.4091\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.5169799760845224, total=   3.4s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.7366\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 277us/step - loss: 1.5328\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 294us/step - loss: 1.4669\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 280us/step - loss: 1.3932\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 280us/step - loss: 1.3242\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 289us/step - loss: 1.2508\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 264us/step - loss: 1.1539\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 282us/step - loss: 1.0474\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 267us/step - loss: 1.0045\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 284us/step - loss: 0.8911\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 291us/step - loss: 0.8188\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 274us/step - loss: 0.7630\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 291us/step - loss: 0.7147\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 275us/step - loss: 0.6367\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 271us/step - loss: 0.6011\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 266us/step - loss: 0.5571\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 266us/step - loss: 0.5373\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 285us/step - loss: 0.4979\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 300us/step - loss: 0.4903\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 259us/step - loss: 0.4365\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.5070271755066338, total=   5.5s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 1s 1ms/step - loss: 1.2554\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 282us/step - loss: 1.1492\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 303us/step - loss: 1.0988\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 274us/step - loss: 1.0300\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 253us/step - loss: 0.9439\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 274us/step - loss: 0.9003\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 271us/step - loss: 0.8271\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 271us/step - loss: 0.7744\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 267us/step - loss: 0.6709\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 272us/step - loss: 0.6470\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 288us/step - loss: 0.6026\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 273us/step - loss: 0.5326\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 270us/step - loss: 0.5363\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 265us/step - loss: 0.4977\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 261us/step - loss: 0.4682\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 281us/step - loss: 0.4197\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 278us/step - loss: 0.4066\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 282us/step - loss: 0.3871\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 273us/step - loss: 0.3871\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 262us/step - loss: 0.3406\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=tanh, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.1388784159546388, total=   7.2s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.6999\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 344us/step - loss: 0.6183\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 321us/step - loss: 0.6243\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 306us/step - loss: 0.6278\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 310us/step - loss: 0.6043\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 363us/step - loss: 0.6140\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 313us/step - loss: 0.6022\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 368us/step - loss: 0.5832\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 307us/step - loss: 0.6034\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 346us/step - loss: 0.5938\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 335us/step - loss: 0.5918\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 320us/step - loss: 0.5793\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 331us/step - loss: 0.5735\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 289us/step - loss: 0.5864\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 296us/step - loss: 0.5796\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 279us/step - loss: 0.5760\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 285us/step - loss: 0.5781\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 273us/step - loss: 0.5864\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 269us/step - loss: 0.5735\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 291us/step - loss: 0.5652\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.07234779667714641, total=   4.0s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4896\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 298us/step - loss: 0.4491\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 291us/step - loss: 0.4471\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 301us/step - loss: 0.4263\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 311us/step - loss: 0.4307\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 298us/step - loss: 0.4380\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 304us/step - loss: 0.4255\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 294us/step - loss: 0.4283\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 325us/step - loss: 0.4198\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 300us/step - loss: 0.4219\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 299us/step - loss: 0.4255\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 294us/step - loss: 0.4164\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 291us/step - loss: 0.4177\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 295us/step - loss: 0.4175\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 284us/step - loss: 0.4161\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 292us/step - loss: 0.4126\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 302us/step - loss: 0.4107\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 298us/step - loss: 0.4126\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 311us/step - loss: 0.4115\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 286us/step - loss: 0.4108\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.0056123405355412714, total=   6.2s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 1s 1ms/step - loss: 0.3660\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 289us/step - loss: 0.3459\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 274us/step - loss: 0.3369\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 250us/step - loss: 0.3365\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 277us/step - loss: 0.3351\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 276us/step - loss: 0.3272\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 280us/step - loss: 0.3295\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 284us/step - loss: 0.3266\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 273us/step - loss: 0.3293\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 275us/step - loss: 0.3252\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 293us/step - loss: 0.3258\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 334us/step - loss: 0.3261\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 332us/step - loss: 0.3226\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 338us/step - loss: 0.3237\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 320us/step - loss: 0.3223\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 290us/step - loss: 0.3205\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 294us/step - loss: 0.3203\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 283us/step - loss: 0.3203\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 280us/step - loss: 0.3215\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 282us/step - loss: 0.3199\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x10c799048>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.004497865079363894, total=   7.9s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 3.4878\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 282us/step - loss: 2.5366\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 313us/step - loss: 2.5835\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 304us/step - loss: 2.6904\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 296us/step - loss: 2.4470\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 295us/step - loss: 2.4795\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 276us/step - loss: 2.3865\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 300us/step - loss: 2.7685\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 312us/step - loss: 2.4827\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 299us/step - loss: 2.6063\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 293us/step - loss: 2.3944\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 301us/step - loss: 2.3512\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 290us/step - loss: 2.3900\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 305us/step - loss: 2.3737\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 283us/step - loss: 2.3206\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 299us/step - loss: 2.3213\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 294us/step - loss: 2.3213\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 296us/step - loss: 2.3298\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 318us/step - loss: 2.3054\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 317us/step - loss: 2.3372\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.1665340553774537, total=   4.0s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 2.0974\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 303us/step - loss: 1.8918\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 286us/step - loss: 1.7667\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 295us/step - loss: 1.7070\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 310us/step - loss: 1.7181\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 298us/step - loss: 1.7053\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 325us/step - loss: 1.6569\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 331us/step - loss: 1.6615\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 304us/step - loss: 1.6690\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 335us/step - loss: 1.6028\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 309us/step - loss: 1.6410\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 302us/step - loss: 1.6052\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 305us/step - loss: 1.6251\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 324us/step - loss: 1.6050\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 317us/step - loss: 1.6167\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 284us/step - loss: 1.6336\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 302us/step - loss: 1.5790\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 300us/step - loss: 1.5615\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 308us/step - loss: 1.5645\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 288us/step - loss: 1.5566\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.012318621247757289, total=   6.3s\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 1s 1ms/step - loss: 1.4929\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 280us/step - loss: 1.3752\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 278us/step - loss: 1.2900\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 283us/step - loss: 1.2602\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 276us/step - loss: 1.2599\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 286us/step - loss: 1.2305\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 281us/step - loss: 1.2336\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 277us/step - loss: 1.2098\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 284us/step - loss: 1.1911\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 288us/step - loss: 1.2043\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 281us/step - loss: 1.2099\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 290us/step - loss: 1.1836\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 281us/step - loss: 1.2044\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 291us/step - loss: 1.1827\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 286us/step - loss: 1.1877\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 283us/step - loss: 1.1866\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 295us/step - loss: 1.1879\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 285us/step - loss: 1.1855\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 291us/step - loss: 1.1751\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 294us/step - loss: 1.1763\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x10c8c9dd8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function mean_squared_error at 0x10c79cbf8>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.04263853577785648, total=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1327/1327 [==============================] - 2s 1ms/step - loss: 0.3453\n",
      "Epoch 2/20\n",
      "1327/1327 [==============================] - 0s 292us/step - loss: 0.3119\n",
      "Epoch 3/20\n",
      "1327/1327 [==============================] - 0s 288us/step - loss: 0.3024\n",
      "Epoch 4/20\n",
      "1327/1327 [==============================] - 0s 292us/step - loss: 0.2942\n",
      "Epoch 5/20\n",
      "1327/1327 [==============================] - 0s 287us/step - loss: 0.2929\n",
      "Epoch 6/20\n",
      "1327/1327 [==============================] - 0s 286us/step - loss: 0.2877\n",
      "Epoch 7/20\n",
      "1327/1327 [==============================] - 0s 287us/step - loss: 0.2914\n",
      "Epoch 8/20\n",
      "1327/1327 [==============================] - 0s 290us/step - loss: 0.2854\n",
      "Epoch 9/20\n",
      "1327/1327 [==============================] - 0s 292us/step - loss: 0.2836\n",
      "Epoch 10/20\n",
      "1327/1327 [==============================] - 0s 290us/step - loss: 0.2840\n",
      "Epoch 11/20\n",
      "1327/1327 [==============================] - 0s 276us/step - loss: 0.2807\n",
      "Epoch 12/20\n",
      "1327/1327 [==============================] - 0s 258us/step - loss: 0.2857\n",
      "Epoch 13/20\n",
      "1327/1327 [==============================] - 0s 261us/step - loss: 0.2835\n",
      "Epoch 14/20\n",
      "1327/1327 [==============================] - 0s 290us/step - loss: 0.2834\n",
      "Epoch 15/20\n",
      "1327/1327 [==============================] - 0s 293us/step - loss: 0.2776\n",
      "Epoch 16/20\n",
      "1327/1327 [==============================] - 0s 290us/step - loss: 0.2796\n",
      "Epoch 17/20\n",
      "1327/1327 [==============================] - 0s 288us/step - loss: 0.2795\n",
      "Epoch 18/20\n",
      "1327/1327 [==============================] - 0s 301us/step - loss: 0.2800\n",
      "Epoch 19/20\n",
      "1327/1327 [==============================] - 0s 295us/step - loss: 0.2794\n",
      "Epoch 20/20\n",
      "1327/1327 [==============================] - 0s 289us/step - loss: 0.2794\n"
     ]
    }
   ],
   "source": [
    "scoring_fnc = make_scorer(performance_metric)\n",
    "cvts=TimeSeriesSplit(n_splits=tscv_split)\n",
    "grid = GridSearchCV(estimator=pipe, \n",
    "                    param_grid=params,\n",
    "                    scoring=scoring_fnc,\n",
    "                    cv=cvts,\n",
    "                    error_score=np.NaN,\n",
    "                    verbose=6,\n",
    "                    n_jobs=1\n",
    "                   )  \n",
    "grid = grid.fit(X_train,y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Regressor','Score','BestEstimator']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=[]\n",
    "data_row=['MLP',\n",
    "                grid.best_score_,\n",
    "                grid.best_estimator_\n",
    "                ]\n",
    "data_list.append(data_row)\n",
    "score=pd.DataFrame(data_list,columns=columns)\n",
    "score.set_index(['Regressor'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>BestEstimator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regressor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>-0.023744</td>\n",
       "      <td>Pipeline(memory='/var/folders/ch/53dqzxsx15b3c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Score                                      BestEstimator\n",
       "Regressor                                                             \n",
       "MLP       -0.023744  Pipeline(memory='/var/folders/ch/53dqzxsx15b3c..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keras_model': <keras.wrappers.scikit_learn.KerasRegressor at 0x10c8c9dd8>,\n",
       " 'keras_model__activation': 'linear',\n",
       " 'keras_model__batch_size': 10,\n",
       " 'keras_model__epochs': 20,\n",
       " 'keras_model__loss': <function keras.losses.logcosh>,\n",
       " 'keras_model__lr': 0.001,\n",
       " 'keras_model__size1': 64,\n",
       " 'keras_model__size2': 64,\n",
       " 'keras_model__size3': 64}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 76s 228ms/step - loss: 1.0166\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6482\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5923\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5741\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5874\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5793\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5639\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5761\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5778\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5748\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.09333720028308656, total= 2.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "665/665 [==============================] - 70s 106ms/step - loss: 0.6679\n",
      "Epoch 2/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4322\n",
      "Epoch 3/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4261\n",
      "Epoch 4/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4203\n",
      "Epoch 5/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4202\n",
      "Epoch 6/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4118\n",
      "Epoch 7/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4249\n",
      "Epoch 8/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4265\n",
      "Epoch 9/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4142\n",
      "Epoch 10/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4146\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.045401505121094754, total= 2.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "996/996 [==============================] - 76s 77ms/step - loss: 0.4706\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3375\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3391\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3334\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3330\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3316\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3294\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3276\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3210\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3335\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.02124937275262262, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "334/334 [==============================] - 83s 247ms/step - loss: 75.4158\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 14.8038\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.0396\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.5976\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7612\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6671\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6674\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5947\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5992\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6062\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.16702011568871966, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "665/665 [==============================] - 78s 118ms/step - loss: 11.6818\n",
      "Epoch 2/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.4840\n",
      "Epoch 3/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6984\n",
      "Epoch 4/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5020\n",
      "Epoch 5/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6205\n",
      "Epoch 6/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7083\n",
      "Epoch 7/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5800\n",
      "Epoch 8/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.8565\n",
      "Epoch 9/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6016\n",
      "Epoch 10/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7786\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.4153698886202162, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 90/996 [=>............................] - ETA: 1:02:21 - loss: 36.3522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasrodriguezcelys/anaconda3/envs/pyfinance/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.920604). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 374s 375ms/step - loss: 13.3740\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6943\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3535\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3468\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3381\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3861\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3465\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3434\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3502\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3620\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.40446234352640276, total=24.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 115s 346ms/step - loss: 0.7466\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6251\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6043\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6117\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5850\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6237\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5908\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5690\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5781\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5892\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.059681637952410105, total= 3.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "665/665 [==============================] - 85s 128ms/step - loss: 0.4914\n",
      "Epoch 2/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4540\n",
      "Epoch 3/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4323\n",
      "Epoch 4/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4416\n",
      "Epoch 5/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4324\n",
      "Epoch 6/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4271\n",
      "Epoch 7/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4285\n",
      "Epoch 8/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4159\n",
      "Epoch 9/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4237\n",
      "Epoch 10/10\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4240\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.00593526632724839, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "996/996 [==============================] - 95s 95ms/step - loss: 0.3787\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3411\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3511\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3506\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3368\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3356\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3283\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3257\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3244\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3267\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.007526485357656654, total= 3.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 80s 240ms/step - loss: 1.1798\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6764\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6356\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5859\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5695\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5773\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5694\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5729\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5613\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5672\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5698\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5680\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5783\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5650\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5702\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5697\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5600\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5567\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5706\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5952\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.07136570822388477, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "665/665 [==============================] - 84s 126ms/step - loss: 0.6904\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4434\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4122\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4165\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4246\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4269\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4227\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4188\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4188\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4159\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4142\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4161\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4181\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4111\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4193\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4150\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4140\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4123\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4117\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4113\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.05525505354179283, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 77s 77ms/step - loss: 0.4855\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3378\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3375\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3300\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3314\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3249\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3261\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3244\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3342\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3318\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3302\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3324\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3288\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3267\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3230\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3221\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3238\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3268\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3318\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3233\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.03433644362213695, total= 2.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 75s 225ms/step - loss: 38.2819\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 11.7330\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2.9958\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2.1036\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9998\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7007\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6058\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5901\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5922\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5752\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5693\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5707\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5971\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5940\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6258\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5971\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5938\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6104\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6192\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5853\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.04664639152332373, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 80s 120ms/step - loss: 19.0929\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.2656\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5111\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5013\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5081\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4717\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4608\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4404\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4553\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4354\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4426\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4637\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5792\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 2.3228\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 9752.6091\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1643.9563\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 231.2779\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 57.9239\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 11.9208\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 7.4154\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-79.88289621369222, total= 2.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 98s 99ms/step - loss: 12.3242\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7506\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3508\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3508\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3504\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3484\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3494\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3721\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3925\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3896\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3432\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4051\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7383\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 6943.3702\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 536.6739\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 41.2883\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 9.7161\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 7.2173\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 3.2289\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 2.9826\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-7.698304815731806, total= 3.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 81s 242ms/step - loss: 0.6585\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6285\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6046\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5942\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5926\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5914\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6076\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5882\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5834\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6005\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5965\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5746\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5664\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5645\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5692\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5710\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5787\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5713\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5799\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5707\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.030960490838047416, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 75s 112ms/step - loss: 0.4896\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4574\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4377\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4340\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4336\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4255\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4227\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4231\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4309\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4193\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4210\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4151\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4180\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4175\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4108\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4116\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4105\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4127\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4130\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4106\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.005947082084436284, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 77s 77ms/step - loss: 0.3699\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3424\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3413\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3346\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3392\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3358\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3338\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3281\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3273\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3258\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3245\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3248\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3215\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3236\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3192\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3216\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3240\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3204\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3209\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3196\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0013472651724655282, total= 2.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "334/334 [==============================] - 77s 230ms/step - loss: 1.0412\n",
      "Epoch 2/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6544\n",
      "Epoch 3/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5904\n",
      "Epoch 4/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6004\n",
      "Epoch 5/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5764\n",
      "Epoch 6/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5753\n",
      "Epoch 7/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5942\n",
      "Epoch 8/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5700\n",
      "Epoch 9/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5565\n",
      "Epoch 10/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5752\n",
      "Epoch 11/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5810\n",
      "Epoch 12/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5754\n",
      "Epoch 13/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5869\n",
      "Epoch 14/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5977\n",
      "Epoch 15/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5691\n",
      "Epoch 16/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5883\n",
      "Epoch 17/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5644\n",
      "Epoch 18/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5596\n",
      "Epoch 19/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5683\n",
      "Epoch 20/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5665\n",
      "Epoch 21/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5641\n",
      "Epoch 22/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5669\n",
      "Epoch 23/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5664\n",
      "Epoch 24/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5688\n",
      "Epoch 25/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5644\n",
      "Epoch 26/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5592\n",
      "Epoch 27/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5584\n",
      "Epoch 28/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5606\n",
      "Epoch 29/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5606\n",
      "Epoch 30/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5541\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.08853572195767434, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "665/665 [==============================] - 76s 115ms/step - loss: 0.6690\n",
      "Epoch 2/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4362\n",
      "Epoch 3/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4354\n",
      "Epoch 4/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4182\n",
      "Epoch 5/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4241\n",
      "Epoch 6/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4147\n",
      "Epoch 7/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4183\n",
      "Epoch 8/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4201\n",
      "Epoch 9/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4216\n",
      "Epoch 10/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4330\n",
      "Epoch 11/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4330\n",
      "Epoch 12/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4161\n",
      "Epoch 13/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4127\n",
      "Epoch 14/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4143\n",
      "Epoch 15/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4139\n",
      "Epoch 16/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4144\n",
      "Epoch 17/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4121\n",
      "Epoch 18/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4134\n",
      "Epoch 19/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4114\n",
      "Epoch 20/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4097\n",
      "Epoch 21/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4106\n",
      "Epoch 22/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4134\n",
      "Epoch 23/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4154\n",
      "Epoch 24/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4196\n",
      "Epoch 25/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4091\n",
      "Epoch 26/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4182\n",
      "Epoch 27/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4175\n",
      "Epoch 28/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4137\n",
      "Epoch 29/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4091\n",
      "Epoch 30/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4097\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0292278607801133, total= 2.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "996/996 [==============================] - 80s 80ms/step - loss: 0.4928\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3414\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3332\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3305\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3318\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3256\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3342\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3289\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3286\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3256\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3255\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3288\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3254\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3257\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3271\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3205\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3254\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3228\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3238\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3288\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3278\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3283\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3273\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3301\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3398\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3316\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3327\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3345\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3343\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3236\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.000274181860181022, total= 3.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "334/334 [==============================] - 75s 225ms/step - loss: 34.1815\n",
      "Epoch 2/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 14.5898\n",
      "Epoch 3/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.9933\n",
      "Epoch 4/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.8960\n",
      "Epoch 5/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.4693\n",
      "Epoch 6/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7010\n",
      "Epoch 7/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6340\n",
      "Epoch 8/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6546\n",
      "Epoch 9/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6321\n",
      "Epoch 10/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6215\n",
      "Epoch 11/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6100\n",
      "Epoch 12/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6224\n",
      "Epoch 13/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6229\n",
      "Epoch 14/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6152\n",
      "Epoch 15/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5803\n",
      "Epoch 16/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5856\n",
      "Epoch 17/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5689\n",
      "Epoch 18/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6383\n",
      "Epoch 19/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5891\n",
      "Epoch 20/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5872\n",
      "Epoch 21/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5881\n",
      "Epoch 22/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5780\n",
      "Epoch 23/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5789\n",
      "Epoch 24/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5660\n",
      "Epoch 25/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5584\n",
      "Epoch 26/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5776\n",
      "Epoch 27/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6023\n",
      "Epoch 28/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6264\n",
      "Epoch 29/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6060\n",
      "Epoch 30/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5735\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.24188057296169885, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "665/665 [==============================] - 71s 106ms/step - loss: 22.5657\n",
      "Epoch 2/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 8.9155\n",
      "Epoch 3/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.0044\n",
      "Epoch 4/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6329\n",
      "Epoch 5/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4722\n",
      "Epoch 6/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4286\n",
      "Epoch 7/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4350\n",
      "Epoch 8/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4373\n",
      "Epoch 9/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4273\n",
      "Epoch 10/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4262\n",
      "Epoch 11/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4239\n",
      "Epoch 12/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4257\n",
      "Epoch 13/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4181\n",
      "Epoch 14/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4317\n",
      "Epoch 15/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4255\n",
      "Epoch 16/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4340\n",
      "Epoch 17/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4298\n",
      "Epoch 18/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4340\n",
      "Epoch 19/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4402\n",
      "Epoch 20/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4393\n",
      "Epoch 21/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4313\n",
      "Epoch 22/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4278\n",
      "Epoch 23/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4230\n",
      "Epoch 24/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4149\n",
      "Epoch 25/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4277\n",
      "Epoch 26/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4303\n",
      "Epoch 27/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4215\n",
      "Epoch 28/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4191\n",
      "Epoch 29/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4458\n",
      "Epoch 30/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4251\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.10250008325704152, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 78s 79ms/step - loss: 13.2523\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4511\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3585\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3527\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3566\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3458\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3471\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3361\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3445\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3469\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3521\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3547\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3539\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3384\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3319\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3379\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3321\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3461\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4762\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 6946.4424\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1211.0287\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 74.1393\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 19.4129\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 11.6929\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 5.5515\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 3.2706\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.7509\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.4346\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.1222\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.0045\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-3.1884628334229648, total= 3.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "334/334 [==============================] - 74s 222ms/step - loss: 0.7117\n",
      "Epoch 2/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6251\n",
      "Epoch 3/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6129\n",
      "Epoch 4/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6018\n",
      "Epoch 5/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5981\n",
      "Epoch 6/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5919\n",
      "Epoch 7/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5965\n",
      "Epoch 8/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5758\n",
      "Epoch 9/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5833\n",
      "Epoch 10/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5761\n",
      "Epoch 11/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5850\n",
      "Epoch 12/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5726\n",
      "Epoch 13/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5762\n",
      "Epoch 14/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5832\n",
      "Epoch 15/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5707\n",
      "Epoch 16/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5655\n",
      "Epoch 17/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5639\n",
      "Epoch 18/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5711\n",
      "Epoch 19/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5785\n",
      "Epoch 20/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5675\n",
      "Epoch 21/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5629\n",
      "Epoch 22/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5559\n",
      "Epoch 23/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5548\n",
      "Epoch 24/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5641\n",
      "Epoch 25/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5595\n",
      "Epoch 26/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5624\n",
      "Epoch 27/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5575\n",
      "Epoch 28/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5619\n",
      "Epoch 29/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5629\n",
      "Epoch 30/30\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5601\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.04413321619470301, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "665/665 [==============================] - 74s 111ms/step - loss: 0.4985\n",
      "Epoch 2/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4455\n",
      "Epoch 3/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4451\n",
      "Epoch 4/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4318\n",
      "Epoch 5/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4360\n",
      "Epoch 6/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4314\n",
      "Epoch 7/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4296\n",
      "Epoch 8/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4290\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4225\n",
      "Epoch 10/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4178\n",
      "Epoch 11/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4182\n",
      "Epoch 12/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4161\n",
      "Epoch 13/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4189\n",
      "Epoch 14/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4129\n",
      "Epoch 15/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4146\n",
      "Epoch 16/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4178\n",
      "Epoch 17/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4146\n",
      "Epoch 18/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4119\n",
      "Epoch 19/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4119\n",
      "Epoch 20/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4111\n",
      "Epoch 21/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4117\n",
      "Epoch 22/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4101\n",
      "Epoch 23/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4101\n",
      "Epoch 24/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4087\n",
      "Epoch 25/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4096\n",
      "Epoch 26/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4099\n",
      "Epoch 27/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4063\n",
      "Epoch 28/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4101\n",
      "Epoch 29/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4063\n",
      "Epoch 30/30\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4072\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.009813302097654741, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 73s 73ms/step - loss: 0.3861\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3476\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3424\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3355\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3366\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3313\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3291\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3277\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3316\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3246\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3233\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3267\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3205\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3270\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3218\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3199\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3210\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3185\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3225\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3193\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3187\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3204\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3181\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3181\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3187\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3191\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3180\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3178\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3192\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3168\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.005540703547788461, total= 3.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "334/334 [==============================] - 72s 216ms/step - loss: 1.0421\n",
      "Epoch 2/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6400\n",
      "Epoch 3/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5958\n",
      "Epoch 4/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5889\n",
      "Epoch 5/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5928\n",
      "Epoch 6/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5738\n",
      "Epoch 7/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5730\n",
      "Epoch 8/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5779\n",
      "Epoch 9/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5674\n",
      "Epoch 10/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5793\n",
      "Epoch 11/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5555\n",
      "Epoch 12/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5615\n",
      "Epoch 13/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5608\n",
      "Epoch 14/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5729\n",
      "Epoch 15/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5626\n",
      "Epoch 16/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5608\n",
      "Epoch 17/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5792\n",
      "Epoch 18/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6008\n",
      "Epoch 19/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5800\n",
      "Epoch 20/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5741\n",
      "Epoch 21/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5789\n",
      "Epoch 22/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5705\n",
      "Epoch 23/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5731\n",
      "Epoch 24/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5557\n",
      "Epoch 25/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5537\n",
      "Epoch 26/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5530\n",
      "Epoch 27/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5678\n",
      "Epoch 28/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5590\n",
      "Epoch 29/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5630\n",
      "Epoch 30/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5632\n",
      "Epoch 31/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5640\n",
      "Epoch 32/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5583\n",
      "Epoch 33/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5605\n",
      "Epoch 34/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5669\n",
      "Epoch 35/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5640\n",
      "Epoch 36/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5558\n",
      "Epoch 37/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5541\n",
      "Epoch 38/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5449\n",
      "Epoch 39/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5963\n",
      "Epoch 40/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5693\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.026016821122628153, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "665/665 [==============================] - 75s 113ms/step - loss: 0.6748\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4614\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4231\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4244\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4139\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4254\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4434\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4346\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4200\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4197\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4156\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4187\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4148\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4117\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4114\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4119\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4058\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4201\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4139\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4089\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4098\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4080\n",
      "Epoch 23/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4120\n",
      "Epoch 24/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4098\n",
      "Epoch 25/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4076\n",
      "Epoch 26/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4091\n",
      "Epoch 27/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4079\n",
      "Epoch 28/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4219\n",
      "Epoch 29/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4302\n",
      "Epoch 30/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4228\n",
      "Epoch 31/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4192\n",
      "Epoch 32/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4144\n",
      "Epoch 33/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4157\n",
      "Epoch 34/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4143\n",
      "Epoch 35/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4164\n",
      "Epoch 36/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4103\n",
      "Epoch 37/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4199\n",
      "Epoch 38/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4185\n",
      "Epoch 39/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4126\n",
      "Epoch 40/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4162\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.00956479897996787, total= 3.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "996/996 [==============================] - 84s 85ms/step - loss: 0.5459\n",
      "Epoch 2/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3348\n",
      "Epoch 3/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3257\n",
      "Epoch 4/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3321\n",
      "Epoch 5/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3308\n",
      "Epoch 6/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3289\n",
      "Epoch 7/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3316\n",
      "Epoch 8/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3310\n",
      "Epoch 9/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3224\n",
      "Epoch 10/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3255\n",
      "Epoch 11/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3240\n",
      "Epoch 12/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3251\n",
      "Epoch 13/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3313\n",
      "Epoch 14/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3232\n",
      "Epoch 15/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3267\n",
      "Epoch 16/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3245\n",
      "Epoch 17/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3184\n",
      "Epoch 18/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3326\n",
      "Epoch 19/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3277\n",
      "Epoch 20/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3273\n",
      "Epoch 21/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3252\n",
      "Epoch 22/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3277\n",
      "Epoch 23/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3284\n",
      "Epoch 24/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3241\n",
      "Epoch 25/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3209\n",
      "Epoch 26/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3315\n",
      "Epoch 27/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3504\n",
      "Epoch 28/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3663\n",
      "Epoch 29/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3350\n",
      "Epoch 30/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3264\n",
      "Epoch 31/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3293\n",
      "Epoch 32/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3417\n",
      "Epoch 33/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3324\n",
      "Epoch 34/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3299\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3283\n",
      "Epoch 36/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3226\n",
      "Epoch 37/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3224\n",
      "Epoch 38/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3203\n",
      "Epoch 39/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3243\n",
      "Epoch 40/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3581\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.4306701676399509, total= 3.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "334/334 [==============================] - 79s 236ms/step - loss: 42.6803\n",
      "Epoch 2/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.6454\n",
      "Epoch 3/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 3.5197\n",
      "Epoch 4/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8264\n",
      "Epoch 5/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7123\n",
      "Epoch 6/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6270\n",
      "Epoch 7/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6794\n",
      "Epoch 8/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6260\n",
      "Epoch 9/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6232\n",
      "Epoch 10/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5960\n",
      "Epoch 11/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6080\n",
      "Epoch 12/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5998\n",
      "Epoch 13/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5833\n",
      "Epoch 14/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5900\n",
      "Epoch 15/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6040\n",
      "Epoch 16/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5889\n",
      "Epoch 17/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5768\n",
      "Epoch 18/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5903\n",
      "Epoch 19/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5646\n",
      "Epoch 20/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5726\n",
      "Epoch 21/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5922\n",
      "Epoch 22/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5760\n",
      "Epoch 23/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5712\n",
      "Epoch 24/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6487\n",
      "Epoch 25/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6115\n",
      "Epoch 26/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5899\n",
      "Epoch 27/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6114\n",
      "Epoch 28/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6081\n",
      "Epoch 29/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6218\n",
      "Epoch 30/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6224\n",
      "Epoch 31/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6037\n",
      "Epoch 32/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6136\n",
      "Epoch 33/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6235\n",
      "Epoch 34/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6367\n",
      "Epoch 35/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6095\n",
      "Epoch 36/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6422\n",
      "Epoch 37/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6317\n",
      "Epoch 38/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6862\n",
      "Epoch 39/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6698\n",
      "Epoch 40/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6170\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.012966902137850012, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "665/665 [==============================] - 80s 121ms/step - loss: 17.4440\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 2.1419\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5207\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4702\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4385\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4463\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4634\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4427\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4410\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4454\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4638\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4824\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4404\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4390\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5551\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5195\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7799\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 4247.5831\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 4405.2656\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 492.0454\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 66.8520\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 17.5256\n",
      "Epoch 23/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 12.0066\n",
      "Epoch 24/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 4.6816\n",
      "Epoch 25/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 4.7619\n",
      "Epoch 26/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 3.0058\n",
      "Epoch 27/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.9454\n",
      "Epoch 28/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.7694\n",
      "Epoch 29/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.3831\n",
      "Epoch 30/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.4828\n",
      "Epoch 31/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.9959\n",
      "Epoch 32/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.0794\n",
      "Epoch 33/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.9857\n",
      "Epoch 34/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7057\n",
      "Epoch 35/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.8102\n",
      "Epoch 36/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.8427\n",
      "Epoch 37/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7842\n",
      "Epoch 38/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7464\n",
      "Epoch 39/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6356\n",
      "Epoch 40/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6964\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.42040571470444066, total= 3.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "996/996 [==============================] - 78s 78ms/step - loss: 16.6368\n",
      "Epoch 2/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5396\n",
      "Epoch 3/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3474\n",
      "Epoch 4/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3564\n",
      "Epoch 5/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3432\n",
      "Epoch 6/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3339\n",
      "Epoch 7/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3424\n",
      "Epoch 8/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3386\n",
      "Epoch 9/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3390\n",
      "Epoch 10/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3422\n",
      "Epoch 11/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3686\n",
      "Epoch 12/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3568\n",
      "Epoch 13/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3515\n",
      "Epoch 14/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4203\n",
      "Epoch 15/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4201\n",
      "Epoch 16/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4701\n",
      "Epoch 17/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 6171.5375\n",
      "Epoch 18/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1103.6445\n",
      "Epoch 19/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 93.5636\n",
      "Epoch 20/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 14.3890\n",
      "Epoch 21/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 6.5915\n",
      "Epoch 22/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 4.1245\n",
      "Epoch 23/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 2.1136\n",
      "Epoch 24/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 2.0396\n",
      "Epoch 25/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.0773\n",
      "Epoch 26/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.3491\n",
      "Epoch 27/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.8254\n",
      "Epoch 28/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.9113\n",
      "Epoch 29/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7932\n",
      "Epoch 30/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6906\n",
      "Epoch 31/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7849\n",
      "Epoch 32/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7158\n",
      "Epoch 33/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.0507\n",
      "Epoch 34/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.8498\n",
      "Epoch 35/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7726\n",
      "Epoch 36/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.0363\n",
      "Epoch 37/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.0960\n",
      "Epoch 38/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.3444\n",
      "Epoch 39/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 2.4964\n",
      "Epoch 40/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 6.4949\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-71.21949663805923, total= 3.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "334/334 [==============================] - 75s 224ms/step - loss: 0.7952\n",
      "Epoch 2/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6283\n",
      "Epoch 3/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5922\n",
      "Epoch 4/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6214\n",
      "Epoch 5/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5852\n",
      "Epoch 6/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6131\n",
      "Epoch 7/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5796\n",
      "Epoch 8/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5997\n",
      "Epoch 9/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5815\n",
      "Epoch 10/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5900\n",
      "Epoch 11/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5807\n",
      "Epoch 12/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5646\n",
      "Epoch 13/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5713\n",
      "Epoch 14/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5800\n",
      "Epoch 15/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5713\n",
      "Epoch 16/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5664\n",
      "Epoch 17/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5611\n",
      "Epoch 18/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5859\n",
      "Epoch 19/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5771\n",
      "Epoch 20/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5752\n",
      "Epoch 21/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5665\n",
      "Epoch 22/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5684\n",
      "Epoch 23/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5675\n",
      "Epoch 24/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5618\n",
      "Epoch 25/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5591\n",
      "Epoch 26/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5563\n",
      "Epoch 27/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5623\n",
      "Epoch 28/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5588\n",
      "Epoch 29/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5654\n",
      "Epoch 30/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5639\n",
      "Epoch 31/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5571\n",
      "Epoch 32/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5572\n",
      "Epoch 33/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5561\n",
      "Epoch 34/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5620\n",
      "Epoch 35/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5540\n",
      "Epoch 36/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5643\n",
      "Epoch 37/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5567\n",
      "Epoch 38/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5504\n",
      "Epoch 39/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5560\n",
      "Epoch 40/40\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5549\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.06078592761117929, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "665/665 [==============================] - 79s 119ms/step - loss: 0.4975\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4759\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4446\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4278\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4392\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4318\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4206\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4260\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4302\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4232\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4247\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4232\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4165\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4167\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4184\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4124\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4151\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4113\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4141\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4124\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4105\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4167\n",
      "Epoch 23/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4116\n",
      "Epoch 24/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4091\n",
      "Epoch 25/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4082\n",
      "Epoch 26/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4082\n",
      "Epoch 27/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4096\n",
      "Epoch 28/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4079\n",
      "Epoch 29/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4101\n",
      "Epoch 30/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4088\n",
      "Epoch 31/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4065\n",
      "Epoch 32/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4099\n",
      "Epoch 33/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4050\n",
      "Epoch 34/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4070\n",
      "Epoch 35/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4077\n",
      "Epoch 36/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4050\n",
      "Epoch 37/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4050\n",
      "Epoch 38/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4080\n",
      "Epoch 39/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4051\n",
      "Epoch 40/40\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4039\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.005423091304223027, total= 3.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "996/996 [==============================] - 161s 162ms/step - loss: 0.3728\n",
      "Epoch 2/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3566\n",
      "Epoch 3/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3543\n",
      "Epoch 4/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3365\n",
      "Epoch 5/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3401\n",
      "Epoch 6/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3364\n",
      "Epoch 7/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3324\n",
      "Epoch 8/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3272\n",
      "Epoch 9/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3276\n",
      "Epoch 10/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3252\n",
      "Epoch 11/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3242\n",
      "Epoch 12/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3259\n",
      "Epoch 13/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3237\n",
      "Epoch 14/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3230\n",
      "Epoch 15/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3229\n",
      "Epoch 16/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3220\n",
      "Epoch 17/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3233\n",
      "Epoch 18/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3199\n",
      "Epoch 19/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3204\n",
      "Epoch 20/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3231\n",
      "Epoch 21/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3187\n",
      "Epoch 22/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3207\n",
      "Epoch 23/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3215\n",
      "Epoch 24/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3187\n",
      "Epoch 25/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3178\n",
      "Epoch 26/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3167\n",
      "Epoch 27/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3196\n",
      "Epoch 28/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3179\n",
      "Epoch 29/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3200\n",
      "Epoch 30/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3175\n",
      "Epoch 31/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3169\n",
      "Epoch 32/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3166\n",
      "Epoch 33/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3157\n",
      "Epoch 34/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3189\n",
      "Epoch 35/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3165\n",
      "Epoch 36/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3171\n",
      "Epoch 37/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3161\n",
      "Epoch 38/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3169\n",
      "Epoch 39/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3166\n",
      "Epoch 40/40\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3163\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.004859971664919138, total= 4.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "334/334 [==============================] - 80s 240ms/step - loss: 1.0864\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6718\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5994\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5797\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6005\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5799\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5791\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5710\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5656\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5800\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5611\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5784\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5768\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5649\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5594\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5630\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5573\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5719\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5780\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5561\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5620\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5637\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5676\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6152\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6021\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5872\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5733\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5744\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5669\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5716\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5678\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5591\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5780\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5653\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5636\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5606\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5581\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5556\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5502\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5612\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5912\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5654\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5731\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5641\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5481\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5623\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5574\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5617\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5641\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5716\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.07234157772333116, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "665/665 [==============================] - 75s 113ms/step - loss: 0.7767\n",
      "Epoch 2/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4258\n",
      "Epoch 3/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4208\n",
      "Epoch 4/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4146\n",
      "Epoch 5/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4207\n",
      "Epoch 6/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4080\n",
      "Epoch 7/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4138\n",
      "Epoch 8/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4198\n",
      "Epoch 9/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4151\n",
      "Epoch 10/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4117\n",
      "Epoch 11/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4118\n",
      "Epoch 12/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4256\n",
      "Epoch 13/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4175\n",
      "Epoch 14/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4242\n",
      "Epoch 15/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4258\n",
      "Epoch 16/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4170\n",
      "Epoch 17/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4141\n",
      "Epoch 18/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4120\n",
      "Epoch 19/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4134\n",
      "Epoch 20/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4128\n",
      "Epoch 21/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4152\n",
      "Epoch 22/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4189\n",
      "Epoch 23/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4102\n",
      "Epoch 24/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4170\n",
      "Epoch 25/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4158\n",
      "Epoch 26/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4109\n",
      "Epoch 27/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4125\n",
      "Epoch 28/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4131\n",
      "Epoch 29/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4149\n",
      "Epoch 30/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4144\n",
      "Epoch 31/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4098\n",
      "Epoch 32/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4132\n",
      "Epoch 33/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4136\n",
      "Epoch 34/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4135\n",
      "Epoch 35/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4159\n",
      "Epoch 36/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4093\n",
      "Epoch 37/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4117\n",
      "Epoch 38/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4147\n",
      "Epoch 39/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4129\n",
      "Epoch 40/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4126\n",
      "Epoch 41/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4084\n",
      "Epoch 42/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4063\n",
      "Epoch 43/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4166\n",
      "Epoch 44/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4141\n",
      "Epoch 45/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4259\n",
      "Epoch 47/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4216\n",
      "Epoch 48/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4173\n",
      "Epoch 49/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4174\n",
      "Epoch 50/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4218\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.006149978892486585, total= 3.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "996/996 [==============================] - 74s 74ms/step - loss: 0.4930\n",
      "Epoch 2/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3382\n",
      "Epoch 3/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3316\n",
      "Epoch 4/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3345\n",
      "Epoch 5/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3368\n",
      "Epoch 6/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3300\n",
      "Epoch 7/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3270\n",
      "Epoch 8/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3273\n",
      "Epoch 9/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3245\n",
      "Epoch 10/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3264\n",
      "Epoch 11/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3255\n",
      "Epoch 12/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3275\n",
      "Epoch 13/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3268\n",
      "Epoch 14/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3288\n",
      "Epoch 15/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3291\n",
      "Epoch 16/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3276\n",
      "Epoch 17/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3241\n",
      "Epoch 18/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3223\n",
      "Epoch 19/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3246\n",
      "Epoch 20/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3232\n",
      "Epoch 21/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3220\n",
      "Epoch 22/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3210\n",
      "Epoch 23/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3219\n",
      "Epoch 24/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3239\n",
      "Epoch 25/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3276\n",
      "Epoch 26/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3223\n",
      "Epoch 27/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3343\n",
      "Epoch 28/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3275\n",
      "Epoch 29/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3314\n",
      "Epoch 30/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3281\n",
      "Epoch 31/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3309\n",
      "Epoch 32/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3415\n",
      "Epoch 33/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4273\n",
      "Epoch 34/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3476\n",
      "Epoch 35/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3579\n",
      "Epoch 36/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3320\n",
      "Epoch 37/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3251\n",
      "Epoch 38/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3208\n",
      "Epoch 39/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3221\n",
      "Epoch 40/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3205\n",
      "Epoch 41/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3223\n",
      "Epoch 42/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3191\n",
      "Epoch 43/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3220\n",
      "Epoch 44/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3206\n",
      "Epoch 45/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3192\n",
      "Epoch 46/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3292\n",
      "Epoch 47/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3272\n",
      "Epoch 48/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3302\n",
      "Epoch 49/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3282\n",
      "Epoch 50/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3302\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0343245074522367, total= 3.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "334/334 [==============================] - 74s 223ms/step - loss: 18.7156\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.0057\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9671\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7550\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7302\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7282\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6744\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5923\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6100\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6304\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7271\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7122\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6342\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5940\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6232\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5894\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6015\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6018\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6500\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6088\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6100\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8225\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7662\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8624\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9890\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.3030\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4910.6518\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4548.5077\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2374.3195\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 420.9376\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 114.5649\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 54.6860\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 19.9351\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.9579\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 5.6521\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2.9398\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.8207\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 3.2431\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2.2925\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2.5021\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.7487\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.2647\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9630\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8072\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9820\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.0067\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.4035\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9400\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.0008\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9924\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.9566734466390268, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "665/665 [==============================] - 72s 108ms/step - loss: 23.9718\n",
      "Epoch 2/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.7663\n",
      "Epoch 3/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5628\n",
      "Epoch 4/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4985\n",
      "Epoch 5/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4892\n",
      "Epoch 6/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4535\n",
      "Epoch 7/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4488\n",
      "Epoch 8/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4250\n",
      "Epoch 9/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4505\n",
      "Epoch 10/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4378\n",
      "Epoch 11/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4831\n",
      "Epoch 12/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4554\n",
      "Epoch 13/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4604\n",
      "Epoch 14/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4404\n",
      "Epoch 15/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4428\n",
      "Epoch 16/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4324\n",
      "Epoch 17/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4405\n",
      "Epoch 18/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4310\n",
      "Epoch 19/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4321\n",
      "Epoch 20/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4156\n",
      "Epoch 21/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4270\n",
      "Epoch 22/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4303\n",
      "Epoch 23/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4244\n",
      "Epoch 24/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4227\n",
      "Epoch 25/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4332\n",
      "Epoch 26/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4290\n",
      "Epoch 27/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4395\n",
      "Epoch 28/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5852\n",
      "Epoch 29/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 6075.4029\n",
      "Epoch 30/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 4556.9812\n",
      "Epoch 31/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 330.9214\n",
      "Epoch 32/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 65.5344\n",
      "Epoch 33/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 18.8006\n",
      "Epoch 34/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 5.5663\n",
      "Epoch 35/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 5.2452\n",
      "Epoch 36/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 4.3272\n",
      "Epoch 37/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 2.2005\n",
      "Epoch 38/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 2.3096\n",
      "Epoch 39/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.7810\n",
      "Epoch 40/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.4870\n",
      "Epoch 41/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.0707\n",
      "Epoch 42/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.2052\n",
      "Epoch 43/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.9823\n",
      "Epoch 44/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.9598\n",
      "Epoch 45/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.8575\n",
      "Epoch 46/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6419\n",
      "Epoch 47/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7302\n",
      "Epoch 48/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5973\n",
      "Epoch 49/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6891\n",
      "Epoch 50/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6366\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.35435008180665784, total= 3.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "996/996 [==============================] - 75s 75ms/step - loss: 8.5602\n",
      "Epoch 2/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6408\n",
      "Epoch 3/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3903\n",
      "Epoch 4/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3459\n",
      "Epoch 5/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3456\n",
      "Epoch 6/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3555\n",
      "Epoch 7/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3460\n",
      "Epoch 8/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3366\n",
      "Epoch 9/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3680\n",
      "Epoch 10/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5584\n",
      "Epoch 11/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1605.5497\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 2s 2ms/step - loss: 558.5353\n",
      "Epoch 13/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 15.9350\n",
      "Epoch 14/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 3.4437\n",
      "Epoch 15/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.6985\n",
      "Epoch 16/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.1423\n",
      "Epoch 17/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7107\n",
      "Epoch 18/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5397\n",
      "Epoch 19/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5136\n",
      "Epoch 20/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4654\n",
      "Epoch 21/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4692\n",
      "Epoch 22/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4607\n",
      "Epoch 23/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4313\n",
      "Epoch 24/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4488\n",
      "Epoch 25/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4597\n",
      "Epoch 26/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4521\n",
      "Epoch 27/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4354\n",
      "Epoch 28/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6417\n",
      "Epoch 29/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7412\n",
      "Epoch 30/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6324\n",
      "Epoch 31/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6656\n",
      "Epoch 32/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.1226\n",
      "Epoch 33/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.8475\n",
      "Epoch 34/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.9791\n",
      "Epoch 35/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6907\n",
      "Epoch 36/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7414\n",
      "Epoch 37/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.0689\n",
      "Epoch 38/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6003\n",
      "Epoch 39/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7861\n",
      "Epoch 40/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6694\n",
      "Epoch 41/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6726\n",
      "Epoch 42/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.0199\n",
      "Epoch 43/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.8274\n",
      "Epoch 44/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6003\n",
      "Epoch 45/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4648\n",
      "Epoch 46/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4534\n",
      "Epoch 47/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4715\n",
      "Epoch 48/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4615\n",
      "Epoch 49/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4362\n",
      "Epoch 50/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4139\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.13452071877005856, total= 3.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "334/334 [==============================] - 74s 223ms/step - loss: 0.6609\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6107\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6189\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6105\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5990\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5853\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5880\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6018\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5727\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5756\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5711\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5691\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5746\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5643\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5721\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5779\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5684\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5614\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5670\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5649\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5678\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5662\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5647\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5570\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5652\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5591\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5630\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5618\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5571\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5564\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5566\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5563\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5529\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5522\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5529\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5508\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5542\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5544\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5513\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5513\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5530\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5513\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5561\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5572\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5600\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5462\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5493\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5528\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5481\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5536\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.06311967461737278, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "665/665 [==============================] - 81s 122ms/step - loss: 0.4689\n",
      "Epoch 2/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4583\n",
      "Epoch 3/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4532\n",
      "Epoch 4/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4431\n",
      "Epoch 5/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4449\n",
      "Epoch 6/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4366\n",
      "Epoch 7/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4263\n",
      "Epoch 8/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4191\n",
      "Epoch 9/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4262\n",
      "Epoch 10/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4201\n",
      "Epoch 11/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4233\n",
      "Epoch 12/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4153\n",
      "Epoch 13/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4222\n",
      "Epoch 14/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4141\n",
      "Epoch 15/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4179\n",
      "Epoch 16/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4113\n",
      "Epoch 17/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4106\n",
      "Epoch 18/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4145\n",
      "Epoch 19/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4123\n",
      "Epoch 20/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4141\n",
      "Epoch 21/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4130\n",
      "Epoch 22/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4133\n",
      "Epoch 23/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4103\n",
      "Epoch 24/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4081\n",
      "Epoch 25/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4085\n",
      "Epoch 26/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4094\n",
      "Epoch 27/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4064\n",
      "Epoch 28/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4063\n",
      "Epoch 29/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4071\n",
      "Epoch 30/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4086\n",
      "Epoch 31/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4051\n",
      "Epoch 32/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4054\n",
      "Epoch 33/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4061\n",
      "Epoch 34/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4079\n",
      "Epoch 35/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4061\n",
      "Epoch 36/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4064\n",
      "Epoch 37/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4052\n",
      "Epoch 38/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4057\n",
      "Epoch 39/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4072\n",
      "Epoch 40/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4044\n",
      "Epoch 41/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4056\n",
      "Epoch 42/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4044\n",
      "Epoch 43/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4042\n",
      "Epoch 44/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4033\n",
      "Epoch 45/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4054\n",
      "Epoch 46/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4034\n",
      "Epoch 47/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4038\n",
      "Epoch 48/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4046\n",
      "Epoch 49/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4044\n",
      "Epoch 50/50\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4049\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.001538574508442303, total= 3.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "996/996 [==============================] - 79s 79ms/step - loss: 0.3843\n",
      "Epoch 2/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3544\n",
      "Epoch 3/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3485\n",
      "Epoch 4/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3344\n",
      "Epoch 5/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3348\n",
      "Epoch 6/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3338\n",
      "Epoch 7/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3330\n",
      "Epoch 8/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3293\n",
      "Epoch 9/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3250\n",
      "Epoch 10/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3262\n",
      "Epoch 11/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3237\n",
      "Epoch 12/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3253\n",
      "Epoch 13/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3232\n",
      "Epoch 14/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3245\n",
      "Epoch 15/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3232\n",
      "Epoch 16/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3220\n",
      "Epoch 17/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3216\n",
      "Epoch 18/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3220\n",
      "Epoch 19/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3218\n",
      "Epoch 20/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3214\n",
      "Epoch 21/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3189\n",
      "Epoch 22/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3195\n",
      "Epoch 23/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3197\n",
      "Epoch 24/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3209\n",
      "Epoch 25/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3169\n",
      "Epoch 26/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3198\n",
      "Epoch 27/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3178\n",
      "Epoch 28/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3208\n",
      "Epoch 29/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3185\n",
      "Epoch 30/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3178\n",
      "Epoch 31/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3174\n",
      "Epoch 32/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3170\n",
      "Epoch 33/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3167\n",
      "Epoch 34/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3160\n",
      "Epoch 35/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3184\n",
      "Epoch 36/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3160\n",
      "Epoch 37/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3165\n",
      "Epoch 38/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3160\n",
      "Epoch 39/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3170\n",
      "Epoch 40/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3170\n",
      "Epoch 41/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3158\n",
      "Epoch 42/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3185\n",
      "Epoch 43/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3176\n",
      "Epoch 44/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3178\n",
      "Epoch 45/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3175\n",
      "Epoch 46/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3161\n",
      "Epoch 47/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3185\n",
      "Epoch 48/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3152\n",
      "Epoch 49/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3163\n",
      "Epoch 50/50\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3158\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.0011603220393537894, total= 3.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 75s 225ms/step - loss: 1.2127\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6880\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6245\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5868\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6059\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5762\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5725\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5779\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5734\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5775\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5708\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5684\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5643\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5659\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5625\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5663\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5718\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5697\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5575\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5600\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5600\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5629\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5569\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5672\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5597\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5657\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5610\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5589\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5675\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5725\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5727\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5669\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5667\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5603\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5585\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5592\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5684\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5671\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5703\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5730\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6019\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5986\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5698\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5854\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5841\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5917\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5949\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5734\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5660\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5644\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5684\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5614\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5575\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5619\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5531\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5571\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5611\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5518\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5792\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5578\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5653\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5655\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5602\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5582\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5606\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5720\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5877\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6022\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5740\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6175\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6469\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5923\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6102\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6081\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5903\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5750\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5708\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5537\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5643\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5546\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5707\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5652\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5618\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5581\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5661\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5614\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5555\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5610\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5549\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5617\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5624\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5610\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5569\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5680\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5554\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5732\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5816\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5715\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5680\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5645\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.07052230632465228, total= 3.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "665/665 [==============================] - 79s 118ms/step - loss: 0.6149\n",
      "Epoch 2/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4451\n",
      "Epoch 3/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4264\n",
      "Epoch 4/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4203\n",
      "Epoch 5/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4343\n",
      "Epoch 6/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4247\n",
      "Epoch 7/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4157\n",
      "Epoch 8/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4163\n",
      "Epoch 9/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4152\n",
      "Epoch 10/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4133\n",
      "Epoch 11/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4126\n",
      "Epoch 12/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4245\n",
      "Epoch 13/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4196\n",
      "Epoch 14/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4190\n",
      "Epoch 15/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4264\n",
      "Epoch 16/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4136\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4163\n",
      "Epoch 18/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4115\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4114\n",
      "Epoch 20/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4137\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4163\n",
      "Epoch 22/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4191\n",
      "Epoch 23/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4169\n",
      "Epoch 24/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4228\n",
      "Epoch 25/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4235\n",
      "Epoch 26/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4195\n",
      "Epoch 27/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4183\n",
      "Epoch 28/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4179\n",
      "Epoch 29/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4217\n",
      "Epoch 30/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4158\n",
      "Epoch 31/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4222\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4237\n",
      "Epoch 33/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4162\n",
      "Epoch 34/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4164\n",
      "Epoch 35/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4262\n",
      "Epoch 36/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4399\n",
      "Epoch 37/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4382\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4165\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4238\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4136\n",
      "Epoch 41/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4141\n",
      "Epoch 42/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4169\n",
      "Epoch 43/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4157\n",
      "Epoch 44/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4229\n",
      "Epoch 45/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4129\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4200\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4244\n",
      "Epoch 48/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4231\n",
      "Epoch 49/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4249\n",
      "Epoch 50/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4298\n",
      "Epoch 51/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4269\n",
      "Epoch 52/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4149\n",
      "Epoch 53/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4236\n",
      "Epoch 54/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4058\n",
      "Epoch 55/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4156\n",
      "Epoch 56/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4250\n",
      "Epoch 57/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4162\n",
      "Epoch 58/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4124\n",
      "Epoch 59/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4131\n",
      "Epoch 60/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4142\n",
      "Epoch 61/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4167\n",
      "Epoch 62/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4240\n",
      "Epoch 63/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4303\n",
      "Epoch 64/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4297\n",
      "Epoch 65/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4223\n",
      "Epoch 66/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4439\n",
      "Epoch 67/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4257\n",
      "Epoch 68/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4167\n",
      "Epoch 69/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4331\n",
      "Epoch 70/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4262\n",
      "Epoch 71/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4257\n",
      "Epoch 72/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4164\n",
      "Epoch 73/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4282\n",
      "Epoch 74/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4172\n",
      "Epoch 75/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4275\n",
      "Epoch 76/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4651\n",
      "Epoch 77/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4524\n",
      "Epoch 78/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4447\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4485\n",
      "Epoch 80/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4288\n",
      "Epoch 81/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4320\n",
      "Epoch 82/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4094\n",
      "Epoch 83/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4138\n",
      "Epoch 84/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4106\n",
      "Epoch 85/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4083\n",
      "Epoch 86/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4095\n",
      "Epoch 87/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4098\n",
      "Epoch 88/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4092\n",
      "Epoch 89/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4124\n",
      "Epoch 90/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4091\n",
      "Epoch 91/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4097\n",
      "Epoch 92/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4165\n",
      "Epoch 93/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4187\n",
      "Epoch 94/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4173\n",
      "Epoch 95/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4238\n",
      "Epoch 96/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4241\n",
      "Epoch 97/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4220\n",
      "Epoch 98/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4191\n",
      "Epoch 99/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4338\n",
      "Epoch 100/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4157\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.09078875601001646, total= 4.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "996/996 [==============================] - 79s 80ms/step - loss: 0.4557\n",
      "Epoch 2/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3326\n",
      "Epoch 3/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3383\n",
      "Epoch 4/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3317\n",
      "Epoch 5/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3297\n",
      "Epoch 6/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3258\n",
      "Epoch 7/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3270\n",
      "Epoch 8/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3339\n",
      "Epoch 9/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3320\n",
      "Epoch 10/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3245\n",
      "Epoch 11/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3265\n",
      "Epoch 12/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3248\n",
      "Epoch 13/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3292\n",
      "Epoch 14/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3267\n",
      "Epoch 15/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3227\n",
      "Epoch 16/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3263\n",
      "Epoch 17/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3255\n",
      "Epoch 18/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3299\n",
      "Epoch 19/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3321\n",
      "Epoch 20/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3221\n",
      "Epoch 21/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3212\n",
      "Epoch 22/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3245\n",
      "Epoch 23/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3237\n",
      "Epoch 24/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3210\n",
      "Epoch 25/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3225\n",
      "Epoch 26/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3244\n",
      "Epoch 27/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3298\n",
      "Epoch 28/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3359\n",
      "Epoch 29/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3257\n",
      "Epoch 30/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3337\n",
      "Epoch 31/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3323\n",
      "Epoch 32/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3267\n",
      "Epoch 33/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3241\n",
      "Epoch 34/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3362\n",
      "Epoch 35/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4930\n",
      "Epoch 36/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4265\n",
      "Epoch 37/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3463\n",
      "Epoch 38/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3353\n",
      "Epoch 39/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3299\n",
      "Epoch 40/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3335\n",
      "Epoch 41/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3224\n",
      "Epoch 42/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3206\n",
      "Epoch 43/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3196\n",
      "Epoch 44/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3194\n",
      "Epoch 45/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3200\n",
      "Epoch 46/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3224\n",
      "Epoch 47/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3186\n",
      "Epoch 48/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3236\n",
      "Epoch 49/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3204\n",
      "Epoch 50/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3213\n",
      "Epoch 51/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3250\n",
      "Epoch 52/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3264\n",
      "Epoch 53/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3278\n",
      "Epoch 54/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3248\n",
      "Epoch 55/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3370\n",
      "Epoch 56/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3310\n",
      "Epoch 57/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3502\n",
      "Epoch 58/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4119\n",
      "Epoch 59/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3745\n",
      "Epoch 60/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3252\n",
      "Epoch 61/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3275\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3289\n",
      "Epoch 63/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3231\n",
      "Epoch 64/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3208\n",
      "Epoch 65/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3251\n",
      "Epoch 66/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3206\n",
      "Epoch 67/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3223\n",
      "Epoch 68/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3199\n",
      "Epoch 69/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3208\n",
      "Epoch 70/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3203\n",
      "Epoch 71/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3244\n",
      "Epoch 72/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3200\n",
      "Epoch 73/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3221\n",
      "Epoch 74/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3204\n",
      "Epoch 75/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3325\n",
      "Epoch 76/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3355\n",
      "Epoch 77/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3345\n",
      "Epoch 78/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3386\n",
      "Epoch 79/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3479\n",
      "Epoch 80/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3655\n",
      "Epoch 81/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3442\n",
      "Epoch 82/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3892\n",
      "Epoch 83/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3449\n",
      "Epoch 84/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3295\n",
      "Epoch 85/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3202\n",
      "Epoch 86/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3240\n",
      "Epoch 87/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3209\n",
      "Epoch 88/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3374\n",
      "Epoch 89/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3239\n",
      "Epoch 90/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3254\n",
      "Epoch 91/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3222\n",
      "Epoch 92/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3271\n",
      "Epoch 93/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3278\n",
      "Epoch 94/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3263\n",
      "Epoch 95/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3231\n",
      "Epoch 96/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3239\n",
      "Epoch 97/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3209\n",
      "Epoch 98/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3203\n",
      "Epoch 99/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3234\n",
      "Epoch 100/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3236\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.011819905288497967, total= 5.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 75s 225ms/step - loss: 26.5257\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.5434\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 3.4083\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.1632\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7608\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7084\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6246\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6362\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6100\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6322\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6060\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6186\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6010\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6336\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6008\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6135\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6327\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6174\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6213\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6500\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6045\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5957\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5784\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5855\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5757\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5831\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5847\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6205\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6040\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5822\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6100\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5750\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5777\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5852\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5731\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5813\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5913\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5991\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5715\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6005\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6042\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6756\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2.2183\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 9487.9726\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7722.4551\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1817.5505\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 311.8071\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 205.1014\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 70.9699\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 27.2479\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 14.2602\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.7019\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.8286\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.5507\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.1464\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 4.8193\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 3.3617\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2.4080\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.9732\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.8860\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2.1944\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.5186\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.0704\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.2772\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.1164\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.2001\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.0219\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.2303\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.3380\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.2305\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.4386\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.5929\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.2343\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.2002\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.1483\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.0694\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.1004\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.0472\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8583\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8553\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8486\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7855\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7211\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9488\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9130\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9561\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.0327\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9700\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.0359\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8549\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8146\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.9202\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8201\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6970\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.7499\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8840\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8993\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.8354\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 1.0140\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 2.9992\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-43.50270396610048, total= 3.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "665/665 [==============================] - 80s 120ms/step - loss: 20.1618\n",
      "Epoch 2/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.5009\n",
      "Epoch 3/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5093\n",
      "Epoch 4/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4676\n",
      "Epoch 5/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4443\n",
      "Epoch 6/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4366\n",
      "Epoch 7/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4409\n",
      "Epoch 8/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4360\n",
      "Epoch 9/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4379\n",
      "Epoch 10/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.442 - 1s 2ms/step - loss: 0.4450\n",
      "Epoch 11/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4434\n",
      "Epoch 12/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4305\n",
      "Epoch 13/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4314\n",
      "Epoch 14/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5044\n",
      "Epoch 15/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5058\n",
      "Epoch 16/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4871\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4355\n",
      "Epoch 18/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4384\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4297\n",
      "Epoch 20/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4402\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4468\n",
      "Epoch 22/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4262\n",
      "Epoch 23/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4188\n",
      "Epoch 24/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4174\n",
      "Epoch 25/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4185\n",
      "Epoch 26/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4165\n",
      "Epoch 27/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4073\n",
      "Epoch 28/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4359\n",
      "Epoch 29/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4363\n",
      "Epoch 30/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4834\n",
      "Epoch 31/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5396\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 10036.7042\n",
      "Epoch 33/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 2529.6391\n",
      "Epoch 34/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 85.2395\n",
      "Epoch 35/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 24.6669\n",
      "Epoch 36/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 5.2544\n",
      "Epoch 37/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 3.6963\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 3.3601\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.9410\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.6824\n",
      "Epoch 41/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.0521\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 1s 2ms/step - loss: 1.2375\n",
      "Epoch 43/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.9852\n",
      "Epoch 44/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.0940\n",
      "Epoch 45/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.9842\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7580\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7971\n",
      "Epoch 48/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7059\n",
      "Epoch 49/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.8848\n",
      "Epoch 50/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6953\n",
      "Epoch 51/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7643\n",
      "Epoch 52/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.8136\n",
      "Epoch 53/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6194\n",
      "Epoch 54/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5504\n",
      "Epoch 55/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5724\n",
      "Epoch 56/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6154\n",
      "Epoch 57/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7167\n",
      "Epoch 58/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.9204\n",
      "Epoch 59/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.0254\n",
      "Epoch 60/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6466\n",
      "Epoch 61/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7843\n",
      "Epoch 62/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.2745\n",
      "Epoch 63/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.1994\n",
      "Epoch 64/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7846\n",
      "Epoch 65/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7999\n",
      "Epoch 66/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.8625\n",
      "Epoch 67/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 3.7420\n",
      "Epoch 68/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 4.3965\n",
      "Epoch 69/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 8.9105\n",
      "Epoch 70/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 22.7517\n",
      "Epoch 71/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 14.8473\n",
      "Epoch 72/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 8.0135\n",
      "Epoch 73/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 2.5287\n",
      "Epoch 74/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.9740\n",
      "Epoch 75/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6367\n",
      "Epoch 76/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5231\n",
      "Epoch 77/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5786\n",
      "Epoch 78/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6202\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6592\n",
      "Epoch 80/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6193\n",
      "Epoch 81/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6671\n",
      "Epoch 82/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6831\n",
      "Epoch 83/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7694\n",
      "Epoch 84/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.8121\n",
      "Epoch 85/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7689\n",
      "Epoch 86/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.6261\n",
      "Epoch 87/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 2.0619\n",
      "Epoch 88/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.2727\n",
      "Epoch 89/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 2.3149\n",
      "Epoch 90/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.6256\n",
      "Epoch 91/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.9100\n",
      "Epoch 92/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7906\n",
      "Epoch 93/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.6280\n",
      "Epoch 94/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7237\n",
      "Epoch 95/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7827\n",
      "Epoch 96/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7695\n",
      "Epoch 97/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7523\n",
      "Epoch 98/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.7800\n",
      "Epoch 99/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.9499\n",
      "Epoch 100/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 1.0593\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-1.6061023049238004, total= 4.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "996/996 [==============================] - 77s 77ms/step - loss: 9.0234\n",
      "Epoch 2/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5057\n",
      "Epoch 3/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3664\n",
      "Epoch 4/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3615\n",
      "Epoch 5/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3652\n",
      "Epoch 6/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4436\n",
      "Epoch 7/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4192\n",
      "Epoch 8/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5149\n",
      "Epoch 9/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 2812.0158\n",
      "Epoch 10/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1860.7737\n",
      "Epoch 11/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 77.5049\n",
      "Epoch 12/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 17.9372\n",
      "Epoch 13/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 7.6673\n",
      "Epoch 14/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 2.3966\n",
      "Epoch 15/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 2.6964\n",
      "Epoch 16/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.5503\n",
      "Epoch 17/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.3898\n",
      "Epoch 18/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.1523\n",
      "Epoch 19/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.1536\n",
      "Epoch 20/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.9571\n",
      "Epoch 21/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.3505\n",
      "Epoch 22/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.9928\n",
      "Epoch 23/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.9490\n",
      "Epoch 24/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6653\n",
      "Epoch 25/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6471\n",
      "Epoch 26/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.9454\n",
      "Epoch 27/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.8829\n",
      "Epoch 28/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6874\n",
      "Epoch 29/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6961\n",
      "Epoch 30/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.7455\n",
      "Epoch 31/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 26.3933\n",
      "Epoch 32/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 18.2663\n",
      "Epoch 33/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 4.0725\n",
      "Epoch 34/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.6174\n",
      "Epoch 35/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.8588\n",
      "Epoch 36/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5372\n",
      "Epoch 37/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4607\n",
      "Epoch 38/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3971\n",
      "Epoch 39/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4045\n",
      "Epoch 40/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4347\n",
      "Epoch 41/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4419\n",
      "Epoch 42/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5635\n",
      "Epoch 43/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5958\n",
      "Epoch 44/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6203\n",
      "Epoch 45/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5444\n",
      "Epoch 46/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6893\n",
      "Epoch 47/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.8368\n",
      "Epoch 48/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7254\n",
      "Epoch 49/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5749\n",
      "Epoch 50/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5305\n",
      "Epoch 51/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4884\n",
      "Epoch 52/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4187\n",
      "Epoch 53/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4515\n",
      "Epoch 54/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6409\n",
      "Epoch 55/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5543\n",
      "Epoch 56/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7451\n",
      "Epoch 57/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6822\n",
      "Epoch 58/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4292\n",
      "Epoch 59/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.6167\n",
      "Epoch 60/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4363\n",
      "Epoch 61/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4288\n",
      "Epoch 62/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4345\n",
      "Epoch 63/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3702\n",
      "Epoch 64/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3727\n",
      "Epoch 65/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3942\n",
      "Epoch 66/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3692\n",
      "Epoch 67/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3889\n",
      "Epoch 68/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3679\n",
      "Epoch 69/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.4942\n",
      "Epoch 70/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.5474\n",
      "Epoch 71/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.5855\n",
      "Epoch 72/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 10415.2638\n",
      "Epoch 73/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 2146.9798\n",
      "Epoch 74/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 168.9521\n",
      "Epoch 75/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 47.2010\n",
      "Epoch 76/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 15.8456\n",
      "Epoch 77/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 12.2637\n",
      "Epoch 78/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 6.6734\n",
      "Epoch 79/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 3.4777\n",
      "Epoch 80/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 3.0136\n",
      "Epoch 81/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 2.6437\n",
      "Epoch 82/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.5731\n",
      "Epoch 83/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.5093\n",
      "Epoch 84/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.3343\n",
      "Epoch 85/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.0613\n",
      "Epoch 86/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.9346\n",
      "Epoch 87/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.9810\n",
      "Epoch 88/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.8340\n",
      "Epoch 89/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7669\n",
      "Epoch 90/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7769\n",
      "Epoch 91/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7705\n",
      "Epoch 92/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.7497\n",
      "Epoch 93/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 1.3722\n",
      "Epoch 94/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 10.0035\n",
      "Epoch 95/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 18.3494\n",
      "Epoch 96/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 10.9979\n",
      "Epoch 97/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 7.5948\n",
      "Epoch 98/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 7.5595\n",
      "Epoch 99/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 34.4348\n",
      "Epoch 100/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 29.1420\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-114.7259039433249, total= 5.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 77s 232ms/step - loss: 0.7455\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6087\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6022\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5906\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5917\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5800\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5860\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5868\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.6081\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5926\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5810\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5704\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5770\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5659\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5727\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5781\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5726\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5718\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5652\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5685\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5628\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5662\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5663\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5595\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5549\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5655\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5631\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5569\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5621\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5576\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5550\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5620\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5579\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5502\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5489\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5532\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5524\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5556\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5536\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5525\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5536\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5513\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5501\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5518\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5539\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5518\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5573\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5562\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5506\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5530\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5558\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5581\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5523\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5484\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5493\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5508\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5541\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5536\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5477\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5517\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5496\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5467\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5513\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5501\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5491\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5463\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5448\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5494\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5450\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5473\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5455\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5469\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5450\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5480\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5453\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5475\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5470\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5468\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5462\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5470\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5465\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5450\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5471\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5481\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5490\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5449\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5448\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5475\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5480\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5456\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5475\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5452\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5450\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5439\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5477\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5464\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5455\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5434\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5428\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.5447\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.06026424724882529, total= 3.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "665/665 [==============================] - 79s 119ms/step - loss: 0.4798\n",
      "Epoch 2/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4550\n",
      "Epoch 3/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4400\n",
      "Epoch 4/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4319\n",
      "Epoch 5/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4288\n",
      "Epoch 6/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4434\n",
      "Epoch 7/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4228\n",
      "Epoch 8/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4324\n",
      "Epoch 9/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4176\n",
      "Epoch 10/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4166\n",
      "Epoch 11/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4139\n",
      "Epoch 12/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4155\n",
      "Epoch 13/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4182\n",
      "Epoch 14/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4135\n",
      "Epoch 15/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4130\n",
      "Epoch 16/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4108\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4168\n",
      "Epoch 18/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4114\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4126\n",
      "Epoch 20/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4111\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4130\n",
      "Epoch 22/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4094\n",
      "Epoch 23/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4066\n",
      "Epoch 24/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4091\n",
      "Epoch 25/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4058\n",
      "Epoch 26/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4058\n",
      "Epoch 27/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4078\n",
      "Epoch 28/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4085\n",
      "Epoch 29/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4054\n",
      "Epoch 30/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4062\n",
      "Epoch 31/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4035\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4045\n",
      "Epoch 33/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4066\n",
      "Epoch 34/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4045\n",
      "Epoch 35/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4048\n",
      "Epoch 36/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4061\n",
      "Epoch 37/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4042\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4055\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4042\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4054\n",
      "Epoch 41/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4013\n",
      "Epoch 42/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4035\n",
      "Epoch 43/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4079\n",
      "Epoch 44/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4060\n",
      "Epoch 45/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4037\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4057\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4032\n",
      "Epoch 48/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4036\n",
      "Epoch 49/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4017\n",
      "Epoch 50/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4043\n",
      "Epoch 51/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4029\n",
      "Epoch 52/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4055\n",
      "Epoch 53/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4017\n",
      "Epoch 54/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4025\n",
      "Epoch 55/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4013\n",
      "Epoch 56/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4009\n",
      "Epoch 57/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4030\n",
      "Epoch 58/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4033\n",
      "Epoch 59/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4030\n",
      "Epoch 60/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4017\n",
      "Epoch 61/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4034\n",
      "Epoch 62/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4005\n",
      "Epoch 63/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4122\n",
      "Epoch 64/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4038\n",
      "Epoch 65/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4021\n",
      "Epoch 66/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4032\n",
      "Epoch 67/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4017\n",
      "Epoch 68/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4037\n",
      "Epoch 69/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4026\n",
      "Epoch 70/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.3994\n",
      "Epoch 71/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4040\n",
      "Epoch 72/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4018\n",
      "Epoch 73/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4000\n",
      "Epoch 74/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4010\n",
      "Epoch 75/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.3996\n",
      "Epoch 76/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4020\n",
      "Epoch 77/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4045\n",
      "Epoch 78/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.3997\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4012\n",
      "Epoch 80/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4009\n",
      "Epoch 81/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4013\n",
      "Epoch 82/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4006\n",
      "Epoch 83/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.3995\n",
      "Epoch 84/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4002\n",
      "Epoch 85/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4007\n",
      "Epoch 86/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.3988\n",
      "Epoch 87/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4068\n",
      "Epoch 88/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4004\n",
      "Epoch 89/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4002\n",
      "Epoch 90/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4017\n",
      "Epoch 91/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4009\n",
      "Epoch 92/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4009\n",
      "Epoch 93/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.3995\n",
      "Epoch 94/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.3997\n",
      "Epoch 95/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.3994\n",
      "Epoch 96/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4015\n",
      "Epoch 97/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4035\n",
      "Epoch 98/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.3993\n",
      "Epoch 99/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.3994\n",
      "Epoch 100/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.4006\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.01414712500027493, total= 4.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "996/996 [==============================] - 81s 81ms/step - loss: 0.3813\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3578\n",
      "Epoch 3/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3569\n",
      "Epoch 4/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3412\n",
      "Epoch 5/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3357\n",
      "Epoch 6/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3381\n",
      "Epoch 7/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3353\n",
      "Epoch 8/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3275\n",
      "Epoch 9/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3321\n",
      "Epoch 10/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3309\n",
      "Epoch 11/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3257\n",
      "Epoch 12/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3276\n",
      "Epoch 13/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3250\n",
      "Epoch 14/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3230\n",
      "Epoch 15/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3253\n",
      "Epoch 16/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3237\n",
      "Epoch 17/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3199\n",
      "Epoch 18/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3201\n",
      "Epoch 19/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3215\n",
      "Epoch 20/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3218\n",
      "Epoch 21/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3216\n",
      "Epoch 22/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3207\n",
      "Epoch 23/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3218\n",
      "Epoch 24/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3196\n",
      "Epoch 25/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3185\n",
      "Epoch 26/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3171\n",
      "Epoch 27/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3187\n",
      "Epoch 28/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3203\n",
      "Epoch 29/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3181\n",
      "Epoch 30/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3194\n",
      "Epoch 31/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3180\n",
      "Epoch 32/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3167\n",
      "Epoch 33/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3179\n",
      "Epoch 34/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3166\n",
      "Epoch 35/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3191\n",
      "Epoch 36/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3186\n",
      "Epoch 37/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3158\n",
      "Epoch 38/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3175\n",
      "Epoch 39/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3171\n",
      "Epoch 40/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3179\n",
      "Epoch 41/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3159\n",
      "Epoch 42/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3175\n",
      "Epoch 43/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3194\n",
      "Epoch 44/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3183\n",
      "Epoch 45/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3169\n",
      "Epoch 46/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3180\n",
      "Epoch 47/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3179\n",
      "Epoch 48/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3152\n",
      "Epoch 49/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3168\n",
      "Epoch 50/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3175\n",
      "Epoch 51/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3158\n",
      "Epoch 52/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3163\n",
      "Epoch 53/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3169\n",
      "Epoch 54/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3195\n",
      "Epoch 55/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3166\n",
      "Epoch 56/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3149\n",
      "Epoch 57/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3145\n",
      "Epoch 58/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3169\n",
      "Epoch 59/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3157\n",
      "Epoch 60/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3154\n",
      "Epoch 61/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3151\n",
      "Epoch 62/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3160\n",
      "Epoch 63/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3165\n",
      "Epoch 64/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3148\n",
      "Epoch 65/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3152\n",
      "Epoch 66/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3148\n",
      "Epoch 67/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3153\n",
      "Epoch 68/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3146\n",
      "Epoch 69/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3156\n",
      "Epoch 70/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3151\n",
      "Epoch 71/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3155\n",
      "Epoch 72/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3152\n",
      "Epoch 73/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3137\n",
      "Epoch 74/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3160\n",
      "Epoch 75/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3139\n",
      "Epoch 76/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3137\n",
      "Epoch 77/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3137\n",
      "Epoch 78/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3141\n",
      "Epoch 79/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3125\n",
      "Epoch 80/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3160\n",
      "Epoch 81/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3145\n",
      "Epoch 82/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3151\n",
      "Epoch 83/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3158\n",
      "Epoch 84/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3143\n",
      "Epoch 85/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3135\n",
      "Epoch 86/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3140\n",
      "Epoch 87/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3150\n",
      "Epoch 88/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3132\n",
      "Epoch 89/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3144\n",
      "Epoch 90/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3129\n",
      "Epoch 91/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3155\n",
      "Epoch 92/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3134\n",
      "Epoch 93/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3136\n",
      "Epoch 94/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3138\n",
      "Epoch 95/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3130\n",
      "Epoch 96/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3139\n",
      "Epoch 97/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3134\n",
      "Epoch 98/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3143\n",
      "Epoch 99/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3135\n",
      "Epoch 100/100\n",
      "996/996 [==============================] - 2s 2ms/step - loss: 0.3138\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=10, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.002193769413797453, total= 5.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 79s 237ms/step - loss: 1.2061\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.8378\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 0s 384us/step - loss: 0.7286\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 0s 387us/step - loss: 0.6550\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 0s 396us/step - loss: 0.6124\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 0s 400us/step - loss: 0.5860\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 0s 393us/step - loss: 0.5606\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 0s 398us/step - loss: 0.5669\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 0s 388us/step - loss: 0.5570\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 0s 396us/step - loss: 0.5572\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.04209344533620252, total= 2.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "665/665 [==============================] - 81s 121ms/step - loss: 0.6721\n",
      "Epoch 2/10\n",
      "665/665 [==============================] - 0s 395us/step - loss: 0.5025\n",
      "Epoch 3/10\n",
      "665/665 [==============================] - 0s 403us/step - loss: 0.4756\n",
      "Epoch 4/10\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4244\n",
      "Epoch 5/10\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4422\n",
      "Epoch 6/10\n",
      "665/665 [==============================] - 0s 506us/step - loss: 0.4274\n",
      "Epoch 7/10\n",
      "665/665 [==============================] - 0s 393us/step - loss: 0.4149\n",
      "Epoch 8/10\n",
      "665/665 [==============================] - 0s 398us/step - loss: 0.4141\n",
      "Epoch 9/10\n",
      "665/665 [==============================] - 0s 401us/step - loss: 0.4098\n",
      "Epoch 10/10\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4105\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0017153848165125662, total= 2.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "996/996 [==============================] - 98s 98ms/step - loss: 0.4991\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3651\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3332\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3279\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3216\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 0s 417us/step - loss: 0.3260\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 0s 439us/step - loss: 0.3197\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 0s 472us/step - loss: 0.3183\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 0s 468us/step - loss: 0.3194\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 0s 464us/step - loss: 0.3168\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.00903309308651834, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 86s 256ms/step - loss: 32.5278\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 0s 459us/step - loss: 19.8650\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 0s 441us/step - loss: 17.7279\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 0s 446us/step - loss: 8.9505\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 0s 422us/step - loss: 3.8734\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 0s 415us/step - loss: 1.3740\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.9259\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.7826\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 0s 440us/step - loss: 0.7046\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5940\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.27793958186653356, total= 2.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "665/665 [==============================] - 97s 146ms/step - loss: 27.9162\n",
      "Epoch 2/10\n",
      "665/665 [==============================] - 0s 442us/step - loss: 5.2158\n",
      "Epoch 3/10\n",
      "665/665 [==============================] - 0s 438us/step - loss: 1.9438\n",
      "Epoch 4/10\n",
      "665/665 [==============================] - 0s 436us/step - loss: 1.4756\n",
      "Epoch 5/10\n",
      "665/665 [==============================] - 0s 469us/step - loss: 0.5631\n",
      "Epoch 6/10\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.5768\n",
      "Epoch 7/10\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4430\n",
      "Epoch 8/10\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4184\n",
      "Epoch 9/10\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4106\n",
      "Epoch 10/10\n",
      "665/665 [==============================] - 0s 440us/step - loss: 0.4243\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0186851897947673, total= 2.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "996/996 [==============================] - 86s 86ms/step - loss: 30.7249\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 0s 407us/step - loss: 2.8794\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.6495\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3847\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3318\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3312\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3298\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3266\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3229\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3192\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=5.1507006772255615e-05, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 88s 264ms/step - loss: 0.8243\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 0s 439us/step - loss: 0.6433\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 0s 451us/step - loss: 0.5922\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5572\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5561\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 0s 435us/step - loss: 0.5703\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5679\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5524\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 0s 433us/step - loss: 0.5578\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5587\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.1155789487584864, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "665/665 [==============================] - 81s 122ms/step - loss: 0.5263\n",
      "Epoch 2/10\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4522\n",
      "Epoch 3/10\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4248\n",
      "Epoch 4/10\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4182\n",
      "Epoch 5/10\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4190\n",
      "Epoch 6/10\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4150\n",
      "Epoch 7/10\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4142\n",
      "Epoch 8/10\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4208\n",
      "Epoch 9/10\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4144\n",
      "Epoch 10/10\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4053\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.007616465323985411, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "996/996 [==============================] - 89s 89ms/step - loss: 0.4294\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3335\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 0s 384us/step - loss: 0.3301\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3370\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 0s 380us/step - loss: 0.3298\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3219\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3236\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 0s 414us/step - loss: 0.3251\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3212\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3329\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.006019151667318368, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 123s 367ms/step - loss: 0.9627\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 395us/step - loss: 0.7215\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 403us/step - loss: 0.6332\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 398us/step - loss: 0.6057\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 400us/step - loss: 0.5781\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 398us/step - loss: 0.5756\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 396us/step - loss: 0.5616\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 397us/step - loss: 0.5614\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5638\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5550\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5590\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 395us/step - loss: 0.5536\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 392us/step - loss: 0.5501\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 398us/step - loss: 0.5444\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 395us/step - loss: 0.5453\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 400us/step - loss: 0.5484\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 397us/step - loss: 0.5427\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5523\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 399us/step - loss: 0.5452\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 393us/step - loss: 0.5449\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.07095559738171531, total= 3.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "665/665 [==============================] - 90s 136ms/step - loss: 0.6712\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.5214\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4446\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4419\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 399us/step - loss: 0.4301\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4278\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 402us/step - loss: 0.4139\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4140\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 486us/step - loss: 0.4106\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 406us/step - loss: 0.4063\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 397us/step - loss: 0.4096\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4058\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.4069\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4019\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4030\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 402us/step - loss: 0.4015\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4042\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 401us/step - loss: 0.4008\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4008\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 406us/step - loss: 0.4012\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.004389219279394396, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 86s 86ms/step - loss: 0.4994\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3595\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3436\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3325\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3301\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3264\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3211\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3171\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 383us/step - loss: 0.3204\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 385us/step - loss: 0.3210\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3200\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3188\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3172\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3160\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 383us/step - loss: 0.3156\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3152\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3148\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 428us/step - loss: 0.3161\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3148\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3154\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.001116958209160468, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 84s 252ms/step - loss: 47.8510\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 396us/step - loss: 20.6854\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 406us/step - loss: 5.2266\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 397us/step - loss: 5.5791\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 397us/step - loss: 3.8613\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 401us/step - loss: 1.9913\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 406us/step - loss: 1.2923\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 390us/step - loss: 0.7856\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 393us/step - loss: 0.6986\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 409us/step - loss: 1.0555\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.8991\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.6759\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 400us/step - loss: 0.6015\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5788\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.6106\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 396us/step - loss: 0.5778\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 396us/step - loss: 0.5637\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 400us/step - loss: 0.5830\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5630\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.468 - 0s 407us/step - loss: 0.5564\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.027317163732609062, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 82s 123ms/step - loss: 38.7325\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 409us/step - loss: 22.2958\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 404us/step - loss: 8.0883\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 411us/step - loss: 2.8430\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 470us/step - loss: 1.3702\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 401us/step - loss: 0.9753\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 443us/step - loss: 0.5299\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4542\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 407us/step - loss: 0.4366\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.4337\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4728\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 398us/step - loss: 0.4201\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 408us/step - loss: 0.4231\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4355\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4388\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4294\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 403us/step - loss: 0.4247\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4098\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 398us/step - loss: 0.4122\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4125\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.014199268581950086, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 84s 84ms/step - loss: 16.1413\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 395us/step - loss: 2.9827\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.6915\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 382us/step - loss: 0.4359\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3676\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 383us/step - loss: 0.3605\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3331\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 379us/step - loss: 0.3299\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 384us/step - loss: 0.3265\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3276\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3267\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 383us/step - loss: 0.3234\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 382us/step - loss: 0.3197\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3258\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3272\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 433us/step - loss: 0.3259\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 378us/step - loss: 0.3292\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 385us/step - loss: 0.3281\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 384us/step - loss: 0.3276\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 382us/step - loss: 0.3211\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.02725190120020904, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 84s 251ms/step - loss: 0.7265\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5920\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 394us/step - loss: 0.5849\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5628\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5540\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5559\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5565\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 401us/step - loss: 0.5489\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5495\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 403us/step - loss: 0.5540\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 400us/step - loss: 0.5474\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5511\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5486\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 397us/step - loss: 0.5543\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5532\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5461\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 399us/step - loss: 0.5524\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5513\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 403us/step - loss: 0.5537\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5502\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.063749670546416, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 81s 122ms/step - loss: 0.5222\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4209\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4170\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4146\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 406us/step - loss: 0.4165\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4153\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4168\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 407us/step - loss: 0.4115\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 403us/step - loss: 0.4179\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 408us/step - loss: 0.4055\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 402us/step - loss: 0.4115\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4101\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 398us/step - loss: 0.4130\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 408us/step - loss: 0.4076\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.411 - 0s 401us/step - loss: 0.4145\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 401us/step - loss: 0.4123\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 402us/step - loss: 0.4071\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 401us/step - loss: 0.4110\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4077\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 407us/step - loss: 0.4066\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.042591825736086886, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "996/996 [==============================] - 85s 85ms/step - loss: 0.3684\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3271\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3268\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3279\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3223\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3270\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3262\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3239\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3212\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 383us/step - loss: 0.3248\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3231\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3234\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3252\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 384us/step - loss: 0.3246\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3225\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3190\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 381us/step - loss: 0.3194\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 383us/step - loss: 0.3191\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 385us/step - loss: 0.3224\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3197\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.011368822703058612, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "334/334 [==============================] - 86s 256ms/step - loss: 1.1549\n",
      "Epoch 2/30\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.9519\n",
      "Epoch 3/30\n",
      "334/334 [==============================] - 0s 398us/step - loss: 0.7542\n",
      "Epoch 4/30\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.6205\n",
      "Epoch 5/30\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.6198 0s - loss: 0.675\n",
      "Epoch 6/30\n",
      "334/334 [==============================] - 0s 399us/step - loss: 0.5730\n",
      "Epoch 7/30\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5810\n",
      "Epoch 8/30\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5842\n",
      "Epoch 9/30\n",
      "334/334 [==============================] - 0s 398us/step - loss: 0.5734\n",
      "Epoch 10/30\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5516\n",
      "Epoch 11/30\n",
      "334/334 [==============================] - 0s 401us/step - loss: 0.5453\n",
      "Epoch 12/30\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5617\n",
      "Epoch 13/30\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5507\n",
      "Epoch 14/30\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5508\n",
      "Epoch 15/30\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5456\n",
      "Epoch 16/30\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5491\n",
      "Epoch 17/30\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5439\n",
      "Epoch 18/30\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5431\n",
      "Epoch 19/30\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5441\n",
      "Epoch 20/30\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5462\n",
      "Epoch 21/30\n",
      "334/334 [==============================] - 0s 400us/step - loss: 0.5458\n",
      "Epoch 22/30\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5433\n",
      "Epoch 23/30\n",
      "334/334 [==============================] - 0s 399us/step - loss: 0.5481\n",
      "Epoch 24/30\n",
      "334/334 [==============================] - 0s 398us/step - loss: 0.5442\n",
      "Epoch 25/30\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5433\n",
      "Epoch 26/30\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5440\n",
      "Epoch 27/30\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5435\n",
      "Epoch 28/30\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5421\n",
      "Epoch 29/30\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5434\n",
      "Epoch 30/30\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5463\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.07506810875233971, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "665/665 [==============================] - 85s 128ms/step - loss: 0.6931\n",
      "Epoch 2/30\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.5009\n",
      "Epoch 3/30\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4615\n",
      "Epoch 4/30\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4367\n",
      "Epoch 5/30\n",
      "665/665 [==============================] - 0s 407us/step - loss: 0.4546\n",
      "Epoch 6/30\n",
      "665/665 [==============================] - 0s 407us/step - loss: 0.4197\n",
      "Epoch 7/30\n",
      "665/665 [==============================] - 0s 408us/step - loss: 0.4169\n",
      "Epoch 8/30\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4177\n",
      "Epoch 9/30\n",
      "665/665 [==============================] - 0s 400us/step - loss: 0.4102\n",
      "Epoch 10/30\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4076\n",
      "Epoch 11/30\n",
      "665/665 [==============================] - 0s 408us/step - loss: 0.4062\n",
      "Epoch 12/30\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4037\n",
      "Epoch 13/30\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4033\n",
      "Epoch 14/30\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4014\n",
      "Epoch 15/30\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4023\n",
      "Epoch 16/30\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4026\n",
      "Epoch 17/30\n",
      "665/665 [==============================] - 0s 408us/step - loss: 0.4042\n",
      "Epoch 18/30\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4038\n",
      "Epoch 19/30\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4030\n",
      "Epoch 20/30\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4011\n",
      "Epoch 21/30\n",
      "665/665 [==============================] - 0s 403us/step - loss: 0.4011\n",
      "Epoch 22/30\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4005\n",
      "Epoch 23/30\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4002\n",
      "Epoch 24/30\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4005\n",
      "Epoch 25/30\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.4005\n",
      "Epoch 26/30\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.3994\n",
      "Epoch 27/30\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.3991\n",
      "Epoch 28/30\n",
      "665/665 [==============================] - 0s 403us/step - loss: 0.3983\n",
      "Epoch 29/30\n",
      "665/665 [==============================] - 0s 401us/step - loss: 0.4016\n",
      "Epoch 30/30\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.3989\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.00028999801208273723, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "996/996 [==============================] - 83s 83ms/step - loss: 0.4754\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3559\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 0s 385us/step - loss: 0.3435\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3340\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3341\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3190\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3254\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3203\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 0s 385us/step - loss: 0.3250\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3195\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3211\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3188\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3186\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 0s 385us/step - loss: 0.3191\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3184\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3158\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3156\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3190\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 0s 382us/step - loss: 0.3171\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3184\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3182\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3197\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3227\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3208\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3173\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3193\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3204\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3167\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3169\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 0s 384us/step - loss: 0.3169\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.004021649475896005, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "334/334 [==============================] - 90s 269ms/step - loss: 57.1291\n",
      "Epoch 2/30\n",
      "334/334 [==============================] - 0s 409us/step - loss: 25.4819\n",
      "Epoch 3/30\n",
      "334/334 [==============================] - 0s 402us/step - loss: 11.4101\n",
      "Epoch 4/30\n",
      "334/334 [==============================] - 0s 407us/step - loss: 4.6469\n",
      "Epoch 5/30\n",
      "334/334 [==============================] - 0s 453us/step - loss: 3.2769\n",
      "Epoch 6/30\n",
      "334/334 [==============================] - 0s 415us/step - loss: 3.7415\n",
      "Epoch 7/30\n",
      "334/334 [==============================] - ETA: 0s - loss: 2.586 - 0s 409us/step - loss: 2.1254\n",
      "Epoch 8/30\n",
      "334/334 [==============================] - 0s 410us/step - loss: 2.2021\n",
      "Epoch 9/30\n",
      "334/334 [==============================] - 0s 402us/step - loss: 1.1945\n",
      "Epoch 10/30\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.8452\n",
      "Epoch 11/30\n",
      "334/334 [==============================] - 0s 403us/step - loss: 0.6880\n",
      "Epoch 12/30\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.6207\n",
      "Epoch 13/30\n",
      "334/334 [==============================] - 0s 403us/step - loss: 0.5958\n",
      "Epoch 14/30\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.6142\n",
      "Epoch 15/30\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5665\n",
      "Epoch 16/30\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5546\n",
      "Epoch 17/30\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5535\n",
      "Epoch 18/30\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5483\n",
      "Epoch 19/30\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5521\n",
      "Epoch 20/30\n",
      "334/334 [==============================] - 0s 401us/step - loss: 0.5598\n",
      "Epoch 21/30\n",
      "334/334 [==============================] - 0s 403us/step - loss: 0.5549\n",
      "Epoch 22/30\n",
      "334/334 [==============================] - 0s 428us/step - loss: 0.5666\n",
      "Epoch 23/30\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.566 - 0s 415us/step - loss: 0.5494\n",
      "Epoch 24/30\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5487\n",
      "Epoch 25/30\n",
      "334/334 [==============================] - 0s 397us/step - loss: 0.5433\n",
      "Epoch 26/30\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5542\n",
      "Epoch 27/30\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5530\n",
      "Epoch 28/30\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5461\n",
      "Epoch 29/30\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5498\n",
      "Epoch 30/30\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5487\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0745069480065077, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "665/665 [==============================] - 85s 128ms/step - loss: 20.8061\n",
      "Epoch 2/30\n",
      "665/665 [==============================] - 0s 410us/step - loss: 10.5761\n",
      "Epoch 3/30\n",
      "665/665 [==============================] - 0s 407us/step - loss: 3.8097\n",
      "Epoch 4/30\n",
      "665/665 [==============================] - 0s 408us/step - loss: 1.0606\n",
      "Epoch 5/30\n",
      "665/665 [==============================] - 0s 441us/step - loss: 0.5481\n",
      "Epoch 6/30\n",
      "665/665 [==============================] - 0s 437us/step - loss: 0.5040\n",
      "Epoch 7/30\n",
      "665/665 [==============================] - 0s 403us/step - loss: 0.4291\n",
      "Epoch 8/30\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4123\n",
      "Epoch 9/30\n",
      "665/665 [==============================] - 0s 402us/step - loss: 0.4130\n",
      "Epoch 10/30\n",
      "665/665 [==============================] - 0s 407us/step - loss: 0.4274\n",
      "Epoch 11/30\n",
      "665/665 [==============================] - 0s 408us/step - loss: 0.4220\n",
      "Epoch 12/30\n",
      "665/665 [==============================] - 0s 406us/step - loss: 0.4378\n",
      "Epoch 13/30\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4271\n",
      "Epoch 14/30\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4298\n",
      "Epoch 15/30\n",
      "665/665 [==============================] - 0s 407us/step - loss: 0.4206\n",
      "Epoch 16/30\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4143\n",
      "Epoch 17/30\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4088\n",
      "Epoch 18/30\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4343\n",
      "Epoch 19/30\n",
      "665/665 [==============================] - 0s 407us/step - loss: 0.4115\n",
      "Epoch 20/30\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4098\n",
      "Epoch 21/30\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4144\n",
      "Epoch 22/30\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4118\n",
      "Epoch 23/30\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4272\n",
      "Epoch 24/30\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4161\n",
      "Epoch 25/30\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4130\n",
      "Epoch 26/30\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.4171\n",
      "Epoch 27/30\n",
      "665/665 [==============================] - 0s 403us/step - loss: 0.4117\n",
      "Epoch 28/30\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4021\n",
      "Epoch 29/30\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4168\n",
      "Epoch 30/30\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4085\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.016176381362872805, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 86s 87ms/step - loss: 16.5136\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 0s 404us/step - loss: 3.5018\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.8493\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.4207\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3768\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3534\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 0s 426us/step - loss: 0.3509\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3401\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3324\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3239\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3245\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3250\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3252\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3289\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3283\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3234\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3292\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3279\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3258\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3259\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3241\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3213\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3224\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3306\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3225\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3264\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3216\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3181\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3244\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3230\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.011888135684881007, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "334/334 [==============================] - 91s 271ms/step - loss: 0.9278\n",
      "Epoch 2/30\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.6239\n",
      "Epoch 3/30\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5915\n",
      "Epoch 4/30\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5658\n",
      "Epoch 5/30\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5533\n",
      "Epoch 6/30\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5471\n",
      "Epoch 7/30\n",
      "334/334 [==============================] - 0s 396us/step - loss: 0.5470\n",
      "Epoch 8/30\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5515\n",
      "Epoch 9/30\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5455\n",
      "Epoch 10/30\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5496\n",
      "Epoch 11/30\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5511\n",
      "Epoch 12/30\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5541\n",
      "Epoch 13/30\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5489\n",
      "Epoch 14/30\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5532\n",
      "Epoch 15/30\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5446\n",
      "Epoch 16/30\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5517\n",
      "Epoch 17/30\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5526\n",
      "Epoch 18/30\n",
      "334/334 [==============================] - 0s 401us/step - loss: 0.5570\n",
      "Epoch 19/30\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5495\n",
      "Epoch 20/30\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5483\n",
      "Epoch 21/30\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5594\n",
      "Epoch 22/30\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5457\n",
      "Epoch 23/30\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5500\n",
      "Epoch 24/30\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5452\n",
      "Epoch 25/30\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5496\n",
      "Epoch 26/30\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5482\n",
      "Epoch 27/30\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5520\n",
      "Epoch 28/30\n",
      "334/334 [==============================] - 0s 425us/step - loss: 0.5457\n",
      "Epoch 29/30\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5476\n",
      "Epoch 30/30\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5499\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.06642723488518931, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "665/665 [==============================] - 89s 134ms/step - loss: 0.4914\n",
      "Epoch 2/30\n",
      "665/665 [==============================] - 0s 494us/step - loss: 0.4332\n",
      "Epoch 3/30\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4272\n",
      "Epoch 4/30\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.4166\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 405us/step - loss: 0.4114\n",
      "Epoch 6/30\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4200\n",
      "Epoch 7/30\n",
      "665/665 [==============================] - 0s 407us/step - loss: 0.4127\n",
      "Epoch 8/30\n",
      "665/665 [==============================] - 0s 399us/step - loss: 0.4293\n",
      "Epoch 9/30\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4244\n",
      "Epoch 10/30\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4162\n",
      "Epoch 11/30\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4206\n",
      "Epoch 12/30\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4126\n",
      "Epoch 13/30\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4154\n",
      "Epoch 14/30\n",
      "665/665 [==============================] - 0s 401us/step - loss: 0.4072\n",
      "Epoch 15/30\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4075\n",
      "Epoch 16/30\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4099\n",
      "Epoch 17/30\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4106\n",
      "Epoch 18/30\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4127\n",
      "Epoch 19/30\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4078\n",
      "Epoch 20/30\n",
      "665/665 [==============================] - 0s 407us/step - loss: 0.4089\n",
      "Epoch 21/30\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4091\n",
      "Epoch 22/30\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4086\n",
      "Epoch 23/30\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4093\n",
      "Epoch 24/30\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4093\n",
      "Epoch 25/30\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4150\n",
      "Epoch 26/30\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.4112\n",
      "Epoch 27/30\n",
      "665/665 [==============================] - 0s 408us/step - loss: 0.4094\n",
      "Epoch 28/30\n",
      "665/665 [==============================] - 0s 403us/step - loss: 0.4096\n",
      "Epoch 29/30\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.4103\n",
      "Epoch 30/30\n",
      "665/665 [==============================] - 0s 406us/step - loss: 0.4071\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.013819918865641379, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 87s 87ms/step - loss: 0.3893\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3444\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3283\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3293\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 0s 383us/step - loss: 0.3254\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3186\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3351\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3269\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3326\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3290\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 0s 383us/step - loss: 0.3305\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3238\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3290 0s - loss: 0.\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3264\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3211\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3206\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3288\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3232\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3219\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3213\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3201\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3190\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3201\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3188\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3200\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3204\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3195\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3214\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3202\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3191\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.00893281117925615, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "334/334 [==============================] - 85s 255ms/step - loss: 0.9552\n",
      "Epoch 2/40\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.8437\n",
      "Epoch 3/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.7833\n",
      "Epoch 4/40\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.7116\n",
      "Epoch 5/40\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.6523\n",
      "Epoch 6/40\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.6215\n",
      "Epoch 7/40\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5806\n",
      "Epoch 8/40\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5665\n",
      "Epoch 9/40\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5536\n",
      "Epoch 10/40\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5518\n",
      "Epoch 11/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5582\n",
      "Epoch 12/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5557\n",
      "Epoch 13/40\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5533\n",
      "Epoch 14/40\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5566\n",
      "Epoch 15/40\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5487\n",
      "Epoch 16/40\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5520\n",
      "Epoch 17/40\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5453\n",
      "Epoch 18/40\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5470\n",
      "Epoch 19/40\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5451\n",
      "Epoch 20/40\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5485\n",
      "Epoch 21/40\n",
      "334/334 [==============================] - 0s 399us/step - loss: 0.5532\n",
      "Epoch 22/40\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5460\n",
      "Epoch 23/40\n",
      "334/334 [==============================] - 0s 398us/step - loss: 0.5454\n",
      "Epoch 24/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5434\n",
      "Epoch 25/40\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5437\n",
      "Epoch 26/40\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5433\n",
      "Epoch 27/40\n",
      "334/334 [==============================] - 0s 398us/step - loss: 0.5465\n",
      "Epoch 28/40\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5462\n",
      "Epoch 29/40\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5447\n",
      "Epoch 30/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5428\n",
      "Epoch 31/40\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5453\n",
      "Epoch 32/40\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5444\n",
      "Epoch 33/40\n",
      "334/334 [==============================] - 0s 403us/step - loss: 0.5421\n",
      "Epoch 34/40\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5444\n",
      "Epoch 35/40\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.616 - 0s 419us/step - loss: 0.5426\n",
      "Epoch 36/40\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5437\n",
      "Epoch 37/40\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5398\n",
      "Epoch 38/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5409\n",
      "Epoch 39/40\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5405\n",
      "Epoch 40/40\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5428\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.06890504717551704, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "665/665 [==============================] - 86s 130ms/step - loss: 0.6984\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.5204\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4408\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 0s 406us/step - loss: 0.4299\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4232\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4262\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4205\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4083\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 0s 405us/step - loss: 0.4038\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4073\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4082\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4047\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 0s 404us/step - loss: 0.4020\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4043\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4043\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4030\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4043\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4018\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4050\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4019\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4021\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4021\n",
      "Epoch 23/40\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4034\n",
      "Epoch 24/40\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4037\n",
      "Epoch 25/40\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4056 0s - loss: 0.39\n",
      "Epoch 26/40\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4071\n",
      "Epoch 27/40\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4016\n",
      "Epoch 28/40\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4042\n",
      "Epoch 29/40\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4032\n",
      "Epoch 30/40\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.4000\n",
      "Epoch 31/40\n",
      "665/665 [==============================] - 0s 406us/step - loss: 0.4024\n",
      "Epoch 32/40\n",
      "665/665 [==============================] - 0s 408us/step - loss: 0.4009\n",
      "Epoch 33/40\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4031\n",
      "Epoch 34/40\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4020\n",
      "Epoch 35/40\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4044\n",
      "Epoch 36/40\n",
      "665/665 [==============================] - 0s 440us/step - loss: 0.4018\n",
      "Epoch 37/40\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4046\n",
      "Epoch 38/40\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4013\n",
      "Epoch 39/40\n",
      "665/665 [==============================] - 0s 465us/step - loss: 0.4016\n",
      "Epoch 40/40\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.3993\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.007487720306994294, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "996/996 [==============================] - 85s 86ms/step - loss: 0.4948\n",
      "Epoch 2/40\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3503\n",
      "Epoch 3/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3358\n",
      "Epoch 4/40\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3333\n",
      "Epoch 5/40\n",
      "996/996 [==============================] - 0s 431us/step - loss: 0.3322\n",
      "Epoch 6/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3286\n",
      "Epoch 7/40\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3206\n",
      "Epoch 8/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3251\n",
      "Epoch 9/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3193\n",
      "Epoch 10/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3196\n",
      "Epoch 11/40\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3190\n",
      "Epoch 12/40\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3194\n",
      "Epoch 13/40\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3210\n",
      "Epoch 14/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3207\n",
      "Epoch 15/40\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3207\n",
      "Epoch 16/40\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3175\n",
      "Epoch 17/40\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3164\n",
      "Epoch 18/40\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3173\n",
      "Epoch 19/40\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3160\n",
      "Epoch 20/40\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3155\n",
      "Epoch 21/40\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3166\n",
      "Epoch 22/40\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3152\n",
      "Epoch 23/40\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3156\n",
      "Epoch 24/40\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3147\n",
      "Epoch 25/40\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3153\n",
      "Epoch 26/40\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3163\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 389us/step - loss: 0.3151\n",
      "Epoch 28/40\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3183\n",
      "Epoch 29/40\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3189\n",
      "Epoch 30/40\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3149\n",
      "Epoch 31/40\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3164\n",
      "Epoch 32/40\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3218\n",
      "Epoch 33/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3180\n",
      "Epoch 34/40\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3190\n",
      "Epoch 35/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3209\n",
      "Epoch 36/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3159\n",
      "Epoch 37/40\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3156\n",
      "Epoch 38/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3215\n",
      "Epoch 39/40\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3168\n",
      "Epoch 40/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3159\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.01735097811250963, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "334/334 [==============================] - 95s 285ms/step - loss: 89.3202\n",
      "Epoch 2/40\n",
      "334/334 [==============================] - 0s 410us/step - loss: 54.3473\n",
      "Epoch 3/40\n",
      "334/334 [==============================] - 0s 420us/step - loss: 23.6568\n",
      "Epoch 4/40\n",
      "334/334 [==============================] - 0s 401us/step - loss: 17.0348\n",
      "Epoch 5/40\n",
      "334/334 [==============================] - 0s 402us/step - loss: 8.8225\n",
      "Epoch 6/40\n",
      "334/334 [==============================] - 0s 415us/step - loss: 4.9246\n",
      "Epoch 7/40\n",
      "334/334 [==============================] - 0s 407us/step - loss: 2.5888\n",
      "Epoch 8/40\n",
      "334/334 [==============================] - 0s 411us/step - loss: 1.6553\n",
      "Epoch 9/40\n",
      "334/334 [==============================] - 0s 408us/step - loss: 1.1059\n",
      "Epoch 10/40\n",
      "334/334 [==============================] - 0s 403us/step - loss: 0.7814\n",
      "Epoch 11/40\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.6214\n",
      "Epoch 12/40\n",
      "334/334 [==============================] - 0s 401us/step - loss: 0.5843\n",
      "Epoch 13/40\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5725\n",
      "Epoch 14/40\n",
      "334/334 [==============================] - 0s 403us/step - loss: 0.5694\n",
      "Epoch 15/40\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5738\n",
      "Epoch 16/40\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5530\n",
      "Epoch 17/40\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5508\n",
      "Epoch 18/40\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5497\n",
      "Epoch 19/40\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5495\n",
      "Epoch 20/40\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5492\n",
      "Epoch 21/40\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5567\n",
      "Epoch 22/40\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5503\n",
      "Epoch 23/40\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5406\n",
      "Epoch 24/40\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5462\n",
      "Epoch 25/40\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5561\n",
      "Epoch 26/40\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5455\n",
      "Epoch 27/40\n",
      "334/334 [==============================] - 0s 400us/step - loss: 0.5445\n",
      "Epoch 28/40\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5440\n",
      "Epoch 29/40\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5450\n",
      "Epoch 30/40\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5421\n",
      "Epoch 31/40\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5435\n",
      "Epoch 32/40\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5467\n",
      "Epoch 33/40\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5403\n",
      "Epoch 34/40\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5560\n",
      "Epoch 35/40\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5609\n",
      "Epoch 36/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5483\n",
      "Epoch 37/40\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5499\n",
      "Epoch 38/40\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5458\n",
      "Epoch 39/40\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5463\n",
      "Epoch 40/40\n",
      "334/334 [==============================] - 0s 397us/step - loss: 0.5437\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.03329286193751502, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "665/665 [==============================] - 106s 160ms/step - loss: 29.4565\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 0s 424us/step - loss: 7.2500\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 0s 441us/step - loss: 1.9463\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 0s 432us/step - loss: 1.3217\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.5720\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 0s 443us/step - loss: 0.5101\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4286\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4250\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4128\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 0s 436us/step - loss: 0.4092\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4075\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4072\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4105\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 0s 406us/step - loss: 0.4159\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4049\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4108\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4105 0s - loss: 0.37\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4290\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4120\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4098\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 0s 429us/step - loss: 0.4121\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 0s 429us/step - loss: 0.4110\n",
      "Epoch 23/40\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4053\n",
      "Epoch 24/40\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4070\n",
      "Epoch 25/40\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4070\n",
      "Epoch 26/40\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4047\n",
      "Epoch 27/40\n",
      "665/665 [==============================] - 0s 437us/step - loss: 0.4086\n",
      "Epoch 28/40\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4036\n",
      "Epoch 29/40\n",
      "665/665 [==============================] - 0s 429us/step - loss: 0.4050\n",
      "Epoch 30/40\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4039\n",
      "Epoch 31/40\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4112\n",
      "Epoch 32/40\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4108\n",
      "Epoch 33/40\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4109\n",
      "Epoch 34/40\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4064\n",
      "Epoch 35/40\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4045\n",
      "Epoch 36/40\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4072\n",
      "Epoch 37/40\n",
      "665/665 [==============================] - 0s 433us/step - loss: 0.4192\n",
      "Epoch 38/40\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4149\n",
      "Epoch 39/40\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4064\n",
      "Epoch 40/40\n",
      "665/665 [==============================] - 0s 451us/step - loss: 0.4052\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.029413831462869355, total= 3.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "996/996 [==============================] - 97s 98ms/step - loss: 24.2824\n",
      "Epoch 2/40\n",
      "996/996 [==============================] - 0s 394us/step - loss: 6.5964\n",
      "Epoch 3/40\n",
      "996/996 [==============================] - 0s 390us/step - loss: 1.1362\n",
      "Epoch 4/40\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.4351\n",
      "Epoch 5/40\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3317\n",
      "Epoch 6/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3438\n",
      "Epoch 7/40\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3303\n",
      "Epoch 8/40\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3241\n",
      "Epoch 9/40\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3230\n",
      "Epoch 10/40\n",
      "996/996 [==============================] - 0s 385us/step - loss: 0.3216\n",
      "Epoch 11/40\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3229\n",
      "Epoch 12/40\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3212\n",
      "Epoch 13/40\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3270\n",
      "Epoch 14/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3283\n",
      "Epoch 15/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3194\n",
      "Epoch 16/40\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3179\n",
      "Epoch 17/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3231\n",
      "Epoch 18/40\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3247\n",
      "Epoch 19/40\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3202\n",
      "Epoch 20/40\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3250\n",
      "Epoch 21/40\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3216\n",
      "Epoch 22/40\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3201\n",
      "Epoch 23/40\n",
      "996/996 [==============================] - 0s 388us/step - loss: 0.3194\n",
      "Epoch 24/40\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3193\n",
      "Epoch 25/40\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3193\n",
      "Epoch 26/40\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3199\n",
      "Epoch 27/40\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3173\n",
      "Epoch 28/40\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3205\n",
      "Epoch 29/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3205\n",
      "Epoch 30/40\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3250\n",
      "Epoch 31/40\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3201\n",
      "Epoch 32/40\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3166\n",
      "Epoch 33/40\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3250\n",
      "Epoch 34/40\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3190\n",
      "Epoch 35/40\n",
      "996/996 [==============================] - 0s 389us/step - loss: 0.3268\n",
      "Epoch 36/40\n",
      "996/996 [==============================] - 0s 386us/step - loss: 0.3197\n",
      "Epoch 37/40\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3234\n",
      "Epoch 38/40\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3208\n",
      "Epoch 39/40\n",
      "996/996 [==============================] - 0s 387us/step - loss: 0.3185\n",
      "Epoch 40/40\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3189\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0046473000497837536, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "334/334 [==============================] - 96s 287ms/step - loss: 0.7193\n",
      "Epoch 2/40\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5982\n",
      "Epoch 3/40\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5798\n",
      "Epoch 4/40\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5633\n",
      "Epoch 5/40\n",
      "334/334 [==============================] - 0s 400us/step - loss: 0.5625\n",
      "Epoch 6/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5570\n",
      "Epoch 7/40\n",
      "334/334 [==============================] - 0s 436us/step - loss: 0.5569\n",
      "Epoch 8/40\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5517\n",
      "Epoch 9/40\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5509\n",
      "Epoch 10/40\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5484\n",
      "Epoch 11/40\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5500\n",
      "Epoch 12/40\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5535\n",
      "Epoch 13/40\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5537\n",
      "Epoch 14/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5490\n",
      "Epoch 15/40\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5571\n",
      "Epoch 16/40\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5485\n",
      "Epoch 17/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5451\n",
      "Epoch 18/40\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5493\n",
      "Epoch 19/40\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5484\n",
      "Epoch 20/40\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5443\n",
      "Epoch 21/40\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5581\n",
      "Epoch 22/40\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5465\n",
      "Epoch 23/40\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5493\n",
      "Epoch 24/40\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5488\n",
      "Epoch 25/40\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5485\n",
      "Epoch 26/40\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5673\n",
      "Epoch 27/40\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5609\n",
      "Epoch 28/40\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5545\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 404us/step - loss: 0.5553\n",
      "Epoch 30/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5478\n",
      "Epoch 31/40\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5508\n",
      "Epoch 32/40\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5476\n",
      "Epoch 33/40\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5484\n",
      "Epoch 34/40\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5490\n",
      "Epoch 35/40\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5504\n",
      "Epoch 36/40\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5483\n",
      "Epoch 37/40\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5520\n",
      "Epoch 38/40\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5496\n",
      "Epoch 39/40\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5489\n",
      "Epoch 40/40\n",
      "334/334 [==============================] - 0s 401us/step - loss: 0.5482\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.08264389197506827, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "665/665 [==============================] - 90s 135ms/step - loss: 0.5344\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4278\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4134\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4139\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4117\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4086\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4116\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4121\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4089\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4053\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4147\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4104\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4119\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4073\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4098\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4114\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 0s 438us/step - loss: 0.4086\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4094\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 0s 450us/step - loss: 0.4099\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 0s 437us/step - loss: 0.4091\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4032\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4059\n",
      "Epoch 23/40\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4072\n",
      "Epoch 24/40\n",
      "665/665 [==============================] - 0s 431us/step - loss: 0.4091\n",
      "Epoch 25/40\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4106\n",
      "Epoch 26/40\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4099\n",
      "Epoch 27/40\n",
      "665/665 [==============================] - 0s 447us/step - loss: 0.4063\n",
      "Epoch 28/40\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4100\n",
      "Epoch 29/40\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4074\n",
      "Epoch 30/40\n",
      "665/665 [==============================] - 0s 446us/step - loss: 0.4066\n",
      "Epoch 31/40\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4045\n",
      "Epoch 32/40\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4082\n",
      "Epoch 33/40\n",
      "665/665 [==============================] - 0s 434us/step - loss: 0.4054\n",
      "Epoch 34/40\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4079\n",
      "Epoch 35/40\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4054\n",
      "Epoch 36/40\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4071\n",
      "Epoch 37/40\n",
      "665/665 [==============================] - 0s 459us/step - loss: 0.4022\n",
      "Epoch 38/40\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4023\n",
      "Epoch 39/40\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4029\n",
      "Epoch 40/40\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4044\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.00814123756300189, total= 2.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "996/996 [==============================] - 98s 99ms/step - loss: 0.3976\n",
      "Epoch 2/40\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3360\n",
      "Epoch 3/40\n",
      "996/996 [==============================] - 0s 391us/step - loss: 0.3316\n",
      "Epoch 4/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3336\n",
      "Epoch 5/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3285\n",
      "Epoch 6/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3212\n",
      "Epoch 7/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3293\n",
      "Epoch 8/40\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3233\n",
      "Epoch 9/40\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3240\n",
      "Epoch 10/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3268\n",
      "Epoch 11/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3246\n",
      "Epoch 12/40\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3222\n",
      "Epoch 13/40\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3259\n",
      "Epoch 14/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3272\n",
      "Epoch 15/40\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3223\n",
      "Epoch 16/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3227\n",
      "Epoch 17/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3207\n",
      "Epoch 18/40\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3217\n",
      "Epoch 19/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3243\n",
      "Epoch 20/40\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3206\n",
      "Epoch 21/40\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3233\n",
      "Epoch 22/40\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3242\n",
      "Epoch 23/40\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3200\n",
      "Epoch 24/40\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3206\n",
      "Epoch 25/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3206\n",
      "Epoch 26/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3212\n",
      "Epoch 27/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3170\n",
      "Epoch 28/40\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3194\n",
      "Epoch 29/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3177\n",
      "Epoch 30/40\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3196\n",
      "Epoch 31/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3199\n",
      "Epoch 32/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3226\n",
      "Epoch 33/40\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3196\n",
      "Epoch 34/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3189\n",
      "Epoch 35/40\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3176\n",
      "Epoch 36/40\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3176\n",
      "Epoch 37/40\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3199\n",
      "Epoch 38/40\n",
      "996/996 [==============================] - 0s 390us/step - loss: 0.3208\n",
      "Epoch 39/40\n",
      "996/996 [==============================] - 0s 392us/step - loss: 0.3174\n",
      "Epoch 40/40\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3171\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.010511147705866364, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "334/334 [==============================] - 97s 291ms/step - loss: 1.4030\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.8297\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 0s 555us/step - loss: 0.6616\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 0s 451us/step - loss: 0.6147\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5657\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5672\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5669\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5590\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5540\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5515\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5472 0s - loss: 0.586\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5561\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5512\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5546\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5572\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5494\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5552\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5556\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5538\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5450\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5468\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5445\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5442\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5446\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5447\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5466\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5454\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5442\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5468\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5428\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5447\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5480\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5402\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5434\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5423\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5442 0s - loss: 0.532\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5442\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 0s 402us/step - loss: 0.5412\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5433\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5402\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5405\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5411\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5421\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5404\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 0s 401us/step - loss: 0.5413\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5420\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5421\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5398\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5437\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 0s 430us/step - loss: 0.5394\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.04640340419644362, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "665/665 [==============================] - 88s 133ms/step - loss: 0.6315\n",
      "Epoch 2/50\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4947\n",
      "Epoch 3/50\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4534\n",
      "Epoch 4/50\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4378\n",
      "Epoch 5/50\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4329\n",
      "Epoch 6/50\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4196\n",
      "Epoch 7/50\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4113\n",
      "Epoch 8/50\n",
      "665/665 [==============================] - 0s 455us/step - loss: 0.4173\n",
      "Epoch 9/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4090\n",
      "Epoch 10/50\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4079\n",
      "Epoch 11/50\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4120\n",
      "Epoch 12/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4044\n",
      "Epoch 13/50\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4064\n",
      "Epoch 14/50\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4061\n",
      "Epoch 15/50\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4067\n",
      "Epoch 16/50\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4029\n",
      "Epoch 17/50\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4054\n",
      "Epoch 18/50\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4054\n",
      "Epoch 19/50\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4029\n",
      "Epoch 20/50\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4046\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 419us/step - loss: 0.4038\n",
      "Epoch 22/50\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4034\n",
      "Epoch 23/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4075\n",
      "Epoch 24/50\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.4011\n",
      "Epoch 25/50\n",
      "665/665 [==============================] - 0s 452us/step - loss: 0.4007\n",
      "Epoch 26/50\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4029\n",
      "Epoch 27/50\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4033\n",
      "Epoch 28/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.3998\n",
      "Epoch 29/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4004\n",
      "Epoch 30/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4008\n",
      "Epoch 31/50\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4016\n",
      "Epoch 32/50\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4010\n",
      "Epoch 33/50\n",
      "665/665 [==============================] - 0s 443us/step - loss: 0.3995\n",
      "Epoch 34/50\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.3994\n",
      "Epoch 35/50\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4019\n",
      "Epoch 36/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4009\n",
      "Epoch 37/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.3989\n",
      "Epoch 38/50\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.3997\n",
      "Epoch 39/50\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.3994\n",
      "Epoch 40/50\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.3984\n",
      "Epoch 41/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4016\n",
      "Epoch 42/50\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4008\n",
      "Epoch 43/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4001\n",
      "Epoch 44/50\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4008\n",
      "Epoch 45/50\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4039\n",
      "Epoch 46/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.3998\n",
      "Epoch 47/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4005\n",
      "Epoch 48/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.3996\n",
      "Epoch 49/50\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4005\n",
      "Epoch 50/50\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.3996\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.001430171170237693, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "996/996 [==============================] - 90s 91ms/step - loss: 0.4902\n",
      "Epoch 2/50\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3530\n",
      "Epoch 3/50\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3318\n",
      "Epoch 4/50\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3328\n",
      "Epoch 5/50\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3237\n",
      "Epoch 6/50\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3207\n",
      "Epoch 7/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3209\n",
      "Epoch 8/50\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3204\n",
      "Epoch 9/50\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3199\n",
      "Epoch 10/50\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3188\n",
      "Epoch 11/50\n",
      "996/996 [==============================] - 0s 414us/step - loss: 0.3210\n",
      "Epoch 12/50\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3238\n",
      "Epoch 13/50\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3199\n",
      "Epoch 14/50\n",
      "996/996 [==============================] - 0s 416us/step - loss: 0.3242\n",
      "Epoch 15/50\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3177\n",
      "Epoch 16/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3169\n",
      "Epoch 17/50\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3189\n",
      "Epoch 18/50\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3185\n",
      "Epoch 19/50\n",
      "996/996 [==============================] - 0s 430us/step - loss: 0.3174\n",
      "Epoch 20/50\n",
      "996/996 [==============================] - 0s 429us/step - loss: 0.3208\n",
      "Epoch 21/50\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3168\n",
      "Epoch 22/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3172\n",
      "Epoch 23/50\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3188\n",
      "Epoch 24/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3201\n",
      "Epoch 25/50\n",
      "996/996 [==============================] - 0s 445us/step - loss: 0.3218\n",
      "Epoch 26/50\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3178\n",
      "Epoch 27/50\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3185\n",
      "Epoch 28/50\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3161\n",
      "Epoch 29/50\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3180\n",
      "Epoch 30/50\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3199\n",
      "Epoch 31/50\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3196\n",
      "Epoch 32/50\n",
      "996/996 [==============================] - 0s 444us/step - loss: 0.3177\n",
      "Epoch 33/50\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3184\n",
      "Epoch 34/50\n",
      "996/996 [==============================] - 0s 415us/step - loss: 0.3137\n",
      "Epoch 35/50\n",
      "996/996 [==============================] - 0s 411us/step - loss: 0.3167\n",
      "Epoch 36/50\n",
      "996/996 [==============================] - 0s 413us/step - loss: 0.3175\n",
      "Epoch 37/50\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3159\n",
      "Epoch 38/50\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3179\n",
      "Epoch 39/50\n",
      "996/996 [==============================] - 0s 415us/step - loss: 0.3144\n",
      "Epoch 40/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3157\n",
      "Epoch 41/50\n",
      "996/996 [==============================] - 0s 414us/step - loss: 0.3162\n",
      "Epoch 42/50\n",
      "996/996 [==============================] - 0s 411us/step - loss: 0.3154\n",
      "Epoch 43/50\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3156\n",
      "Epoch 44/50\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3155\n",
      "Epoch 45/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3151\n",
      "Epoch 46/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3144\n",
      "Epoch 47/50\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3154\n",
      "Epoch 48/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3145\n",
      "Epoch 49/50\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3149\n",
      "Epoch 50/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3153\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.003316982089657472, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "334/334 [==============================] - 96s 288ms/step - loss: 50.0872\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 58.4888\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 0s 429us/step - loss: 23.6221\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 0s 408us/step - loss: 8.3140\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 0s 412us/step - loss: 10.4653\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 0s 481us/step - loss: 7.3152\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 0s 442us/step - loss: 3.3167\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 0s 427us/step - loss: 1.1405\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.9798\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 0s 410us/step - loss: 1.0206\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 0s 440us/step - loss: 0.8845\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.7320\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.6332\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.6439\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5844\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5892\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5562\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 0s 425us/step - loss: 0.5604\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5509\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5636\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 0s 435us/step - loss: 0.5584\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5708\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5583\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5873\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5883\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5517\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5581\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5616\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5505\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5520\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5472\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5526\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 0s 400us/step - loss: 0.5460\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5480\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5490\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5486\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5415\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5467\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5484\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5479\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5494\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5452\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5500 0s - loss: 0.633\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5440\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5420\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5470\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5456\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5437\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5424\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5424\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.06695041266720958, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "665/665 [==============================] - 95s 143ms/step - loss: 26.0215\n",
      "Epoch 2/50\n",
      "665/665 [==============================] - 0s 426us/step - loss: 7.7667\n",
      "Epoch 3/50\n",
      "665/665 [==============================] - 0s 419us/step - loss: 1.6423 0s - loss: 1.69\n",
      "Epoch 4/50\n",
      "665/665 [==============================] - 0s 420us/step - loss: 1.2399\n",
      "Epoch 5/50\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.6360\n",
      "Epoch 6/50\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.5217\n",
      "Epoch 7/50\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.5047\n",
      "Epoch 8/50\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4762\n",
      "Epoch 9/50\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4211\n",
      "Epoch 10/50\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4346\n",
      "Epoch 11/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4110\n",
      "Epoch 12/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4299\n",
      "Epoch 13/50\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4171\n",
      "Epoch 14/50\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4085\n",
      "Epoch 15/50\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4123\n",
      "Epoch 16/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4139\n",
      "Epoch 17/50\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4160\n",
      "Epoch 18/50\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4154\n",
      "Epoch 19/50\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4203\n",
      "Epoch 20/50\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4143\n",
      "Epoch 21/50\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4157\n",
      "Epoch 22/50\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4121\n",
      "Epoch 23/50\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4140\n",
      "Epoch 24/50\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4338\n",
      "Epoch 25/50\n",
      "665/665 [==============================] - 0s 440us/step - loss: 0.4160\n",
      "Epoch 26/50\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4076\n",
      "Epoch 27/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4165 0s - loss: 0.40\n",
      "Epoch 28/50\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4151\n",
      "Epoch 29/50\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4105\n",
      "Epoch 30/50\n",
      "665/665 [==============================] - 0s 431us/step - loss: 0.4125\n",
      "Epoch 31/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4240\n",
      "Epoch 32/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4070\n",
      "Epoch 33/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4093\n",
      "Epoch 34/50\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4069\n",
      "Epoch 35/50\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4110\n",
      "Epoch 36/50\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4138\n",
      "Epoch 37/50\n",
      "665/665 [==============================] - 0s 444us/step - loss: 0.4074\n",
      "Epoch 38/50\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4090\n",
      "Epoch 39/50\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4048\n",
      "Epoch 40/50\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4039\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 414us/step - loss: 0.4048\n",
      "Epoch 42/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4073\n",
      "Epoch 43/50\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4095\n",
      "Epoch 44/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4116\n",
      "Epoch 45/50\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4128\n",
      "Epoch 46/50\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4101\n",
      "Epoch 47/50\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4069\n",
      "Epoch 48/50\n",
      "665/665 [==============================] - 0s 475us/step - loss: 0.4111\n",
      "Epoch 49/50\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4076 0s - loss: 0.39\n",
      "Epoch 50/50\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4122\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.016536608964623056, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "996/996 [==============================] - 93s 94ms/step - loss: 24.1977\n",
      "Epoch 2/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 5.6383 0s - loss: 7.\n",
      "Epoch 3/50\n",
      "996/996 [==============================] - 0s 407us/step - loss: 1.0234\n",
      "Epoch 4/50\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3700\n",
      "Epoch 5/50\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3457\n",
      "Epoch 6/50\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3282\n",
      "Epoch 7/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3244\n",
      "Epoch 8/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3257\n",
      "Epoch 9/50\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3262\n",
      "Epoch 10/50\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3209\n",
      "Epoch 11/50\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3241\n",
      "Epoch 12/50\n",
      "996/996 [==============================] - 0s 433us/step - loss: 0.3251\n",
      "Epoch 13/50\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3231\n",
      "Epoch 14/50\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3160\n",
      "Epoch 15/50\n",
      "996/996 [==============================] - 0s 411us/step - loss: 0.3197\n",
      "Epoch 16/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3184\n",
      "Epoch 17/50\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3198\n",
      "Epoch 18/50\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3220\n",
      "Epoch 19/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3184\n",
      "Epoch 20/50\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3202\n",
      "Epoch 21/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3199\n",
      "Epoch 22/50\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3159\n",
      "Epoch 23/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3180\n",
      "Epoch 24/50\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3180\n",
      "Epoch 25/50\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3178\n",
      "Epoch 26/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3184\n",
      "Epoch 27/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3189\n",
      "Epoch 28/50\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3175\n",
      "Epoch 29/50\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3187\n",
      "Epoch 30/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3185\n",
      "Epoch 31/50\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3179\n",
      "Epoch 32/50\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3195\n",
      "Epoch 33/50\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3213\n",
      "Epoch 34/50\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3177\n",
      "Epoch 35/50\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3179\n",
      "Epoch 36/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3177\n",
      "Epoch 37/50\n",
      "996/996 [==============================] - ETA: 0s - loss: 0.315 - 0s 398us/step - loss: 0.3166\n",
      "Epoch 38/50\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3229\n",
      "Epoch 39/50\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3202\n",
      "Epoch 40/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3150\n",
      "Epoch 41/50\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3157\n",
      "Epoch 42/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3173\n",
      "Epoch 43/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3173\n",
      "Epoch 44/50\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3196\n",
      "Epoch 45/50\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3178\n",
      "Epoch 46/50\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3244\n",
      "Epoch 47/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3193\n",
      "Epoch 48/50\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3197\n",
      "Epoch 49/50\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3173\n",
      "Epoch 50/50\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3181\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.000945714996668845, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "334/334 [==============================] - 93s 279ms/step - loss: 0.7227\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.6033\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5708\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 0s 427us/step - loss: 0.5650\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5571\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5459\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5539\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5520\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5507\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5534\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 0s 429us/step - loss: 0.5487\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5536\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5508\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5466\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5461\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5446\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5453\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5504\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5542\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5611\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5564\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5536\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5448\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5474\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5496\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5472\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5477\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5550\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5458\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 0s 425us/step - loss: 0.5525\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5530\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5491\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5465\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5514\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5449\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5469\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5438\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5452\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5450\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5455\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5470\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5486\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 0s 430us/step - loss: 0.5486\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5501\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5460\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5432\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5470\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5438\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5455\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5463\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.07334576810119176, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "665/665 [==============================] - 97s 146ms/step - loss: 0.4898\n",
      "Epoch 2/50\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4375\n",
      "Epoch 3/50\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4292\n",
      "Epoch 4/50\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4168\n",
      "Epoch 5/50\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4189\n",
      "Epoch 6/50\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4153\n",
      "Epoch 7/50\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4115\n",
      "Epoch 8/50\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4232\n",
      "Epoch 9/50\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4098\n",
      "Epoch 10/50\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4135\n",
      "Epoch 11/50\n",
      "665/665 [==============================] - 0s 431us/step - loss: 0.4176\n",
      "Epoch 12/50\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4187\n",
      "Epoch 13/50\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4268\n",
      "Epoch 14/50\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4106\n",
      "Epoch 15/50\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4149\n",
      "Epoch 16/50\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.424 - 0s 423us/step - loss: 0.4199\n",
      "Epoch 17/50\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4210\n",
      "Epoch 18/50\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4081\n",
      "Epoch 19/50\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4105\n",
      "Epoch 20/50\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4144\n",
      "Epoch 21/50\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4128\n",
      "Epoch 22/50\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4088\n",
      "Epoch 23/50\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4113\n",
      "Epoch 24/50\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4157\n",
      "Epoch 25/50\n",
      "665/665 [==============================] - 0s 409us/step - loss: 0.4095\n",
      "Epoch 26/50\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4063\n",
      "Epoch 27/50\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4036\n",
      "Epoch 28/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4079\n",
      "Epoch 29/50\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4111\n",
      "Epoch 30/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4049\n",
      "Epoch 31/50\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4083\n",
      "Epoch 32/50\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4038\n",
      "Epoch 33/50\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4076\n",
      "Epoch 34/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4078\n",
      "Epoch 35/50\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4042\n",
      "Epoch 36/50\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4042\n",
      "Epoch 37/50\n",
      "665/665 [==============================] - 0s 438us/step - loss: 0.4122\n",
      "Epoch 38/50\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4047\n",
      "Epoch 39/50\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4094\n",
      "Epoch 40/50\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4090\n",
      "Epoch 41/50\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4099\n",
      "Epoch 42/50\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4014\n",
      "Epoch 43/50\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4059\n",
      "Epoch 44/50\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4043\n",
      "Epoch 45/50\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4024\n",
      "Epoch 46/50\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4040\n",
      "Epoch 47/50\n",
      "665/665 [==============================] - 0s 410us/step - loss: 0.4060\n",
      "Epoch 48/50\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4025\n",
      "Epoch 49/50\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4030\n",
      "Epoch 50/50\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4040\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0031251396499487605, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "996/996 [==============================] - 94s 95ms/step - loss: 0.3894\n",
      "Epoch 2/50\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3419\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 403us/step - loss: 0.3357\n",
      "Epoch 4/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3230\n",
      "Epoch 5/50\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3282\n",
      "Epoch 6/50\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3273\n",
      "Epoch 7/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3266\n",
      "Epoch 8/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3261\n",
      "Epoch 9/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3283\n",
      "Epoch 10/50\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3269\n",
      "Epoch 11/50\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3277\n",
      "Epoch 12/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3228\n",
      "Epoch 13/50\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3254\n",
      "Epoch 14/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3254\n",
      "Epoch 15/50\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3239\n",
      "Epoch 16/50\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3230\n",
      "Epoch 17/50\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3235\n",
      "Epoch 18/50\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3208\n",
      "Epoch 19/50\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3226\n",
      "Epoch 20/50\n",
      "996/996 [==============================] - 0s 393us/step - loss: 0.3223\n",
      "Epoch 21/50\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3208\n",
      "Epoch 22/50\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3182\n",
      "Epoch 23/50\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3188\n",
      "Epoch 24/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3200\n",
      "Epoch 25/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3193\n",
      "Epoch 26/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3189\n",
      "Epoch 27/50\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3195\n",
      "Epoch 28/50\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3281\n",
      "Epoch 29/50\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3200\n",
      "Epoch 30/50\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3191\n",
      "Epoch 31/50\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3163\n",
      "Epoch 32/50\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3173\n",
      "Epoch 33/50\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3189\n",
      "Epoch 34/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3215\n",
      "Epoch 35/50\n",
      "996/996 [==============================] - ETA: 0s - loss: 0.319 - 0s 401us/step - loss: 0.3175\n",
      "Epoch 36/50\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3172\n",
      "Epoch 37/50\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3217\n",
      "Epoch 38/50\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3161\n",
      "Epoch 39/50\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3186\n",
      "Epoch 40/50\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3170\n",
      "Epoch 41/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3153\n",
      "Epoch 42/50\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3177\n",
      "Epoch 43/50\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3173\n",
      "Epoch 44/50\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3172\n",
      "Epoch 45/50\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3165\n",
      "Epoch 46/50\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3207\n",
      "Epoch 47/50\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3163\n",
      "Epoch 48/50\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3182\n",
      "Epoch 49/50\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3143\n",
      "Epoch 50/50\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3162\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.004505426709608296, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 106s 317ms/step - loss: 1.1316\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 449us/step - loss: 0.6852\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 443us/step - loss: 0.6510\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 425us/step - loss: 0.6264\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5990\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 439us/step - loss: 0.5924\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 425us/step - loss: 0.5929\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5773\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 437us/step - loss: 0.5800\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 431us/step - loss: 0.5618\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 428us/step - loss: 0.5586\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5666\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5584\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 427us/step - loss: 0.5511\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5500\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5486\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5449\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5501\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5476\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5505\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5461\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 428us/step - loss: 0.5472\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5517\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5469\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5560\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 437us/step - loss: 0.5435\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5500\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5468\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5446\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5457\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5466\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5451\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 428us/step - loss: 0.5442\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5430\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5446\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5419\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5424\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5414\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5420\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5413\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5444\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 412us/step - loss: 0.5455\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5438\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.506 - 0s 418us/step - loss: 0.5432\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5427\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 403us/step - loss: 0.5434\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5469\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5417\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5395\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5429\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5456\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5421\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5420\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5400\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5494\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5404\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 427us/step - loss: 0.5425\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5419\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5408\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5421\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5428\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5406\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5413\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5399\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5413\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5407\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5411\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 453us/step - loss: 0.5414\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 491us/step - loss: 0.5402\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5390\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5396\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5407\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5425\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5408\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 433us/step - loss: 0.5421\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5418\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 404us/step - loss: 0.5400\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5411\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5388\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5401\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5403\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5419\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5408\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 407us/step - loss: 0.5382\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5437\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5401\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5422\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5408\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5414\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5443\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5418\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5394\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5415\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5409\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5411\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5403\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5387\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.544 - 0s 415us/step - loss: 0.5404\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5389\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5412\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.07221210992984695, total=11.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "665/665 [==============================] - 96s 145ms/step - loss: 0.6519\n",
      "Epoch 2/100\n",
      "665/665 [==============================] - 0s 468us/step - loss: 0.5492\n",
      "Epoch 3/100\n",
      "665/665 [==============================] - 0s 429us/step - loss: 0.4497\n",
      "Epoch 4/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4219\n",
      "Epoch 5/100\n",
      "665/665 [==============================] - 0s 431us/step - loss: 0.4100\n",
      "Epoch 6/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4139\n",
      "Epoch 7/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4120\n",
      "Epoch 8/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4117\n",
      "Epoch 9/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4117\n",
      "Epoch 10/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4149\n",
      "Epoch 11/100\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4042\n",
      "Epoch 12/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4042\n",
      "Epoch 13/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4026\n",
      "Epoch 14/100\n",
      "665/665 [==============================] - 0s 434us/step - loss: 0.4008\n",
      "Epoch 15/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4060\n",
      "Epoch 16/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4057\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4020\n",
      "Epoch 18/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4004\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4023\n",
      "Epoch 20/100\n",
      "665/665 [==============================] - 0s 453us/step - loss: 0.4002\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4028\n",
      "Epoch 22/100\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4026\n",
      "Epoch 23/100\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.4030\n",
      "Epoch 24/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4039\n",
      "Epoch 25/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4011\n",
      "Epoch 26/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4037\n",
      "Epoch 27/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4033\n",
      "Epoch 28/100\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4023\n",
      "Epoch 29/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4031\n",
      "Epoch 30/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4012\n",
      "Epoch 31/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4050\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4027\n",
      "Epoch 33/100\n",
      "665/665 [==============================] - 0s 414us/step - loss: 0.3999\n",
      "Epoch 34/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4019\n",
      "Epoch 35/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4001\n",
      "Epoch 36/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.3988\n",
      "Epoch 37/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.3995\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.3987\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4003\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - 0s 434us/step - loss: 0.3999\n",
      "Epoch 41/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4014\n",
      "Epoch 42/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.3999\n",
      "Epoch 43/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4007\n",
      "Epoch 44/100\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4007\n",
      "Epoch 45/100\n",
      "665/665 [==============================] - 0s 435us/step - loss: 0.4017\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.3999\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4004\n",
      "Epoch 48/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4030\n",
      "Epoch 49/100\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4002\n",
      "Epoch 50/100\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4005\n",
      "Epoch 51/100\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4077\n",
      "Epoch 52/100\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4021\n",
      "Epoch 53/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4027\n",
      "Epoch 54/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4075\n",
      "Epoch 55/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4123\n",
      "Epoch 56/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4063\n",
      "Epoch 57/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4044\n",
      "Epoch 58/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4026\n",
      "Epoch 59/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4078\n",
      "Epoch 60/100\n",
      "665/665 [==============================] - 0s 442us/step - loss: 0.4034\n",
      "Epoch 61/100\n",
      "665/665 [==============================] - 0s 449us/step - loss: 0.4055\n",
      "Epoch 62/100\n",
      "665/665 [==============================] - 0s 449us/step - loss: 0.4008\n",
      "Epoch 63/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4024\n",
      "Epoch 64/100\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4019\n",
      "Epoch 65/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4005\n",
      "Epoch 66/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4011\n",
      "Epoch 67/100\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.3999\n",
      "Epoch 68/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4031\n",
      "Epoch 69/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4026\n",
      "Epoch 70/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.3997\n",
      "Epoch 71/100\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4013\n",
      "Epoch 72/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4018\n",
      "Epoch 73/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4002\n",
      "Epoch 74/100\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4001\n",
      "Epoch 75/100\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4001\n",
      "Epoch 76/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4000\n",
      "Epoch 77/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.3990\n",
      "Epoch 78/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4003\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.3981\n",
      "Epoch 80/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.3981 0s - loss: 0.41\n",
      "Epoch 81/100\n",
      "665/665 [==============================] - 0s 411us/step - loss: 0.4071\n",
      "Epoch 82/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4094\n",
      "Epoch 83/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4149\n",
      "Epoch 84/100\n",
      "665/665 [==============================] - 0s 437us/step - loss: 0.4038\n",
      "Epoch 85/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4114\n",
      "Epoch 86/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4057\n",
      "Epoch 87/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4061\n",
      "Epoch 88/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4040\n",
      "Epoch 89/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4036\n",
      "Epoch 90/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4027\n",
      "Epoch 91/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4017\n",
      "Epoch 92/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4006\n",
      "Epoch 93/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4006\n",
      "Epoch 94/100\n",
      "665/665 [==============================] - 0s 429us/step - loss: 0.4000\n",
      "Epoch 95/100\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4006\n",
      "Epoch 96/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4008\n",
      "Epoch 97/100\n",
      "665/665 [==============================] - 0s 429us/step - loss: 0.4008\n",
      "Epoch 98/100\n",
      "665/665 [==============================] - 0s 431us/step - loss: 0.4045\n",
      "Epoch 99/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.3991\n",
      "Epoch 100/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.3994\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.006023083213838154, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "996/996 [==============================] - 96s 96ms/step - loss: 0.5083\n",
      "Epoch 2/100\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3527\n",
      "Epoch 3/100\n",
      "996/996 [==============================] - 0s 413us/step - loss: 0.3458\n",
      "Epoch 4/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3314\n",
      "Epoch 5/100\n",
      "996/996 [==============================] - 0s 416us/step - loss: 0.3278\n",
      "Epoch 6/100\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3250\n",
      "Epoch 7/100\n",
      "996/996 [==============================] - 0s 465us/step - loss: 0.3206\n",
      "Epoch 8/100\n",
      "996/996 [==============================] - 0s 424us/step - loss: 0.3213\n",
      "Epoch 9/100\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3201\n",
      "Epoch 10/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3192\n",
      "Epoch 11/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3184\n",
      "Epoch 12/100\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3197\n",
      "Epoch 13/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3188\n",
      "Epoch 14/100\n",
      "996/996 [==============================] - 0s 417us/step - loss: 0.3177\n",
      "Epoch 15/100\n",
      "996/996 [==============================] - 0s 435us/step - loss: 0.3189\n",
      "Epoch 16/100\n",
      "996/996 [==============================] - 0s 423us/step - loss: 0.3162\n",
      "Epoch 17/100\n",
      "996/996 [==============================] - 0s 425us/step - loss: 0.3149\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 433us/step - loss: 0.3191\n",
      "Epoch 19/100\n",
      "996/996 [==============================] - 0s 421us/step - loss: 0.3196\n",
      "Epoch 20/100\n",
      "996/996 [==============================] - 0s 416us/step - loss: 0.3169\n",
      "Epoch 21/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3162\n",
      "Epoch 22/100\n",
      "996/996 [==============================] - 0s 417us/step - loss: 0.3163\n",
      "Epoch 23/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3148\n",
      "Epoch 24/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3183\n",
      "Epoch 25/100\n",
      "996/996 [==============================] - 0s 413us/step - loss: 0.3199\n",
      "Epoch 26/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3193\n",
      "Epoch 27/100\n",
      "996/996 [==============================] - 0s 418us/step - loss: 0.3167\n",
      "Epoch 28/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3201\n",
      "Epoch 29/100\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3169\n",
      "Epoch 30/100\n",
      "996/996 [==============================] - 0s 414us/step - loss: 0.3188\n",
      "Epoch 31/100\n",
      "996/996 [==============================] - 0s 418us/step - loss: 0.3161\n",
      "Epoch 32/100\n",
      "996/996 [==============================] - 0s 413us/step - loss: 0.3161\n",
      "Epoch 33/100\n",
      "996/996 [==============================] - 0s 416us/step - loss: 0.3153\n",
      "Epoch 34/100\n",
      "996/996 [==============================] - 0s 415us/step - loss: 0.3207\n",
      "Epoch 35/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3221\n",
      "Epoch 36/100\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3167\n",
      "Epoch 37/100\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3187\n",
      "Epoch 38/100\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3205\n",
      "Epoch 39/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3209\n",
      "Epoch 40/100\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3189\n",
      "Epoch 41/100\n",
      "996/996 [==============================] - 0s 416us/step - loss: 0.3157\n",
      "Epoch 42/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3188\n",
      "Epoch 43/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3171\n",
      "Epoch 44/100\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3158\n",
      "Epoch 45/100\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3167\n",
      "Epoch 46/100\n",
      "996/996 [==============================] - 0s 418us/step - loss: 0.3171\n",
      "Epoch 47/100\n",
      "996/996 [==============================] - 0s 413us/step - loss: 0.3147\n",
      "Epoch 48/100\n",
      "996/996 [==============================] - 0s 413us/step - loss: 0.3143\n",
      "Epoch 49/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3155\n",
      "Epoch 50/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3145\n",
      "Epoch 51/100\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3145\n",
      "Epoch 52/100\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3150\n",
      "Epoch 53/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3168\n",
      "Epoch 54/100\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3147\n",
      "Epoch 55/100\n",
      "996/996 [==============================] - 0s 416us/step - loss: 0.3157\n",
      "Epoch 56/100\n",
      "996/996 [==============================] - 0s 414us/step - loss: 0.3165\n",
      "Epoch 57/100\n",
      "996/996 [==============================] - 0s 411us/step - loss: 0.3165\n",
      "Epoch 58/100\n",
      "996/996 [==============================] - 0s 420us/step - loss: 0.3165\n",
      "Epoch 59/100\n",
      "996/996 [==============================] - 0s 417us/step - loss: 0.3156\n",
      "Epoch 60/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3146\n",
      "Epoch 61/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3149\n",
      "Epoch 62/100\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3129\n",
      "Epoch 63/100\n",
      "996/996 [==============================] - 0s 422us/step - loss: 0.3173\n",
      "Epoch 64/100\n",
      "996/996 [==============================] - 0s 411us/step - loss: 0.3192\n",
      "Epoch 65/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3172\n",
      "Epoch 66/100\n",
      "996/996 [==============================] - 0s 422us/step - loss: 0.3188\n",
      "Epoch 67/100\n",
      "996/996 [==============================] - 0s 421us/step - loss: 0.3168\n",
      "Epoch 68/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3179\n",
      "Epoch 69/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3179\n",
      "Epoch 70/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3150\n",
      "Epoch 71/100\n",
      "996/996 [==============================] - ETA: 0s - loss: 0.314 - 0s 400us/step - loss: 0.3162\n",
      "Epoch 72/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3139\n",
      "Epoch 73/100\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3217\n",
      "Epoch 74/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3154\n",
      "Epoch 75/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3172\n",
      "Epoch 76/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3151\n",
      "Epoch 77/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3173\n",
      "Epoch 78/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3199\n",
      "Epoch 79/100\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3169\n",
      "Epoch 80/100\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3159\n",
      "Epoch 81/100\n",
      "996/996 [==============================] - 0s 416us/step - loss: 0.3177\n",
      "Epoch 82/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3174\n",
      "Epoch 83/100\n",
      "996/996 [==============================] - 0s 414us/step - loss: 0.3191\n",
      "Epoch 84/100\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3190\n",
      "Epoch 85/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3175\n",
      "Epoch 86/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3152\n",
      "Epoch 87/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3163\n",
      "Epoch 88/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3151\n",
      "Epoch 89/100\n",
      "996/996 [==============================] - 0s 411us/step - loss: 0.3146\n",
      "Epoch 90/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3139\n",
      "Epoch 91/100\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3152\n",
      "Epoch 92/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3131\n",
      "Epoch 93/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3219\n",
      "Epoch 94/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3163\n",
      "Epoch 95/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3187\n",
      "Epoch 96/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3183\n",
      "Epoch 97/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3168\n",
      "Epoch 98/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3156\n",
      "Epoch 99/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3154\n",
      "Epoch 100/100\n",
      "996/996 [==============================] - 0s 411us/step - loss: 0.3167\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.004853693213710986, total= 3.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 90s 269ms/step - loss: 67.5100\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 16.8507\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 431us/step - loss: 14.6069\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 9.4545\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 10.9096\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 428us/step - loss: 8.8250\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 407us/step - loss: 2.7336\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 425us/step - loss: 3.0162\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 1.6286\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 425us/step - loss: 0.8037\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 428us/step - loss: 0.6696\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.6596\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.6521\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.6124\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5932\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.6057\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5841\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5868\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5699\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5741\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5718\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 430us/step - loss: 0.5616\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 428us/step - loss: 0.5570\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5559\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5533\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5469\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5453\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 427us/step - loss: 0.5479\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5432\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5451\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5433\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5581\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5440\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5502\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5544\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5552\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5447\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5473\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 428us/step - loss: 0.5454\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5442\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5496\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5451\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5432\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5448\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5532\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5537\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5517\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5595\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5485\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5530\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5527\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5435\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 425us/step - loss: 0.5486\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5589\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5497\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5518\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5507\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.597 - 0s 420us/step - loss: 0.5473\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 409us/step - loss: 0.5534\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 425us/step - loss: 0.5905\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 401us/step - loss: 0.5815\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5534\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.6313\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.6552\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5990\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 483us/step - loss: 0.6895\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.6127\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.7379\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.7193\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.6367\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.6040\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5972\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5570\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5605\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5664\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5618\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5483\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5471\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5494\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5451\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5439\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5443\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5410\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 427us/step - loss: 0.5513\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5422\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5436\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5445\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 427us/step - loss: 0.5428\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5422\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5433\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5423\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5437\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 408us/step - loss: 0.5461\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5514\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 406us/step - loss: 0.5428\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5489\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5431\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5489\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 410us/step - loss: 0.5435\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 428us/step - loss: 0.5476\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.06495733211318844, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "665/665 [==============================] - 91s 136ms/step - loss: 66.1823\n",
      "Epoch 2/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 15.6126\n",
      "Epoch 3/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 5.3869\n",
      "Epoch 4/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.8016\n",
      "Epoch 5/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.6208\n",
      "Epoch 6/100\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4891\n",
      "Epoch 7/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4367\n",
      "Epoch 8/100\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4168\n",
      "Epoch 9/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4133\n",
      "Epoch 10/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4123\n",
      "Epoch 11/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4037\n",
      "Epoch 12/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4075\n",
      "Epoch 13/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4061\n",
      "Epoch 14/100\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4004\n",
      "Epoch 15/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4046\n",
      "Epoch 16/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4064\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4112\n",
      "Epoch 18/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.406 - 0s 420us/step - loss: 0.4036\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4057\n",
      "Epoch 20/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4044\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4103\n",
      "Epoch 22/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4183\n",
      "Epoch 23/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4109\n",
      "Epoch 24/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4235\n",
      "Epoch 25/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4119\n",
      "Epoch 26/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4170\n",
      "Epoch 27/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4162\n",
      "Epoch 28/100\n",
      "665/665 [==============================] - 0s 431us/step - loss: 0.4209\n",
      "Epoch 29/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4255\n",
      "Epoch 30/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4199\n",
      "Epoch 31/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4083\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4100\n",
      "Epoch 33/100\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4050\n",
      "Epoch 34/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4086 0s - loss: 0.43\n",
      "Epoch 35/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4091\n",
      "Epoch 36/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4139\n",
      "Epoch 37/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4260\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4298\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - 0s 521us/step - loss: 0.4309\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - 0s 453us/step - loss: 0.4336\n",
      "Epoch 41/100\n",
      "665/665 [==============================] - 0s 444us/step - loss: 0.4229\n",
      "Epoch 42/100\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4113\n",
      "Epoch 43/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4240\n",
      "Epoch 44/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4169\n",
      "Epoch 45/100\n",
      "665/665 [==============================] - 0s 473us/step - loss: 0.4135\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - 0s 463us/step - loss: 0.4140\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4062\n",
      "Epoch 48/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.412 - 0s 425us/step - loss: 0.4143\n",
      "Epoch 49/100\n",
      "665/665 [==============================] - 0s 442us/step - loss: 0.4085\n",
      "Epoch 50/100\n",
      "665/665 [==============================] - 0s 435us/step - loss: 0.4089\n",
      "Epoch 51/100\n",
      "665/665 [==============================] - 0s 441us/step - loss: 0.4076\n",
      "Epoch 52/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4023\n",
      "Epoch 53/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4041\n",
      "Epoch 54/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4012\n",
      "Epoch 55/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4023\n",
      "Epoch 56/100\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4041\n",
      "Epoch 57/100\n",
      "665/665 [==============================] - 0s 412us/step - loss: 0.4034\n",
      "Epoch 58/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4058\n",
      "Epoch 59/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4034\n",
      "Epoch 60/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4015\n",
      "Epoch 61/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4028\n",
      "Epoch 62/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4039\n",
      "Epoch 63/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4075\n",
      "Epoch 64/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4060\n",
      "Epoch 65/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4043\n",
      "Epoch 66/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4045\n",
      "Epoch 67/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4060\n",
      "Epoch 68/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.418 - 0s 425us/step - loss: 0.4145\n",
      "Epoch 69/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.412 - 0s 419us/step - loss: 0.4113\n",
      "Epoch 70/100\n",
      "665/665 [==============================] - 0s 416us/step - loss: 0.4144\n",
      "Epoch 71/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4037\n",
      "Epoch 72/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4078\n",
      "Epoch 73/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4076\n",
      "Epoch 74/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4097\n",
      "Epoch 75/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4141\n",
      "Epoch 76/100\n",
      "665/665 [==============================] - 0s 429us/step - loss: 0.4070\n",
      "Epoch 77/100\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4096\n",
      "Epoch 78/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4095\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4060\n",
      "Epoch 80/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4065\n",
      "Epoch 81/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4124\n",
      "Epoch 82/100\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4040\n",
      "Epoch 83/100\n",
      "665/665 [==============================] - 0s 413us/step - loss: 0.4050\n",
      "Epoch 84/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4055\n",
      "Epoch 85/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4130\n",
      "Epoch 86/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4116\n",
      "Epoch 87/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4157\n",
      "Epoch 88/100\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4154\n",
      "Epoch 89/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4120\n",
      "Epoch 90/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4057\n",
      "Epoch 91/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4139\n",
      "Epoch 92/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4094\n",
      "Epoch 93/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4101\n",
      "Epoch 94/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4086\n",
      "Epoch 95/100\n",
      "665/665 [==============================] - 0s 440us/step - loss: 0.4135\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 433us/step - loss: 0.4197\n",
      "Epoch 97/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4075\n",
      "Epoch 98/100\n",
      "665/665 [==============================] - 0s 429us/step - loss: 0.4216\n",
      "Epoch 99/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4095\n",
      "Epoch 100/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4112\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0005936850486505385, total= 2.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "996/996 [==============================] - 90s 91ms/step - loss: 13.4423\n",
      "Epoch 2/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 3.0433\n",
      "Epoch 3/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 1.1088\n",
      "Epoch 4/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.4724\n",
      "Epoch 5/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3539\n",
      "Epoch 6/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3300\n",
      "Epoch 7/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3354\n",
      "Epoch 8/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3237\n",
      "Epoch 9/100\n",
      "996/996 [==============================] - 0s 444us/step - loss: 0.3291\n",
      "Epoch 10/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3250\n",
      "Epoch 11/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3275\n",
      "Epoch 12/100\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3288 0s - loss: 0.\n",
      "Epoch 13/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3322\n",
      "Epoch 14/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3244\n",
      "Epoch 15/100\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3267\n",
      "Epoch 16/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3243\n",
      "Epoch 17/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3254\n",
      "Epoch 18/100\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3223\n",
      "Epoch 19/100\n",
      "996/996 [==============================] - 0s 416us/step - loss: 0.3200\n",
      "Epoch 20/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3198\n",
      "Epoch 21/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3228\n",
      "Epoch 22/100\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3195\n",
      "Epoch 23/100\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3219\n",
      "Epoch 24/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3175\n",
      "Epoch 25/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3225\n",
      "Epoch 26/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3219\n",
      "Epoch 27/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3243\n",
      "Epoch 28/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3166\n",
      "Epoch 29/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3198\n",
      "Epoch 30/100\n",
      "996/996 [==============================] - ETA: 0s - loss: 0.309 - 0s 405us/step - loss: 0.3254\n",
      "Epoch 31/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3200\n",
      "Epoch 32/100\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3186\n",
      "Epoch 33/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3192\n",
      "Epoch 34/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3214\n",
      "Epoch 35/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3231\n",
      "Epoch 36/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3177\n",
      "Epoch 37/100\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3181\n",
      "Epoch 38/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3201\n",
      "Epoch 39/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3240\n",
      "Epoch 40/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3169 0s - loss: 0.\n",
      "Epoch 41/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3260\n",
      "Epoch 42/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3206\n",
      "Epoch 43/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3287\n",
      "Epoch 44/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3230\n",
      "Epoch 45/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3264\n",
      "Epoch 46/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3312\n",
      "Epoch 47/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3204\n",
      "Epoch 48/100\n",
      "996/996 [==============================] - 0s 430us/step - loss: 0.3316\n",
      "Epoch 49/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3221\n",
      "Epoch 50/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3262\n",
      "Epoch 51/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3240\n",
      "Epoch 52/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3251\n",
      "Epoch 53/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3237\n",
      "Epoch 54/100\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3196\n",
      "Epoch 55/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3199\n",
      "Epoch 56/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3196\n",
      "Epoch 57/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3216\n",
      "Epoch 58/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3233\n",
      "Epoch 59/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3190\n",
      "Epoch 60/100\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3246\n",
      "Epoch 61/100\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3226\n",
      "Epoch 62/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3201\n",
      "Epoch 63/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3276\n",
      "Epoch 64/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3221\n",
      "Epoch 65/100\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3183\n",
      "Epoch 66/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3191\n",
      "Epoch 67/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3196\n",
      "Epoch 68/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3219\n",
      "Epoch 69/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3191\n",
      "Epoch 70/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3202\n",
      "Epoch 71/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3208\n",
      "Epoch 72/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3219\n",
      "Epoch 73/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3175\n",
      "Epoch 74/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3205\n",
      "Epoch 75/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3208 0s - loss: 0.\n",
      "Epoch 76/100\n",
      "996/996 [==============================] - 0s 395us/step - loss: 0.3269\n",
      "Epoch 77/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3215\n",
      "Epoch 78/100\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3219\n",
      "Epoch 79/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3228\n",
      "Epoch 80/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3240\n",
      "Epoch 81/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3237 0s - loss: 0.\n",
      "Epoch 82/100\n",
      "996/996 [==============================] - 0s 398us/step - loss: 0.3218\n",
      "Epoch 83/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3284\n",
      "Epoch 84/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3215\n",
      "Epoch 85/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3230\n",
      "Epoch 86/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3221\n",
      "Epoch 87/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3207\n",
      "Epoch 88/100\n",
      "996/996 [==============================] - 0s 396us/step - loss: 0.3177\n",
      "Epoch 89/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3214\n",
      "Epoch 90/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3188\n",
      "Epoch 91/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3245\n",
      "Epoch 92/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3216\n",
      "Epoch 93/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3200\n",
      "Epoch 94/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3266\n",
      "Epoch 95/100\n",
      "996/996 [==============================] - 0s 394us/step - loss: 0.3251\n",
      "Epoch 96/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3275\n",
      "Epoch 97/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3292\n",
      "Epoch 98/100\n",
      "996/996 [==============================] - 0s 397us/step - loss: 0.3318\n",
      "Epoch 99/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3333\n",
      "Epoch 100/100\n",
      "996/996 [==============================] - 0s 400us/step - loss: 0.3311\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.044681776895907355, total= 3.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 91s 272ms/step - loss: 0.7485\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.6058\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5833\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 429us/step - loss: 0.5593\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 433us/step - loss: 0.5668\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5562\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5515\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5508\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5480\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5461\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5443\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5543\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 428us/step - loss: 0.5471\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5453\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5453\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5506\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5452\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5473\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 433us/step - loss: 0.5445\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5462\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5485\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 405us/step - loss: 0.5514\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5525\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5485\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 429us/step - loss: 0.5514\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5598\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5506\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5490\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5536\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5445\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 430us/step - loss: 0.5498\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5442\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5545\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5451\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5482\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5472\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 431us/step - loss: 0.5446\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5505\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5489\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5566\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 427us/step - loss: 0.5531\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5518\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5464\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5477\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 425us/step - loss: 0.5503\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5410\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5467\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 426us/step - loss: 0.5465\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 425us/step - loss: 0.5492\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5472\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5531\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5481\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5476\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5512\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5486\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5439\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5442\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5425\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5512\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.510 - 0s 424us/step - loss: 0.5500\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5468\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 421us/step - loss: 0.5453\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 417us/step - loss: 0.5485\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5424\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5446\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5444\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5430\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5449\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 482us/step - loss: 0.5407\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5448\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 431us/step - loss: 0.5437\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 429us/step - loss: 0.5429\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 431us/step - loss: 0.5440\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5451\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5435\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5457\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5424\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 412us/step - loss: 0.5439\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5411\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 416us/step - loss: 0.5455\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5443\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5461\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 427us/step - loss: 0.5476\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5435\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5423\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5451\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 422us/step - loss: 0.5453\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 415us/step - loss: 0.5459\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 418us/step - loss: 0.5448\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.521 - 0s 419us/step - loss: 0.5427\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 451us/step - loss: 0.5451\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 548us/step - loss: 0.5451\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 458us/step - loss: 0.5425\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 413us/step - loss: 0.5443\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 423us/step - loss: 0.5474\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 427us/step - loss: 0.5485\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 414us/step - loss: 0.5474\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 436us/step - loss: 0.5440\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 424us/step - loss: 0.5451\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 420us/step - loss: 0.5433\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.05923584635388579, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "665/665 [==============================] - 88s 133ms/step - loss: 0.4987\n",
      "Epoch 2/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4334\n",
      "Epoch 3/100\n",
      "665/665 [==============================] - 0s 431us/step - loss: 0.4170\n",
      "Epoch 4/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4137\n",
      "Epoch 5/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4111\n",
      "Epoch 6/100\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4145\n",
      "Epoch 7/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4149\n",
      "Epoch 8/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4099\n",
      "Epoch 9/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4161\n",
      "Epoch 10/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4150\n",
      "Epoch 11/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4077\n",
      "Epoch 12/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4042\n",
      "Epoch 13/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4071\n",
      "Epoch 14/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4067\n",
      "Epoch 15/100\n",
      "665/665 [==============================] - 0s 431us/step - loss: 0.4093\n",
      "Epoch 16/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4091\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4147\n",
      "Epoch 18/100\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4095\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4061\n",
      "Epoch 20/100\n",
      "665/665 [==============================] - 0s 438us/step - loss: 0.4133\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4054\n",
      "Epoch 22/100\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4082\n",
      "Epoch 23/100\n",
      "665/665 [==============================] - 0s 437us/step - loss: 0.4055\n",
      "Epoch 24/100\n",
      "665/665 [==============================] - 0s 432us/step - loss: 0.4050\n",
      "Epoch 25/100\n",
      "665/665 [==============================] - 0s 434us/step - loss: 0.4049\n",
      "Epoch 26/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4073\n",
      "Epoch 27/100\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4090\n",
      "Epoch 28/100\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4081\n",
      "Epoch 29/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4037\n",
      "Epoch 30/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4036\n",
      "Epoch 31/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4049\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4027\n",
      "Epoch 33/100\n",
      "665/665 [==============================] - 0s 449us/step - loss: 0.4055\n",
      "Epoch 34/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4066\n",
      "Epoch 35/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4087\n",
      "Epoch 36/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4042\n",
      "Epoch 37/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4054\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - 0s 433us/step - loss: 0.4030\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4020\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4012\n",
      "Epoch 41/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.4030\n",
      "Epoch 42/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4041\n",
      "Epoch 43/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4058\n",
      "Epoch 44/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4074\n",
      "Epoch 45/100\n",
      "665/665 [==============================] - 0s 430us/step - loss: 0.4060\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4021\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4038\n",
      "Epoch 48/100\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4047\n",
      "Epoch 49/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4062\n",
      "Epoch 50/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4037\n",
      "Epoch 51/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4027\n",
      "Epoch 52/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4028 0s - loss: 0.40\n",
      "Epoch 53/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.4035\n",
      "Epoch 54/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4030\n",
      "Epoch 55/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4003\n",
      "Epoch 56/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4041\n",
      "Epoch 57/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4045\n",
      "Epoch 58/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4023\n",
      "Epoch 59/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4034\n",
      "Epoch 60/100\n",
      "665/665 [==============================] - 0s 419us/step - loss: 0.4009\n",
      "Epoch 61/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4027\n",
      "Epoch 62/100\n",
      "665/665 [==============================] - 0s 429us/step - loss: 0.4015\n",
      "Epoch 63/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4023\n",
      "Epoch 64/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4024\n",
      "Epoch 65/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4026\n",
      "Epoch 66/100\n",
      "665/665 [==============================] - 0s 425us/step - loss: 0.4016\n",
      "Epoch 67/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4034\n",
      "Epoch 68/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4015\n",
      "Epoch 69/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4007\n",
      "Epoch 70/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.4000\n",
      "Epoch 71/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.395 - 0s 426us/step - loss: 0.4013\n",
      "Epoch 72/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4003\n",
      "Epoch 73/100\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4010\n",
      "Epoch 74/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4024 0s - loss: 0.40\n",
      "Epoch 75/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4004\n",
      "Epoch 76/100\n",
      "665/665 [==============================] - 0s 415us/step - loss: 0.4014\n",
      "Epoch 77/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4029\n",
      "Epoch 78/100\n",
      "665/665 [==============================] - 0s 434us/step - loss: 0.4003\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.3994 0s - loss: 0.40\n",
      "Epoch 80/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4010\n",
      "Epoch 81/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4006\n",
      "Epoch 82/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.4009\n",
      "Epoch 83/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.3995\n",
      "Epoch 84/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.3991\n",
      "Epoch 85/100\n",
      "665/665 [==============================] - 0s 418us/step - loss: 0.4005\n",
      "Epoch 86/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.3984\n",
      "Epoch 87/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.405 - 0s 422us/step - loss: 0.4007\n",
      "Epoch 88/100\n",
      "665/665 [==============================] - 0s 423us/step - loss: 0.4004 0s - loss: 0.32\n",
      "Epoch 89/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.4018\n",
      "Epoch 90/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4008\n",
      "Epoch 91/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.3999\n",
      "Epoch 92/100\n",
      "665/665 [==============================] - 0s 427us/step - loss: 0.4005\n",
      "Epoch 93/100\n",
      "665/665 [==============================] - 0s 417us/step - loss: 0.3990\n",
      "Epoch 94/100\n",
      "665/665 [==============================] - 0s 426us/step - loss: 0.3986\n",
      "Epoch 95/100\n",
      "665/665 [==============================] - 0s 421us/step - loss: 0.3993\n",
      "Epoch 96/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4009\n",
      "Epoch 97/100\n",
      "665/665 [==============================] - 0s 422us/step - loss: 0.3991\n",
      "Epoch 98/100\n",
      "665/665 [==============================] - 0s 420us/step - loss: 0.4009 0s - loss: 0.35\n",
      "Epoch 99/100\n",
      "665/665 [==============================] - 0s 424us/step - loss: 0.4009\n",
      "Epoch 100/100\n",
      "665/665 [==============================] - 0s 428us/step - loss: 0.3990\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.007617280349400346, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "996/996 [==============================] - 93s 93ms/step - loss: 0.3778\n",
      "Epoch 2/100\n",
      "996/996 [==============================] - 0s 411us/step - loss: 0.3403\n",
      "Epoch 3/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3341\n",
      "Epoch 4/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3276\n",
      "Epoch 5/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3293\n",
      "Epoch 6/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3336\n",
      "Epoch 7/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3240\n",
      "Epoch 8/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3261\n",
      "Epoch 9/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3235\n",
      "Epoch 10/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3282\n",
      "Epoch 11/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3219\n",
      "Epoch 12/100\n",
      "996/996 [==============================] - 0s 415us/step - loss: 0.3218\n",
      "Epoch 13/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3262\n",
      "Epoch 14/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3239\n",
      "Epoch 15/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3268\n",
      "Epoch 16/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3240\n",
      "Epoch 17/100\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3262\n",
      "Epoch 18/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3265\n",
      "Epoch 19/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3226\n",
      "Epoch 20/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3197\n",
      "Epoch 21/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3193\n",
      "Epoch 22/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3198\n",
      "Epoch 23/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3229\n",
      "Epoch 24/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3215\n",
      "Epoch 25/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3204\n",
      "Epoch 26/100\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3191\n",
      "Epoch 27/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3229\n",
      "Epoch 28/100\n",
      "996/996 [==============================] - 0s 417us/step - loss: 0.3218\n",
      "Epoch 29/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3203\n",
      "Epoch 30/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3189\n",
      "Epoch 31/100\n",
      "996/996 [==============================] - ETA: 0s - loss: 0.323 - 0s 408us/step - loss: 0.3188\n",
      "Epoch 32/100\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3189\n",
      "Epoch 33/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3199\n",
      "Epoch 34/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3164\n",
      "Epoch 35/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3196\n",
      "Epoch 36/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3171\n",
      "Epoch 37/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3160\n",
      "Epoch 38/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3166\n",
      "Epoch 39/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3185\n",
      "Epoch 40/100\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3161\n",
      "Epoch 41/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3181\n",
      "Epoch 42/100\n",
      "996/996 [==============================] - 0s 412us/step - loss: 0.3187\n",
      "Epoch 43/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3202\n",
      "Epoch 44/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3185\n",
      "Epoch 45/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3185\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 408us/step - loss: 0.3162\n",
      "Epoch 47/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3174\n",
      "Epoch 48/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3172\n",
      "Epoch 49/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3166\n",
      "Epoch 50/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3194\n",
      "Epoch 51/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3144\n",
      "Epoch 52/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3172\n",
      "Epoch 53/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3144\n",
      "Epoch 54/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3180\n",
      "Epoch 55/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3169\n",
      "Epoch 56/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3170\n",
      "Epoch 57/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3155\n",
      "Epoch 58/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3146\n",
      "Epoch 59/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3152\n",
      "Epoch 60/100\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3154\n",
      "Epoch 61/100\n",
      "996/996 [==============================] - 0s 411us/step - loss: 0.3147\n",
      "Epoch 62/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3157\n",
      "Epoch 63/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3144\n",
      "Epoch 64/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3146\n",
      "Epoch 65/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3166\n",
      "Epoch 66/100\n",
      "996/996 [==============================] - 0s 404us/step - loss: 0.3158\n",
      "Epoch 67/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3155\n",
      "Epoch 68/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3151\n",
      "Epoch 69/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3173\n",
      "Epoch 70/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3157\n",
      "Epoch 71/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3159\n",
      "Epoch 72/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3139\n",
      "Epoch 73/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3154\n",
      "Epoch 74/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3151\n",
      "Epoch 75/100\n",
      "996/996 [==============================] - 0s 410us/step - loss: 0.3152\n",
      "Epoch 76/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3148\n",
      "Epoch 77/100\n",
      "996/996 [==============================] - 0s 403us/step - loss: 0.3146\n",
      "Epoch 78/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3159\n",
      "Epoch 79/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3152\n",
      "Epoch 80/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3143\n",
      "Epoch 81/100\n",
      "996/996 [==============================] - 0s 399us/step - loss: 0.3166\n",
      "Epoch 82/100\n",
      "996/996 [==============================] - 0s 402us/step - loss: 0.3149\n",
      "Epoch 83/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3139\n",
      "Epoch 84/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3144\n",
      "Epoch 85/100\n",
      "996/996 [==============================] - 0s 418us/step - loss: 0.3145\n",
      "Epoch 86/100\n",
      "996/996 [==============================] - 0s 411us/step - loss: 0.3153\n",
      "Epoch 87/100\n",
      "996/996 [==============================] - 0s 416us/step - loss: 0.3144 0s - loss: 0.\n",
      "Epoch 88/100\n",
      "996/996 [==============================] - 0s 427us/step - loss: 0.3144\n",
      "Epoch 89/100\n",
      "996/996 [==============================] - 0s 419us/step - loss: 0.3144\n",
      "Epoch 90/100\n",
      "996/996 [==============================] - 0s 429us/step - loss: 0.3141\n",
      "Epoch 91/100\n",
      "996/996 [==============================] - 0s 416us/step - loss: 0.3143\n",
      "Epoch 92/100\n",
      "996/996 [==============================] - 0s 409us/step - loss: 0.3141\n",
      "Epoch 93/100\n",
      "996/996 [==============================] - 0s 401us/step - loss: 0.3146\n",
      "Epoch 94/100\n",
      "996/996 [==============================] - 0s 405us/step - loss: 0.3143\n",
      "Epoch 95/100\n",
      "996/996 [==============================] - 0s 406us/step - loss: 0.3146\n",
      "Epoch 96/100\n",
      "996/996 [==============================] - 0s 413us/step - loss: 0.3140\n",
      "Epoch 97/100\n",
      "996/996 [==============================] - 0s 472us/step - loss: 0.3150\n",
      "Epoch 98/100\n",
      "996/996 [==============================] - 0s 407us/step - loss: 0.3142\n",
      "Epoch 99/100\n",
      "996/996 [==============================] - ETA: 0s - loss: 0.310 - 0s 403us/step - loss: 0.3135\n",
      "Epoch 100/100\n",
      "996/996 [==============================] - 0s 408us/step - loss: 0.3142\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=50, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.00016001329099579742, total= 3.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 92s 277ms/step - loss: 1.0891\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.8133\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.6747\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 0s 241us/step - loss: 0.5913\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5942\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5696\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5722\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 0s 245us/step - loss: 0.5639\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 0s 242us/step - loss: 0.5666\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 0s 242us/step - loss: 0.5632\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.09240348020531308, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "665/665 [==============================] - 90s 135ms/step - loss: 0.7133\n",
      "Epoch 2/10\n",
      "665/665 [==============================] - 0s 213us/step - loss: 0.4897\n",
      "Epoch 3/10\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4795\n",
      "Epoch 4/10\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4267\n",
      "Epoch 5/10\n",
      "665/665 [==============================] - 0s 213us/step - loss: 0.4178\n",
      "Epoch 6/10\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.4103\n",
      "Epoch 7/10\n",
      "665/665 [==============================] - 0s 211us/step - loss: 0.4158\n",
      "Epoch 8/10\n",
      "665/665 [==============================] - 0s 213us/step - loss: 0.4199\n",
      "Epoch 9/10\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.4081\n",
      "Epoch 10/10\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4091\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.0093747147177341, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "996/996 [==============================] - 92s 92ms/step - loss: 0.5407\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3692\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3491\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 0s 202us/step - loss: 0.3387\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 0s 203us/step - loss: 0.3368\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3278\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3256\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 0s 201us/step - loss: 0.3214\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3170\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 0s 203us/step - loss: 0.3192\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.006526167437854058, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 94s 280ms/step - loss: 37.3688\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 0s 253us/step - loss: 78.9348\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 0s 246us/step - loss: 8.1600\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 0s 254us/step - loss: 20.9618\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 0s 261us/step - loss: 28.5560\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 0s 237us/step - loss: 19.1494\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 0s 247us/step - loss: 6.8880\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 0s 252us/step - loss: 4.8542\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 0s 257us/step - loss: 5.5521\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 0s 243us/step - loss: 3.8396\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-3.3373766027909353, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "665/665 [==============================] - 92s 138ms/step - loss: 33.2554\n",
      "Epoch 2/10\n",
      "665/665 [==============================] - 0s 214us/step - loss: 11.2178\n",
      "Epoch 3/10\n",
      "665/665 [==============================] - 0s 223us/step - loss: 4.3582\n",
      "Epoch 4/10\n",
      "665/665 [==============================] - 0s 216us/step - loss: 1.9469\n",
      "Epoch 5/10\n",
      "665/665 [==============================] - 0s 218us/step - loss: 1.5861\n",
      "Epoch 6/10\n",
      "665/665 [==============================] - 0s 210us/step - loss: 0.9308\n",
      "Epoch 7/10\n",
      "665/665 [==============================] - 0s 212us/step - loss: 0.6935\n",
      "Epoch 8/10\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.6195\n",
      "Epoch 9/10\n",
      "665/665 [==============================] - 0s 212us/step - loss: 0.4832\n",
      "Epoch 10/10\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.4403\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.14595639931553994, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "996/996 [==============================] - 90s 91ms/step - loss: 21.7669\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 0s 207us/step - loss: 5.3952\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 0s 210us/step - loss: 3.4253\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 0s 204us/step - loss: 1.4034\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.7538\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3903\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 0s 204us/step - loss: 0.3472\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 0s 203us/step - loss: 0.3380\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3210\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.3276\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.0008994751200418483, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 88s 263ms/step - loss: 0.7692\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.5899\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5715\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 0s 243us/step - loss: 0.5638\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 0s 242us/step - loss: 0.5583\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5591\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 0s 239us/step - loss: 0.5523\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5506\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5469\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 0s 243us/step - loss: 0.5466\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.06463874186526564, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "665/665 [==============================] - 92s 139ms/step - loss: 0.5568\n",
      "Epoch 2/10\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4387\n",
      "Epoch 3/10\n",
      "665/665 [==============================] - 0s 215us/step - loss: 0.4154\n",
      "Epoch 4/10\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4079\n",
      "Epoch 5/10\n",
      "665/665 [==============================] - 0s 215us/step - loss: 0.4048\n",
      "Epoch 6/10\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.4046\n",
      "Epoch 7/10\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4039\n",
      "Epoch 8/10\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4074\n",
      "Epoch 9/10\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.4026\n",
      "Epoch 10/10\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4041\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.000441047681956519, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/10\n",
      "996/996 [==============================] - 90s 90ms/step - loss: 0.3773\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3238\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3271\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3240\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3235\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3188\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3182\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3174\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 0s 203us/step - loss: 0.3196\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3182\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=10, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.02463434494538097, total= 2.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 93s 280ms/step - loss: 1.1846\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.8308\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.7909\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 245us/step - loss: 0.6291\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.6590\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.6284\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.6184\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5690\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 243us/step - loss: 0.5667\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5733\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5713\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 243us/step - loss: 0.5611\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5530\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5569\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5613\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5558\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 245us/step - loss: 0.5511\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 240us/step - loss: 0.5546\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5452\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 243us/step - loss: 0.5496\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.07104216575913336, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 173s 260ms/step - loss: 0.7585\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 238us/step - loss: 0.5563\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 243us/step - loss: 0.4679\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4295\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4149\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4142\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4153\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4090\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 214us/step - loss: 0.4112\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4096\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4084\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4045\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 285us/step - loss: 0.4037\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 257us/step - loss: 0.4048\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 241us/step - loss: 0.4025\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4041\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4047\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4043\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4026\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4077\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.002216333823432004, total= 4.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 102s 102ms/step - loss: 0.5914\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3950\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3491\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3361\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 203us/step - loss: 0.3303\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3282\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 223us/step - loss: 0.3233\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3216\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3203\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3211\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 204us/step - loss: 0.3161\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3199\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 211us/step - loss: 0.3174\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3150\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3169\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 204us/step - loss: 0.3153\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3156\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3150\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3152\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3142\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.005568134432818006, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "334/334 [==============================] - 97s 291ms/step - loss: 12.7237\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 250us/step - loss: 70.4012\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 243us/step - loss: 20.7248\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 260us/step - loss: 8.5927\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 243us/step - loss: 9.5410\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 247us/step - loss: 3.2479\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 250us/step - loss: 2.3663\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 260us/step - loss: 2.6262\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 243us/step - loss: 2.4164\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 244us/step - loss: 1.5786\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 256us/step - loss: 2.4101\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 273us/step - loss: 1.4638\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.8211\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 1.6008\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 255us/step - loss: 1.0773\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.7863\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.8353\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 245us/step - loss: 0.6392\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.6227\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.6097\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.04611947270966121, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 92s 138ms/step - loss: 52.7616\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 225us/step - loss: 10.6745\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 224us/step - loss: 18.0607\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 222us/step - loss: 7.8797\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 223us/step - loss: 5.0822\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 221us/step - loss: 1.4573\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.8787\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.5307\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4852\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 210us/step - loss: 0.4488\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 214us/step - loss: 0.4496\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4718\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4496\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4357\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4255\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 248us/step - loss: 0.4207\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4070\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4043\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.3997\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.4020\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.00384235110786757, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 104s 104ms/step - loss: 39.9336\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 205us/step - loss: 13.6705\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 205us/step - loss: 4.3011\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 210us/step - loss: 1.5462\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.6059\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3893\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3251\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3221\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3170\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3140\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3146\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3136\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3124\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3152\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.3158\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3147\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3141\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3193\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3174\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 204us/step - loss: 0.3129\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.001800550563826775, total= 2.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 94s 281ms/step - loss: 0.8691\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 0s 268us/step - loss: 0.5944\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5965\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5825\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5743\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 0s 242us/step - loss: 0.5556\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5552\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5569\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5507\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5528\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5517\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5513\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 0s 243us/step - loss: 0.5507\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5397\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5476\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5533\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5503\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5469\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5442\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 0s 273us/step - loss: 0.5413\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0985760156721105, total= 2.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "665/665 [==============================] - 96s 144ms/step - loss: 0.7641\n",
      "Epoch 2/20\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.5074\n",
      "Epoch 3/20\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4209\n",
      "Epoch 4/20\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4191\n",
      "Epoch 5/20\n",
      "665/665 [==============================] - 0s 235us/step - loss: 0.4068\n",
      "Epoch 6/20\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4071\n",
      "Epoch 7/20\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4036\n",
      "Epoch 8/20\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4020\n",
      "Epoch 9/20\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4028\n",
      "Epoch 10/20\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.4039\n",
      "Epoch 11/20\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.4036\n",
      "Epoch 12/20\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4015\n",
      "Epoch 13/20\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4009\n",
      "Epoch 14/20\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4028\n",
      "Epoch 15/20\n",
      "665/665 [==============================] - 0s 213us/step - loss: 0.4021\n",
      "Epoch 16/20\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4021\n",
      "Epoch 17/20\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4034\n",
      "Epoch 18/20\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4017\n",
      "Epoch 19/20\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4039\n",
      "Epoch 20/20\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4044\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.008662646907251492, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/20\n",
      "996/996 [==============================] - 95s 96ms/step - loss: 0.4365\n",
      "Epoch 2/20\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3396\n",
      "Epoch 3/20\n",
      "996/996 [==============================] - 0s 204us/step - loss: 0.3295\n",
      "Epoch 4/20\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3195\n",
      "Epoch 5/20\n",
      "996/996 [==============================] - 0s 202us/step - loss: 0.3190\n",
      "Epoch 6/20\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3180\n",
      "Epoch 7/20\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3202\n",
      "Epoch 8/20\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.3188\n",
      "Epoch 9/20\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3199\n",
      "Epoch 10/20\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3219\n",
      "Epoch 11/20\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3204\n",
      "Epoch 12/20\n",
      "996/996 [==============================] - 0s 204us/step - loss: 0.3192\n",
      "Epoch 13/20\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3208\n",
      "Epoch 14/20\n",
      "996/996 [==============================] - 0s 228us/step - loss: 0.3192\n",
      "Epoch 15/20\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3216\n",
      "Epoch 16/20\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3203\n",
      "Epoch 17/20\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3203\n",
      "Epoch 18/20\n",
      "996/996 [==============================] - 0s 202us/step - loss: 0.3217\n",
      "Epoch 19/20\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3201\n",
      "Epoch 20/20\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3180\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=20, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.005637203141820368, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "334/334 [==============================] - 96s 288ms/step - loss: 1.1692\n",
      "Epoch 2/30\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.8152\n",
      "Epoch 3/30\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.6652\n",
      "Epoch 4/30\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.6129\n",
      "Epoch 5/30\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5850\n",
      "Epoch 6/30\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.5922\n",
      "Epoch 7/30\n",
      "334/334 [==============================] - 0s 270us/step - loss: 0.5745\n",
      "Epoch 8/30\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5709\n",
      "Epoch 9/30\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5675\n",
      "Epoch 10/30\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.5546\n",
      "Epoch 11/30\n",
      "334/334 [==============================] - 0s 243us/step - loss: 0.5570\n",
      "Epoch 12/30\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5737\n",
      "Epoch 13/30\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5469\n",
      "Epoch 14/30\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5511\n",
      "Epoch 15/30\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5561\n",
      "Epoch 16/30\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5510\n",
      "Epoch 17/30\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5512\n",
      "Epoch 18/30\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5500\n",
      "Epoch 19/30\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5513\n",
      "Epoch 20/30\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5479\n",
      "Epoch 21/30\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5533\n",
      "Epoch 22/30\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5515\n",
      "Epoch 23/30\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5484\n",
      "Epoch 24/30\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5507\n",
      "Epoch 25/30\n",
      "334/334 [==============================] - 0s 245us/step - loss: 0.5491\n",
      "Epoch 26/30\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5472\n",
      "Epoch 27/30\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5456\n",
      "Epoch 28/30\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5456\n",
      "Epoch 29/30\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5482\n",
      "Epoch 30/30\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5455\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.09256708602104835, total= 2.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "665/665 [==============================] - 96s 144ms/step - loss: 0.7868\n",
      "Epoch 2/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.5395\n",
      "Epoch 3/30\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4557\n",
      "Epoch 4/30\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4333\n",
      "Epoch 5/30\n",
      "665/665 [==============================] - 0s 248us/step - loss: 0.4185\n",
      "Epoch 6/30\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4168\n",
      "Epoch 7/30\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4166\n",
      "Epoch 8/30\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4117\n",
      "Epoch 9/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4132\n",
      "Epoch 10/30\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4090\n",
      "Epoch 11/30\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4033\n",
      "Epoch 12/30\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4054\n",
      "Epoch 13/30\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4034\n",
      "Epoch 14/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4036\n",
      "Epoch 15/30\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4041\n",
      "Epoch 16/30\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4060\n",
      "Epoch 17/30\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4048\n",
      "Epoch 18/30\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4035\n",
      "Epoch 19/30\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.4027\n",
      "Epoch 20/30\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4029\n",
      "Epoch 21/30\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4021\n",
      "Epoch 22/30\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4045\n",
      "Epoch 23/30\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4008\n",
      "Epoch 24/30\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4016\n",
      "Epoch 25/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4005\n",
      "Epoch 26/30\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4008\n",
      "Epoch 27/30\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4000\n",
      "Epoch 28/30\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4009\n",
      "Epoch 29/30\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.3990\n",
      "Epoch 30/30\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4000\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.003385440214055513, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 99s 99ms/step - loss: 0.4783\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3795\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3495\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3495\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3339\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3288\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3300\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3243\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3191\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3182\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3158\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3166\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3161\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3162\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3143\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3160\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 0s 204us/step - loss: 0.3159\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.3161\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 0s 226us/step - loss: 0.3152\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3163\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3142\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3143\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.3149\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3145\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3159\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3141\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3141\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3133\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3135\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3134\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.005344959005161631, total= 2.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "334/334 [==============================] - 1163s 3s/step - loss: 64.3378\n",
      "Epoch 2/30\n",
      "334/334 [==============================] - 0s 265us/step - loss: 68.7702\n",
      "Epoch 3/30\n",
      "334/334 [==============================] - 0s 256us/step - loss: 10.4946\n",
      "Epoch 4/30\n",
      "334/334 [==============================] - 0s 381us/step - loss: 13.9393\n",
      "Epoch 5/30\n",
      "334/334 [==============================] - 0s 245us/step - loss: 24.9108\n",
      "Epoch 6/30\n",
      "334/334 [==============================] - 0s 249us/step - loss: 7.4284\n",
      "Epoch 7/30\n",
      "334/334 [==============================] - 0s 248us/step - loss: 5.6202\n",
      "Epoch 8/30\n",
      "334/334 [==============================] - 0s 311us/step - loss: 6.0143\n",
      "Epoch 9/30\n",
      "334/334 [==============================] - 0s 258us/step - loss: 8.1380\n",
      "Epoch 10/30\n",
      "334/334 [==============================] - 0s 263us/step - loss: 2.7572\n",
      "Epoch 11/30\n",
      "334/334 [==============================] - 0s 428us/step - loss: 2.4388\n",
      "Epoch 12/30\n",
      "334/334 [==============================] - 0s 257us/step - loss: 6.7813\n",
      "Epoch 13/30\n",
      "334/334 [==============================] - 0s 389us/step - loss: 3.8592\n",
      "Epoch 14/30\n",
      "334/334 [==============================] - 0s 245us/step - loss: 1.5704\n",
      "Epoch 15/30\n",
      "334/334 [==============================] - 0s 252us/step - loss: 1.1510\n",
      "Epoch 16/30\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.8813\n",
      "Epoch 17/30\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.7430\n",
      "Epoch 18/30\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.6561\n",
      "Epoch 19/30\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5917\n",
      "Epoch 20/30\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5999\n",
      "Epoch 21/30\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5634\n",
      "Epoch 22/30\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5522\n",
      "Epoch 23/30\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5541\n",
      "Epoch 24/30\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5834\n",
      "Epoch 25/30\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.6085\n",
      "Epoch 26/30\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.6107\n",
      "Epoch 27/30\n",
      "334/334 [==============================] - 0s 268us/step - loss: 0.5646\n",
      "Epoch 28/30\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5706\n",
      "Epoch 29/30\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.5492\n",
      "Epoch 30/30\n",
      "334/334 [==============================] - 0s 269us/step - loss: 0.5508\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.03411587495737489, total=51.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "665/665 [==============================] - 169s 254ms/step - loss: 27.6902\n",
      "Epoch 2/30\n",
      "665/665 [==============================] - 0s 223us/step - loss: 3.0450\n",
      "Epoch 3/30\n",
      "665/665 [==============================] - 0s 220us/step - loss: 2.6898\n",
      "Epoch 4/30\n",
      "665/665 [==============================] - 0s 224us/step - loss: 2.0079\n",
      "Epoch 5/30\n",
      "665/665 [==============================] - 0s 223us/step - loss: 1.0192\n",
      "Epoch 6/30\n",
      "665/665 [==============================] - 0s 217us/step - loss: 1.1609\n",
      "Epoch 7/30\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.7580\n",
      "Epoch 8/30\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4945\n",
      "Epoch 9/30\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4311\n",
      "Epoch 10/30\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4255\n",
      "Epoch 11/30\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4287\n",
      "Epoch 12/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4091\n",
      "Epoch 13/30\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4089\n",
      "Epoch 14/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4031\n",
      "Epoch 15/30\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.3997\n",
      "Epoch 16/30\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4060\n",
      "Epoch 17/30\n",
      "665/665 [==============================] - 0s 245us/step - loss: 0.4039\n",
      "Epoch 18/30\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4036\n",
      "Epoch 19/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.3987\n",
      "Epoch 20/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4043\n",
      "Epoch 21/30\n",
      "665/665 [==============================] - 0s 213us/step - loss: 0.3984\n",
      "Epoch 22/30\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.3990\n",
      "Epoch 23/30\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.3995\n",
      "Epoch 24/30\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.3994\n",
      "Epoch 25/30\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4015\n",
      "Epoch 26/30\n",
      "665/665 [==============================] - 0s 215us/step - loss: 0.4027\n",
      "Epoch 27/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4001\n",
      "Epoch 28/30\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4036\n",
      "Epoch 29/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4013\n",
      "Epoch 30/30\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3994\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.003541397080301323, total= 4.7min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 144s 144ms/step - loss: 24.9997\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 0s 233us/step - loss: 13.7232\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 0s 283us/step - loss: 4.7170\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 2.8151\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.6933\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.4251\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3627\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3373\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3188\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 0s 205us/step - loss: 0.3186\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3224\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3168\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3143\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3176\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3189\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3174\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3147\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3172\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3159\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3145\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3168\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 0s 262us/step - loss: 0.3177\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3203\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3174\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3167\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3144\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3187\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3161\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3167\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3158\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0030518571135009775, total= 4.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "334/334 [==============================] - 106s 318ms/step - loss: 1.0717\n",
      "Epoch 2/30\n",
      "334/334 [==============================] - 0s 322us/step - loss: 0.6439\n",
      "Epoch 3/30\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.6153\n",
      "Epoch 4/30\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.6291\n",
      "Epoch 5/30\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5971\n",
      "Epoch 6/30\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5599\n",
      "Epoch 7/30\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5484\n",
      "Epoch 8/30\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5496\n",
      "Epoch 9/30\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5491\n",
      "Epoch 10/30\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5493\n",
      "Epoch 11/30\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5458\n",
      "Epoch 12/30\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5471\n",
      "Epoch 13/30\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5469\n",
      "Epoch 14/30\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5437\n",
      "Epoch 15/30\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5458\n",
      "Epoch 16/30\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5486\n",
      "Epoch 17/30\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.5422\n",
      "Epoch 18/30\n",
      "334/334 [==============================] - 0s 241us/step - loss: 0.5458\n",
      "Epoch 19/30\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5475\n",
      "Epoch 20/30\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5479\n",
      "Epoch 21/30\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5454\n",
      "Epoch 22/30\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5459\n",
      "Epoch 23/30\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5447\n",
      "Epoch 24/30\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.5468\n",
      "Epoch 25/30\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5457\n",
      "Epoch 26/30\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5449\n",
      "Epoch 27/30\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5470\n",
      "Epoch 28/30\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5447\n",
      "Epoch 29/30\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5435\n",
      "Epoch 30/30\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5450\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.07712064496405113, total= 3.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "665/665 [==============================] - 103s 155ms/step - loss: 0.5418\n",
      "Epoch 2/30\n",
      "665/665 [==============================] - 0s 243us/step - loss: 0.4403\n",
      "Epoch 3/30\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4198\n",
      "Epoch 4/30\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4120\n",
      "Epoch 5/30\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4022\n",
      "Epoch 6/30\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4014\n",
      "Epoch 7/30\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4006\n",
      "Epoch 8/30\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4018\n",
      "Epoch 9/30\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4019\n",
      "Epoch 10/30\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4018\n",
      "Epoch 11/30\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4007\n",
      "Epoch 12/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4018\n",
      "Epoch 13/30\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4038\n",
      "Epoch 14/30\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4030\n",
      "Epoch 15/30\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.4035\n",
      "Epoch 16/30\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4062\n",
      "Epoch 17/30\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4027\n",
      "Epoch 18/30\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4028\n",
      "Epoch 19/30\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4024\n",
      "Epoch 20/30\n",
      "665/665 [==============================] - 0s 217us/step - loss: 0.4023\n",
      "Epoch 21/30\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.4000\n",
      "Epoch 22/30\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4007\n",
      "Epoch 23/30\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3986\n",
      "Epoch 24/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4014\n",
      "Epoch 25/30\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4003\n",
      "Epoch 26/30\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4035\n",
      "Epoch 27/30\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4000\n",
      "Epoch 28/30\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4018\n",
      "Epoch 29/30\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4015\n",
      "Epoch 30/30\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.3998\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.009475849940465908, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 114s 114ms/step - loss: 0.4274\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3383\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 0s 223us/step - loss: 0.3259\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 0s 228us/step - loss: 0.3166\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 211us/step - loss: 0.3178\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3191\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3273\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3257\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3237\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3230\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3187\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3185\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3170\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3180\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3183\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3155\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3171\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3202\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3161\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3157\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3149\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3188\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3161\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3175\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3168\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3177\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3165\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3169\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3161\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3161\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=30, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.00011623274708094655, total= 3.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "334/334 [==============================] - 108s 324ms/step - loss: 1.0933\n",
      "Epoch 2/40\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.8364\n",
      "Epoch 3/40\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.6317\n",
      "Epoch 4/40\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.6251\n",
      "Epoch 5/40\n",
      "334/334 [==============================] - 0s 327us/step - loss: 0.5902\n",
      "Epoch 6/40\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5725\n",
      "Epoch 7/40\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5812\n",
      "Epoch 8/40\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5654\n",
      "Epoch 9/40\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5757\n",
      "Epoch 10/40\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5669\n",
      "Epoch 11/40\n",
      "334/334 [==============================] - 0s 245us/step - loss: 0.5585\n",
      "Epoch 12/40\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5595\n",
      "Epoch 13/40\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5529\n",
      "Epoch 14/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5555\n",
      "Epoch 15/40\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5465\n",
      "Epoch 16/40\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5574\n",
      "Epoch 17/40\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5496\n",
      "Epoch 18/40\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5519\n",
      "Epoch 19/40\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5460\n",
      "Epoch 20/40\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5457\n",
      "Epoch 21/40\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5445\n",
      "Epoch 22/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5482\n",
      "Epoch 23/40\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5468\n",
      "Epoch 24/40\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5472\n",
      "Epoch 25/40\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5435\n",
      "Epoch 26/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5485\n",
      "Epoch 27/40\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5527\n",
      "Epoch 28/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5429\n",
      "Epoch 29/40\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5525\n",
      "Epoch 30/40\n",
      "334/334 [==============================] - 0s 245us/step - loss: 0.5498\n",
      "Epoch 31/40\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5456\n",
      "Epoch 32/40\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5478\n",
      "Epoch 33/40\n",
      "334/334 [==============================] - 0s 244us/step - loss: 0.5425\n",
      "Epoch 34/40\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5453\n",
      "Epoch 35/40\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5419\n",
      "Epoch 36/40\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5453\n",
      "Epoch 37/40\n",
      "334/334 [==============================] - 0s 386us/step - loss: 0.5416\n",
      "Epoch 38/40\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5443\n",
      "Epoch 39/40\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5443\n",
      "Epoch 40/40\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5461\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.05621799970637764, total= 3.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "665/665 [==============================] - 103s 154ms/step - loss: 0.8588\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.5445\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4623\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4275\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 0s 235us/step - loss: 0.4247\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4136\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 0s 258us/step - loss: 0.4111\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 0s 238us/step - loss: 0.4133\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 0s 239us/step - loss: 0.4098\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4069\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.3996\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4048\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4074\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 0s 236us/step - loss: 0.4005\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4044\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4083\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4047\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4042\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4002\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 0s 215us/step - loss: 0.4016\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4025\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4008\n",
      "Epoch 23/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4005\n",
      "Epoch 24/40\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4017\n",
      "Epoch 25/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4022\n",
      "Epoch 26/40\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4017\n",
      "Epoch 27/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4019\n",
      "Epoch 28/40\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4018\n",
      "Epoch 29/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4024\n",
      "Epoch 30/40\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4000\n",
      "Epoch 31/40\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3984\n",
      "Epoch 32/40\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3988\n",
      "Epoch 33/40\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3985\n",
      "Epoch 34/40\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3990\n",
      "Epoch 35/40\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3992\n",
      "Epoch 36/40\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3979\n",
      "Epoch 37/40\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3993\n",
      "Epoch 38/40\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3984\n",
      "Epoch 39/40\n",
      "665/665 [==============================] - 0s 234us/step - loss: 0.3984\n",
      "Epoch 40/40\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.3990\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.001717344380642638, total= 3.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "996/996 [==============================] - 104s 104ms/step - loss: 0.5288\n",
      "Epoch 2/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3694\n",
      "Epoch 3/40\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3327\n",
      "Epoch 4/40\n",
      "996/996 [==============================] - 0s 208us/step - loss: 0.3321\n",
      "Epoch 5/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3271\n",
      "Epoch 6/40\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3190\n",
      "Epoch 7/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3232\n",
      "Epoch 8/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3196\n",
      "Epoch 9/40\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3234\n",
      "Epoch 10/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3217\n",
      "Epoch 11/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3218\n",
      "Epoch 12/40\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3223\n",
      "Epoch 13/40\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3221\n",
      "Epoch 14/40\n",
      "996/996 [==============================] - 0s 261us/step - loss: 0.3174\n",
      "Epoch 15/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3155\n",
      "Epoch 16/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3183\n",
      "Epoch 17/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3188\n",
      "Epoch 18/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3169\n",
      "Epoch 19/40\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3145\n",
      "Epoch 20/40\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3141\n",
      "Epoch 21/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3141\n",
      "Epoch 22/40\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3146\n",
      "Epoch 23/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3173\n",
      "Epoch 24/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3144\n",
      "Epoch 25/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3153\n",
      "Epoch 26/40\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3138\n",
      "Epoch 27/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3151\n",
      "Epoch 28/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3138\n",
      "Epoch 29/40\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3137\n",
      "Epoch 30/40\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3156\n",
      "Epoch 31/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3143\n",
      "Epoch 32/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3150\n",
      "Epoch 33/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3151\n",
      "Epoch 34/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3135\n",
      "Epoch 35/40\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3146\n",
      "Epoch 36/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3155\n",
      "Epoch 37/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3135\n",
      "Epoch 38/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3144\n",
      "Epoch 39/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3133\n",
      "Epoch 40/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3127\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.000611173675835408, total= 3.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "334/334 [==============================] - 105s 314ms/step - loss: 28.2898\n",
      "Epoch 2/40\n",
      "334/334 [==============================] - 0s 241us/step - loss: 22.7455\n",
      "Epoch 3/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 18.6910\n",
      "Epoch 4/40\n",
      "334/334 [==============================] - 0s 248us/step - loss: 19.1895\n",
      "Epoch 5/40\n",
      "334/334 [==============================] - 0s 249us/step - loss: 6.8920\n",
      "Epoch 6/40\n",
      "334/334 [==============================] - 0s 255us/step - loss: 6.2405\n",
      "Epoch 7/40\n",
      "334/334 [==============================] - 0s 258us/step - loss: 2.2998\n",
      "Epoch 8/40\n",
      "334/334 [==============================] - 0s 268us/step - loss: 2.2598\n",
      "Epoch 9/40\n",
      "334/334 [==============================] - 0s 250us/step - loss: 1.5613\n",
      "Epoch 10/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 1.4952\n",
      "Epoch 11/40\n",
      "334/334 [==============================] - 0s 248us/step - loss: 1.2316\n",
      "Epoch 12/40\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.9573\n",
      "Epoch 13/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.7608\n",
      "Epoch 14/40\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.6708\n",
      "Epoch 15/40\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.6763\n",
      "Epoch 16/40\n",
      "334/334 [==============================] - 0s 243us/step - loss: 0.6945\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 249us/step - loss: 0.7073\n",
      "Epoch 18/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5833\n",
      "Epoch 19/40\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.6029\n",
      "Epoch 20/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5732\n",
      "Epoch 21/40\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5622\n",
      "Epoch 22/40\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5621\n",
      "Epoch 23/40\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5505\n",
      "Epoch 24/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5612\n",
      "Epoch 25/40\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5584\n",
      "Epoch 26/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5851\n",
      "Epoch 27/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5373\n",
      "Epoch 28/40\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5865\n",
      "Epoch 29/40\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5456\n",
      "Epoch 30/40\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5521\n",
      "Epoch 31/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5504\n",
      "Epoch 32/40\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5444\n",
      "Epoch 33/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5477\n",
      "Epoch 34/40\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5569\n",
      "Epoch 35/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5438\n",
      "Epoch 36/40\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5502\n",
      "Epoch 37/40\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5389\n",
      "Epoch 38/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5519\n",
      "Epoch 39/40\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5426\n",
      "Epoch 40/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5457\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.060536092384435136, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "665/665 [==============================] - 99s 149ms/step - loss: 24.1916\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 0s 242us/step - loss: 7.7898\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 0s 241us/step - loss: 8.5681\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 4.5822\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 0s 222us/step - loss: 2.5644\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.9264\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.5717\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.5726\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.5724\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4816\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4881\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4401\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4133\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4063\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4072\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.3979\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4030\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4017\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4021\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4044\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 0s 216us/step - loss: 0.3987\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4015\n",
      "Epoch 23/40\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.3986\n",
      "Epoch 24/40\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3981\n",
      "Epoch 25/40\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4003\n",
      "Epoch 26/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3994\n",
      "Epoch 27/40\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4017\n",
      "Epoch 28/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4019\n",
      "Epoch 29/40\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3998\n",
      "Epoch 30/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3979\n",
      "Epoch 31/40\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3984\n",
      "Epoch 32/40\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.3988\n",
      "Epoch 33/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.3982\n",
      "Epoch 34/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3982\n",
      "Epoch 35/40\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3990\n",
      "Epoch 36/40\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.3998\n",
      "Epoch 37/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4007\n",
      "Epoch 38/40\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3982\n",
      "Epoch 39/40\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3981\n",
      "Epoch 40/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3983\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0016536031806906326, total= 2.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "996/996 [==============================] - 106s 107ms/step - loss: 24.0920\n",
      "Epoch 2/40\n",
      "996/996 [==============================] - 0s 232us/step - loss: 19.4893\n",
      "Epoch 3/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 6.9536\n",
      "Epoch 4/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 2.3294\n",
      "Epoch 5/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.6495\n",
      "Epoch 6/40\n",
      "996/996 [==============================] - 0s 251us/step - loss: 0.3847\n",
      "Epoch 7/40\n",
      "996/996 [==============================] - 0s 227us/step - loss: 0.3818\n",
      "Epoch 8/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3504\n",
      "Epoch 9/40\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3340\n",
      "Epoch 10/40\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3350\n",
      "Epoch 11/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3198\n",
      "Epoch 12/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3195\n",
      "Epoch 13/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3175\n",
      "Epoch 14/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3245\n",
      "Epoch 15/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3204\n",
      "Epoch 16/40\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3232\n",
      "Epoch 17/40\n",
      "996/996 [==============================] - 0s 207us/step - loss: 0.3167\n",
      "Epoch 18/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3201\n",
      "Epoch 19/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3194\n",
      "Epoch 20/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3172\n",
      "Epoch 21/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3225\n",
      "Epoch 22/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3151\n",
      "Epoch 23/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3151\n",
      "Epoch 24/40\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3177\n",
      "Epoch 25/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3188\n",
      "Epoch 26/40\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3196\n",
      "Epoch 27/40\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3159\n",
      "Epoch 28/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3141\n",
      "Epoch 29/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3172\n",
      "Epoch 30/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3173\n",
      "Epoch 31/40\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3167\n",
      "Epoch 32/40\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3163\n",
      "Epoch 33/40\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3160\n",
      "Epoch 34/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3137\n",
      "Epoch 35/40\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3153\n",
      "Epoch 36/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3143\n",
      "Epoch 37/40\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3134\n",
      "Epoch 38/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3135\n",
      "Epoch 39/40\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3150\n",
      "Epoch 40/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3144\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0018974268800551197, total= 3.1min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "334/334 [==============================] - 105s 314ms/step - loss: 1.0355\n",
      "Epoch 2/40\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.6766\n",
      "Epoch 3/40\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.6068\n",
      "Epoch 4/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5949\n",
      "Epoch 5/40\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5627\n",
      "Epoch 6/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5577\n",
      "Epoch 7/40\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5601\n",
      "Epoch 8/40\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5543\n",
      "Epoch 9/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5524\n",
      "Epoch 10/40\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5496\n",
      "Epoch 11/40\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5495\n",
      "Epoch 12/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5454\n",
      "Epoch 13/40\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5479\n",
      "Epoch 14/40\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5441\n",
      "Epoch 15/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5453\n",
      "Epoch 16/40\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5472\n",
      "Epoch 17/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5462\n",
      "Epoch 18/40\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5408\n",
      "Epoch 19/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5458\n",
      "Epoch 20/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5452\n",
      "Epoch 21/40\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5466\n",
      "Epoch 22/40\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5484\n",
      "Epoch 23/40\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5469\n",
      "Epoch 24/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5509\n",
      "Epoch 25/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5456\n",
      "Epoch 26/40\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5442\n",
      "Epoch 27/40\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5416\n",
      "Epoch 28/40\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5436\n",
      "Epoch 29/40\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5407\n",
      "Epoch 30/40\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5436\n",
      "Epoch 31/40\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5437\n",
      "Epoch 32/40\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5414\n",
      "Epoch 33/40\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5439\n",
      "Epoch 34/40\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5483\n",
      "Epoch 35/40\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5463\n",
      "Epoch 36/40\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5428\n",
      "Epoch 37/40\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5447\n",
      "Epoch 38/40\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5452\n",
      "Epoch 39/40\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5453\n",
      "Epoch 40/40\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5453\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.08134573218330843, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "665/665 [==============================] - 101s 151ms/step - loss: 0.6376\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 0s 264us/step - loss: 0.4400\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4327\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4140\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4083\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4057\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4027\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 0s 243us/step - loss: 0.4029\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4030\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4041\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 0s 241us/step - loss: 0.4014\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 0s 281us/step - loss: 0.4039\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 0s 253us/step - loss: 0.4052\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 0s 250us/step - loss: 0.4031\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4029\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4041\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.4092\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4018\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 228us/step - loss: 0.4061\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4020\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4030\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4044\n",
      "Epoch 23/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4014\n",
      "Epoch 24/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4029\n",
      "Epoch 25/40\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4026\n",
      "Epoch 26/40\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4072\n",
      "Epoch 27/40\n",
      "665/665 [==============================] - 0s 255us/step - loss: 0.4031\n",
      "Epoch 28/40\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4041\n",
      "Epoch 29/40\n",
      "665/665 [==============================] - 0s 241us/step - loss: 0.4047\n",
      "Epoch 30/40\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4029\n",
      "Epoch 31/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4076\n",
      "Epoch 32/40\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4015\n",
      "Epoch 33/40\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4038\n",
      "Epoch 34/40\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4023\n",
      "Epoch 35/40\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4009\n",
      "Epoch 36/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4008\n",
      "Epoch 37/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4006\n",
      "Epoch 38/40\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4033\n",
      "Epoch 39/40\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4020\n",
      "Epoch 40/40\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4007\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.015551059793913913, total= 2.9min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/40\n",
      "996/996 [==============================] - 127s 128ms/step - loss: 0.3624\n",
      "Epoch 2/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3286\n",
      "Epoch 3/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3234\n",
      "Epoch 4/40\n",
      "996/996 [==============================] - 0s 258us/step - loss: 0.3196\n",
      "Epoch 5/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3230\n",
      "Epoch 6/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3205\n",
      "Epoch 7/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3187\n",
      "Epoch 8/40\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3180\n",
      "Epoch 9/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3205\n",
      "Epoch 10/40\n",
      "996/996 [==============================] - 0s 237us/step - loss: 0.3167\n",
      "Epoch 11/40\n",
      "996/996 [==============================] - 0s 206us/step - loss: 0.3193\n",
      "Epoch 12/40\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3192\n",
      "Epoch 13/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3198\n",
      "Epoch 14/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3188\n",
      "Epoch 15/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3180\n",
      "Epoch 16/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3196\n",
      "Epoch 17/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3195\n",
      "Epoch 18/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3211\n",
      "Epoch 19/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3195\n",
      "Epoch 20/40\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3185\n",
      "Epoch 21/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3176\n",
      "Epoch 22/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3178\n",
      "Epoch 23/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3156\n",
      "Epoch 24/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3167\n",
      "Epoch 25/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3217\n",
      "Epoch 26/40\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3186\n",
      "Epoch 27/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3190\n",
      "Epoch 28/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3165\n",
      "Epoch 29/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3165\n",
      "Epoch 30/40\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3155\n",
      "Epoch 31/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3178\n",
      "Epoch 32/40\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3199\n",
      "Epoch 33/40\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3205\n",
      "Epoch 34/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3171\n",
      "Epoch 35/40\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3174\n",
      "Epoch 36/40\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3165\n",
      "Epoch 37/40\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3203\n",
      "Epoch 38/40\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3210\n",
      "Epoch 39/40\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3188\n",
      "Epoch 40/40\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3195\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=40, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.011174987256509783, total= 3.8min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "334/334 [==============================] - 107s 321ms/step - loss: 1.1135\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.9367\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 0s 322us/step - loss: 0.6923\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.6475\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5969\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 0s 349us/step - loss: 0.5883\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5731\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5805\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5621\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5664\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5633\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5588\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5523\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5498\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5500\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5575\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5564\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5567\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5558\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5651\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5553\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5517\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5516\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5514\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5611\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5517\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5545\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5485\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5459\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5437\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5471\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5460\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5444\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 0s 246us/step - loss: 0.5455\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5421\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5443\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5411\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5437\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5468\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5441\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5411\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5420\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5412\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5441\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5438\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5434\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5447\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5441\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5403\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5400\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.049456103355970615, total= 3.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "665/665 [==============================] - 109s 164ms/step - loss: 0.7235\n",
      "Epoch 2/50\n",
      "665/665 [==============================] - 0s 246us/step - loss: 0.5276\n",
      "Epoch 3/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4735\n",
      "Epoch 4/50\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4360\n",
      "Epoch 5/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4375\n",
      "Epoch 6/50\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4272\n",
      "Epoch 7/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4124\n",
      "Epoch 8/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4098\n",
      "Epoch 9/50\n",
      "665/665 [==============================] - 0s 295us/step - loss: 0.4021\n",
      "Epoch 10/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4050\n",
      "Epoch 11/50\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4114\n",
      "Epoch 12/50\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4073\n",
      "Epoch 13/50\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4027\n",
      "Epoch 14/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4034\n",
      "Epoch 15/50\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4057\n",
      "Epoch 16/50\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4041\n",
      "Epoch 17/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4011\n",
      "Epoch 18/50\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4058\n",
      "Epoch 19/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4087\n",
      "Epoch 20/50\n",
      "665/665 [==============================] - 0s 245us/step - loss: 0.4007\n",
      "Epoch 21/50\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4021\n",
      "Epoch 22/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4026\n",
      "Epoch 23/50\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4005\n",
      "Epoch 24/50\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.3993\n",
      "Epoch 25/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4001\n",
      "Epoch 26/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4003\n",
      "Epoch 27/50\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4012\n",
      "Epoch 28/50\n",
      "665/665 [==============================] - 0s 218us/step - loss: 0.3995\n",
      "Epoch 29/50\n",
      "665/665 [==============================] - 0s 249us/step - loss: 0.3998\n",
      "Epoch 30/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3992\n",
      "Epoch 31/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3993\n",
      "Epoch 32/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4015\n",
      "Epoch 33/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3993\n",
      "Epoch 34/50\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3993\n",
      "Epoch 35/50\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3991\n",
      "Epoch 36/50\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.3995\n",
      "Epoch 37/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3983\n",
      "Epoch 38/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3983\n",
      "Epoch 39/50\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.3982\n",
      "Epoch 40/50\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.3989\n",
      "Epoch 41/50\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.3992\n",
      "Epoch 42/50\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.3987\n",
      "Epoch 43/50\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.3981\n",
      "Epoch 44/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3984\n",
      "Epoch 45/50\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.3991\n",
      "Epoch 46/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3974\n",
      "Epoch 47/50\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3979\n",
      "Epoch 48/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3987\n",
      "Epoch 49/50\n",
      "665/665 [==============================] - 0s 301us/step - loss: 0.3989\n",
      "Epoch 50/50\n",
      "665/665 [==============================] - 0s 249us/step - loss: 0.3987\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.0054466461685565015, total= 3.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 113s 113ms/step - loss: 0.5704\n",
      "Epoch 2/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.4183\n",
      "Epoch 3/50\n",
      "996/996 [==============================] - 0s 244us/step - loss: 0.3520\n",
      "Epoch 4/50\n",
      "996/996 [==============================] - 0s 228us/step - loss: 0.3443\n",
      "Epoch 5/50\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3288\n",
      "Epoch 6/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3210\n",
      "Epoch 7/50\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3215\n",
      "Epoch 8/50\n",
      "996/996 [==============================] - 0s 238us/step - loss: 0.3219\n",
      "Epoch 9/50\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3244\n",
      "Epoch 10/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3158\n",
      "Epoch 11/50\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3179\n",
      "Epoch 12/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3180\n",
      "Epoch 13/50\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3172\n",
      "Epoch 14/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3179\n",
      "Epoch 15/50\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3177\n",
      "Epoch 16/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3152\n",
      "Epoch 17/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3182\n",
      "Epoch 18/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3148\n",
      "Epoch 19/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3143\n",
      "Epoch 20/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3164\n",
      "Epoch 21/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3159\n",
      "Epoch 22/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3150\n",
      "Epoch 23/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3144\n",
      "Epoch 24/50\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3136\n",
      "Epoch 25/50\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3151\n",
      "Epoch 26/50\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3143\n",
      "Epoch 27/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3140\n",
      "Epoch 28/50\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3138\n",
      "Epoch 29/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3135\n",
      "Epoch 30/50\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3134\n",
      "Epoch 31/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3144\n",
      "Epoch 32/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3136\n",
      "Epoch 33/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3126\n",
      "Epoch 34/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3128\n",
      "Epoch 35/50\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3127\n",
      "Epoch 36/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3125\n",
      "Epoch 37/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3133\n",
      "Epoch 38/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3127\n",
      "Epoch 39/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3129\n",
      "Epoch 40/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3128\n",
      "Epoch 41/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3132\n",
      "Epoch 42/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3128\n",
      "Epoch 43/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3130\n",
      "Epoch 44/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3131\n",
      "Epoch 45/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3129\n",
      "Epoch 46/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3126\n",
      "Epoch 47/50\n",
      "996/996 [==============================] - 0s 232us/step - loss: 0.3130\n",
      "Epoch 48/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3128\n",
      "Epoch 49/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3124\n",
      "Epoch 50/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3128\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0018228303223206677, total= 3.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "334/334 [==============================] - 118s 352ms/step - loss: 65.8367\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 0s 251us/step - loss: 58.6659\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 0s 366us/step - loss: 22.1479\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 0s 260us/step - loss: 12.1477\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 0s 256us/step - loss: 9.4488\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 0s 257us/step - loss: 7.4278\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 0s 248us/step - loss: 2.6366\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 0s 259us/step - loss: 2.3960\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 0s 273us/step - loss: 1.1607\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.8434\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.7121\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.8979\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.9220\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.6944\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5982\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.6016\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5846\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5645\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5673\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5584\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5521\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5488\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5466\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5500\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5481\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5475\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5511\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5437\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5601\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5532\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5496\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5508\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5486\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5470\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5451\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5429\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5450\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5445\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5482\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5527\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5546\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5516\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5474\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5402\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5441\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5408\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5437\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5411\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5412\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5406\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.04379202101038859, total= 3.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "665/665 [==============================] - 108s 163ms/step - loss: 50.1098\n",
      "Epoch 2/50\n",
      "665/665 [==============================] - 0s 229us/step - loss: 22.6864\n",
      "Epoch 3/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 21.9502\n",
      "Epoch 4/50\n",
      "665/665 [==============================] - 0s 282us/step - loss: 18.0144\n",
      "Epoch 5/50\n",
      "665/665 [==============================] - 0s 243us/step - loss: 4.7787\n",
      "Epoch 6/50\n",
      "665/665 [==============================] - 0s 225us/step - loss: 2.0589\n",
      "Epoch 7/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.8908\n",
      "Epoch 8/50\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.6050\n",
      "Epoch 9/50\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.6180\n",
      "Epoch 10/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.5650\n",
      "Epoch 11/50\n",
      "665/665 [==============================] - 0s 235us/step - loss: 0.4681\n",
      "Epoch 12/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.5138\n",
      "Epoch 13/50\n",
      "665/665 [==============================] - 0s 234us/step - loss: 0.4466\n",
      "Epoch 14/50\n",
      "665/665 [==============================] - 0s 235us/step - loss: 0.4459\n",
      "Epoch 15/50\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4102\n",
      "Epoch 16/50\n",
      "665/665 [==============================] - 0s 235us/step - loss: 0.4042\n",
      "Epoch 17/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4038\n",
      "Epoch 18/50\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4014\n",
      "Epoch 19/50\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4018\n",
      "Epoch 20/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4002\n",
      "Epoch 21/50\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4010\n",
      "Epoch 22/50\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4002\n",
      "Epoch 23/50\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4000\n",
      "Epoch 24/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4004\n",
      "Epoch 25/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3996\n",
      "Epoch 26/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4013\n",
      "Epoch 27/50\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4016\n",
      "Epoch 28/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3986\n",
      "Epoch 29/50\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3998\n",
      "Epoch 30/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4005\n",
      "Epoch 31/50\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4001\n",
      "Epoch 32/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3990\n",
      "Epoch 33/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3992\n",
      "Epoch 34/50\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4013\n",
      "Epoch 35/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3977\n",
      "Epoch 36/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4006\n",
      "Epoch 37/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3997\n",
      "Epoch 38/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4000\n",
      "Epoch 39/50\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.3981\n",
      "Epoch 40/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3988\n",
      "Epoch 41/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3988\n",
      "Epoch 42/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4000\n",
      "Epoch 43/50\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.3999\n",
      "Epoch 44/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4001\n",
      "Epoch 45/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3998\n",
      "Epoch 46/50\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.3992\n",
      "Epoch 47/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3993\n",
      "Epoch 48/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3975\n",
      "Epoch 49/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4012\n",
      "Epoch 50/50\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3987\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.004088614347581232, total= 3.0min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "996/996 [==============================] - 108s 109ms/step - loss: 14.8971\n",
      "Epoch 2/50\n",
      "996/996 [==============================] - 0s 222us/step - loss: 3.7141\n",
      "Epoch 3/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 2.0891\n",
      "Epoch 4/50\n",
      "996/996 [==============================] - 0s 238us/step - loss: 1.0379\n",
      "Epoch 5/50\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.4382\n",
      "Epoch 6/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.4063\n",
      "Epoch 7/50\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3545\n",
      "Epoch 8/50\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3384\n",
      "Epoch 9/50\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3489\n",
      "Epoch 10/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3226\n",
      "Epoch 11/50\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3250\n",
      "Epoch 12/50\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3221\n",
      "Epoch 13/50\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3241\n",
      "Epoch 14/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3197\n",
      "Epoch 15/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3158\n",
      "Epoch 16/50\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3201\n",
      "Epoch 17/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3173\n",
      "Epoch 18/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3165\n",
      "Epoch 19/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3202\n",
      "Epoch 20/50\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3176\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 217us/step - loss: 0.3223\n",
      "Epoch 22/50\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3191\n",
      "Epoch 23/50\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3252\n",
      "Epoch 24/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3181\n",
      "Epoch 25/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3169\n",
      "Epoch 26/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3176\n",
      "Epoch 27/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3186\n",
      "Epoch 28/50\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3190\n",
      "Epoch 29/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3161\n",
      "Epoch 30/50\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3178\n",
      "Epoch 31/50\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3171\n",
      "Epoch 32/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3156\n",
      "Epoch 33/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3173\n",
      "Epoch 34/50\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3157\n",
      "Epoch 35/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3177\n",
      "Epoch 36/50\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3143\n",
      "Epoch 37/50\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3163\n",
      "Epoch 38/50\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3142\n",
      "Epoch 39/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3152\n",
      "Epoch 40/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3154\n",
      "Epoch 41/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3170\n",
      "Epoch 42/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3191\n",
      "Epoch 43/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3217\n",
      "Epoch 44/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3178\n",
      "Epoch 45/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3183\n",
      "Epoch 46/50\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3171\n",
      "Epoch 47/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3164\n",
      "Epoch 48/50\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3170\n",
      "Epoch 49/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3212\n",
      "Epoch 50/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3197\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.014396932080539937, total= 3.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "334/334 [==============================] - 121s 362ms/step - loss: 1.1213\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 0s 284us/step - loss: 0.6643\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.6067\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5938\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 0s 377us/step - loss: 0.5845\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5628\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5534\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5514\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5476\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5521\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5513\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5457\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5453\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5431\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5437\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 0s 352us/step - loss: 0.5443\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5445\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5455\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5441\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 0s 269us/step - loss: 0.5426\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5422\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5443\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5405\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5434\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5424\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5442\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5464\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 0s 248us/step - loss: 0.5441\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 0s 285us/step - loss: 0.5414\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 0s 268us/step - loss: 0.5439\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 0s 270us/step - loss: 0.5435\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5428\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 0s 290us/step - loss: 0.5428\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5418\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5446\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5425\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5413\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5419\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5436\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5473\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5462\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5426\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 0s 271us/step - loss: 0.5422\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5444\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5428\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.5453\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5446\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5464\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5439\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5463\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.08207262710329566, total= 3.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "665/665 [==============================] - 118s 177ms/step - loss: 0.4598\n",
      "Epoch 2/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4263\n",
      "Epoch 3/50\n",
      "665/665 [==============================] - 0s 263us/step - loss: 0.4155\n",
      "Epoch 4/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4059\n",
      "Epoch 5/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4055\n",
      "Epoch 6/50\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4041\n",
      "Epoch 7/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4040\n",
      "Epoch 8/50\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4040\n",
      "Epoch 9/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4047\n",
      "Epoch 10/50\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4031\n",
      "Epoch 11/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4042\n",
      "Epoch 12/50\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4079\n",
      "Epoch 13/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4040\n",
      "Epoch 14/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4033\n",
      "Epoch 15/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4047\n",
      "Epoch 16/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4040\n",
      "Epoch 17/50\n",
      "665/665 [==============================] - 0s 264us/step - loss: 0.4033\n",
      "Epoch 18/50\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4032\n",
      "Epoch 19/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4089\n",
      "Epoch 20/50\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4030\n",
      "Epoch 21/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4052\n",
      "Epoch 22/50\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4056\n",
      "Epoch 23/50\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4049\n",
      "Epoch 24/50\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4019\n",
      "Epoch 25/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4028\n",
      "Epoch 26/50\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4024\n",
      "Epoch 27/50\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4046\n",
      "Epoch 28/50\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4031\n",
      "Epoch 29/50\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4032\n",
      "Epoch 30/50\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4051\n",
      "Epoch 31/50\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4043\n",
      "Epoch 32/50\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4032\n",
      "Epoch 33/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4029\n",
      "Epoch 34/50\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4017\n",
      "Epoch 35/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3988\n",
      "Epoch 36/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4025\n",
      "Epoch 37/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4050\n",
      "Epoch 38/50\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4013\n",
      "Epoch 39/50\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4049\n",
      "Epoch 40/50\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4009\n",
      "Epoch 41/50\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4002\n",
      "Epoch 42/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4008\n",
      "Epoch 43/50\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4037\n",
      "Epoch 44/50\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4012\n",
      "Epoch 45/50\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4030\n",
      "Epoch 46/50\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4025\n",
      "Epoch 47/50\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4040\n",
      "Epoch 48/50\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4045\n",
      "Epoch 49/50\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4029\n",
      "Epoch 50/50\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4043\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.005231200187579832, total= 3.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/50\n",
      "996/996 [==============================] - 113s 113ms/step - loss: 0.3761\n",
      "Epoch 2/50\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3342\n",
      "Epoch 3/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3265\n",
      "Epoch 4/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3231\n",
      "Epoch 5/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3177\n",
      "Epoch 6/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3240\n",
      "Epoch 7/50\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3198\n",
      "Epoch 8/50\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3238\n",
      "Epoch 9/50\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3212\n",
      "Epoch 10/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3200\n",
      "Epoch 11/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3216\n",
      "Epoch 12/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3186\n",
      "Epoch 13/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3194\n",
      "Epoch 14/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3160\n",
      "Epoch 15/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3184\n",
      "Epoch 16/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3238\n",
      "Epoch 17/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3232\n",
      "Epoch 18/50\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3249\n",
      "Epoch 19/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3256\n",
      "Epoch 20/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3214\n",
      "Epoch 21/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3201\n",
      "Epoch 22/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3230\n",
      "Epoch 23/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3194\n",
      "Epoch 24/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3180\n",
      "Epoch 25/50\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3185\n",
      "Epoch 26/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3191\n",
      "Epoch 27/50\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3202\n",
      "Epoch 28/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3169\n",
      "Epoch 29/50\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3177\n",
      "Epoch 30/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3202\n",
      "Epoch 31/50\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3201\n",
      "Epoch 32/50\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3174\n",
      "Epoch 33/50\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3166\n",
      "Epoch 34/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3166\n",
      "Epoch 35/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3183\n",
      "Epoch 36/50\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3153\n",
      "Epoch 37/50\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3161\n",
      "Epoch 38/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3156\n",
      "Epoch 39/50\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3179\n",
      "Epoch 40/50\n",
      "996/996 [==============================] - 0s 230us/step - loss: 0.3162\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 215us/step - loss: 0.3195\n",
      "Epoch 42/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3165\n",
      "Epoch 43/50\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3178\n",
      "Epoch 44/50\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3185\n",
      "Epoch 45/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3183\n",
      "Epoch 46/50\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3164\n",
      "Epoch 47/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3148\n",
      "Epoch 48/50\n",
      "996/996 [==============================] - 0s 227us/step - loss: 0.3157\n",
      "Epoch 49/50\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3161\n",
      "Epoch 50/50\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3158\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=50, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-8.142173566993982e-05, total= 3.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 121s 362ms/step - loss: 1.1086\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 314us/step - loss: 0.9606\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 339us/step - loss: 0.6615\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 303us/step - loss: 0.6795\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.6137\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5842\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 282us/step - loss: 0.5880\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5826\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5718\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 273us/step - loss: 0.5748\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5488\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5486\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5481\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5576\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5553\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5578\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.5436\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5551\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5496\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 270us/step - loss: 0.5482\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5499\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5517\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5436\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 280us/step - loss: 0.5468\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5433\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 268us/step - loss: 0.5413\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5411\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5464\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5434\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5415\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5400\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5441\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5468\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5423\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 291us/step - loss: 0.5449\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 504us/step - loss: 0.5470\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 270us/step - loss: 0.5464\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5452\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5439\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5448\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5451\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 270us/step - loss: 0.5428\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5413\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 268us/step - loss: 0.5423\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5414\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.5442\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5440\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.5425\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5422\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5446\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5435\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5428\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5424\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5436\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5431\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5444\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5462\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5411\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.5389\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 250us/step - loss: 0.5428\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5394\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5424\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5425\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5409\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5401\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5409\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.5394\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5399\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5382\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5428\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5429\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5394\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5394\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 270us/step - loss: 0.5410\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5415\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5412\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 268us/step - loss: 0.5401\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5402\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5391\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5395\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5412\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5385\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5401\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5398\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5397\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5398\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5386\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5409\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5405\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5391\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 271us/step - loss: 0.5394\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5390\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 275us/step - loss: 0.5409\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5404\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5385\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5388\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5409\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.5389\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5400\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5416\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.056186258859920235, total= 3.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "665/665 [==============================] - 114s 172ms/step - loss: 0.7779\n",
      "Epoch 2/100\n",
      "665/665 [==============================] - 0s 246us/step - loss: 0.4994\n",
      "Epoch 3/100\n",
      "665/665 [==============================] - 0s 281us/step - loss: 0.4766\n",
      "Epoch 4/100\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4671\n",
      "Epoch 5/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4335\n",
      "Epoch 6/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4246\n",
      "Epoch 7/100\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.4169\n",
      "Epoch 8/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4127\n",
      "Epoch 9/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4144\n",
      "Epoch 10/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4058\n",
      "Epoch 11/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4044\n",
      "Epoch 12/100\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4045\n",
      "Epoch 13/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4093\n",
      "Epoch 14/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4062\n",
      "Epoch 15/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4031\n",
      "Epoch 16/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4081\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4011\n",
      "Epoch 18/100\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.4011\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - 0s 256us/step - loss: 0.4029\n",
      "Epoch 20/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4021\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4013\n",
      "Epoch 22/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4040\n",
      "Epoch 23/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4023\n",
      "Epoch 24/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4005\n",
      "Epoch 25/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4002\n",
      "Epoch 26/100\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.3988\n",
      "Epoch 27/100\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4009\n",
      "Epoch 28/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4003\n",
      "Epoch 29/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3988\n",
      "Epoch 30/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3988\n",
      "Epoch 31/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4004\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3996\n",
      "Epoch 33/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4006\n",
      "Epoch 34/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3986\n",
      "Epoch 35/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4006\n",
      "Epoch 36/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4002\n",
      "Epoch 37/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3993\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3994\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3988\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3989\n",
      "Epoch 41/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3996\n",
      "Epoch 42/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3986\n",
      "Epoch 43/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3982\n",
      "Epoch 44/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3987\n",
      "Epoch 45/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3987\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3992\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3985\n",
      "Epoch 48/100\n",
      "665/665 [==============================] - 0s 237us/step - loss: 0.3986\n",
      "Epoch 49/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3985\n",
      "Epoch 50/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3980\n",
      "Epoch 51/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3977\n",
      "Epoch 52/100\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.3995\n",
      "Epoch 53/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3968\n",
      "Epoch 54/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3999\n",
      "Epoch 55/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3977\n",
      "Epoch 56/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3982\n",
      "Epoch 57/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3995\n",
      "Epoch 58/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3977\n",
      "Epoch 59/100\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.3992\n",
      "Epoch 60/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3974\n",
      "Epoch 61/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3979\n",
      "Epoch 62/100\n",
      "665/665 [==============================] - 0s 239us/step - loss: 0.3977\n",
      "Epoch 63/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3974\n",
      "Epoch 64/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3982\n",
      "Epoch 65/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3978\n",
      "Epoch 66/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3976\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 224us/step - loss: 0.3972\n",
      "Epoch 68/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3970\n",
      "Epoch 69/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3982\n",
      "Epoch 70/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3987\n",
      "Epoch 71/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3964\n",
      "Epoch 72/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3972\n",
      "Epoch 73/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3976\n",
      "Epoch 74/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3967\n",
      "Epoch 75/100\n",
      "665/665 [==============================] - 0s 286us/step - loss: 0.3978\n",
      "Epoch 76/100\n",
      "665/665 [==============================] - 0s 275us/step - loss: 0.3974\n",
      "Epoch 77/100\n",
      "665/665 [==============================] - 0s 301us/step - loss: 0.3988\n",
      "Epoch 78/100\n",
      "665/665 [==============================] - 0s 241us/step - loss: 0.3975\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3975\n",
      "Epoch 80/100\n",
      "665/665 [==============================] - 0s 242us/step - loss: 0.3973\n",
      "Epoch 81/100\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.3967\n",
      "Epoch 82/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3969\n",
      "Epoch 83/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3974\n",
      "Epoch 84/100\n",
      "665/665 [==============================] - 0s 241us/step - loss: 0.3976\n",
      "Epoch 85/100\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.3972\n",
      "Epoch 86/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3973\n",
      "Epoch 87/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3977\n",
      "Epoch 88/100\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.3965\n",
      "Epoch 89/100\n",
      "665/665 [==============================] - 0s 245us/step - loss: 0.3974\n",
      "Epoch 90/100\n",
      "665/665 [==============================] - 0s 273us/step - loss: 0.3969\n",
      "Epoch 91/100\n",
      "665/665 [==============================] - 0s 236us/step - loss: 0.3972\n",
      "Epoch 92/100\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.3979\n",
      "Epoch 93/100\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.3976\n",
      "Epoch 94/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3972\n",
      "Epoch 95/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3968\n",
      "Epoch 96/100\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.3968\n",
      "Epoch 97/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3969\n",
      "Epoch 98/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3979\n",
      "Epoch 99/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3973\n",
      "Epoch 100/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3975\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.0019524179859328195, total= 3.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "996/996 [==============================] - 114s 114ms/step - loss: 0.5326\n",
      "Epoch 2/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3912\n",
      "Epoch 3/100\n",
      "996/996 [==============================] - 0s 287us/step - loss: 0.3522\n",
      "Epoch 4/100\n",
      "996/996 [==============================] - 0s 343us/step - loss: 0.3389\n",
      "Epoch 5/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3312\n",
      "Epoch 6/100\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3274\n",
      "Epoch 7/100\n",
      "996/996 [==============================] - 0s 230us/step - loss: 0.3214\n",
      "Epoch 8/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3231\n",
      "Epoch 9/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3178\n",
      "Epoch 10/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3182\n",
      "Epoch 11/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3147\n",
      "Epoch 12/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3184\n",
      "Epoch 13/100\n",
      "996/996 [==============================] - 0s 251us/step - loss: 0.3150\n",
      "Epoch 14/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3186\n",
      "Epoch 15/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3182\n",
      "Epoch 16/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3184\n",
      "Epoch 17/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3190\n",
      "Epoch 18/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3166\n",
      "Epoch 19/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3181\n",
      "Epoch 20/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3180\n",
      "Epoch 21/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3164\n",
      "Epoch 22/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3139\n",
      "Epoch 23/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3160\n",
      "Epoch 24/100\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3135\n",
      "Epoch 25/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3138\n",
      "Epoch 26/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3162\n",
      "Epoch 27/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3153\n",
      "Epoch 28/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3143\n",
      "Epoch 29/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3137\n",
      "Epoch 30/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3138\n",
      "Epoch 31/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3124\n",
      "Epoch 32/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3131\n",
      "Epoch 33/100\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3136\n",
      "Epoch 34/100\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3142\n",
      "Epoch 35/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3126\n",
      "Epoch 36/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3136\n",
      "Epoch 37/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3128\n",
      "Epoch 38/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3134\n",
      "Epoch 39/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3129\n",
      "Epoch 40/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3126\n",
      "Epoch 41/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3127\n",
      "Epoch 42/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3125\n",
      "Epoch 43/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3133\n",
      "Epoch 44/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3126\n",
      "Epoch 45/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3128\n",
      "Epoch 46/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3123\n",
      "Epoch 47/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3130\n",
      "Epoch 48/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3119\n",
      "Epoch 49/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3124\n",
      "Epoch 50/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3124\n",
      "Epoch 51/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3128\n",
      "Epoch 52/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3128\n",
      "Epoch 53/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3123\n",
      "Epoch 54/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3124\n",
      "Epoch 55/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3127\n",
      "Epoch 56/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3127\n",
      "Epoch 57/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3126\n",
      "Epoch 58/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3125\n",
      "Epoch 59/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3119\n",
      "Epoch 60/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3126\n",
      "Epoch 61/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3124\n",
      "Epoch 62/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3128\n",
      "Epoch 63/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3130\n",
      "Epoch 64/100\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3127\n",
      "Epoch 65/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3153\n",
      "Epoch 66/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3150\n",
      "Epoch 67/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3122\n",
      "Epoch 68/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3150\n",
      "Epoch 69/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3131\n",
      "Epoch 70/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3130\n",
      "Epoch 71/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3129\n",
      "Epoch 72/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3124\n",
      "Epoch 73/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3130\n",
      "Epoch 74/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3124\n",
      "Epoch 75/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3127\n",
      "Epoch 76/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3126\n",
      "Epoch 77/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3124\n",
      "Epoch 78/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3128\n",
      "Epoch 79/100\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3121\n",
      "Epoch 80/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3124\n",
      "Epoch 81/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3139\n",
      "Epoch 82/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3127\n",
      "Epoch 83/100\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3138\n",
      "Epoch 84/100\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3121\n",
      "Epoch 85/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3131\n",
      "Epoch 86/100\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3124\n",
      "Epoch 87/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3132\n",
      "Epoch 88/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3126\n",
      "Epoch 89/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3127\n",
      "Epoch 90/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3121\n",
      "Epoch 91/100\n",
      "996/996 [==============================] - 0s 231us/step - loss: 0.3128\n",
      "Epoch 92/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3131\n",
      "Epoch 93/100\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3125\n",
      "Epoch 94/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3131\n",
      "Epoch 95/100\n",
      "996/996 [==============================] - 0s 210us/step - loss: 0.3133\n",
      "Epoch 96/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3125\n",
      "Epoch 97/100\n",
      "996/996 [==============================] - 0s 223us/step - loss: 0.3124\n",
      "Epoch 98/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3127\n",
      "Epoch 99/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3135\n",
      "Epoch 100/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3161\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.01, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.003580678162351525, total= 3.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 117s 351ms/step - loss: 26.1584\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 35.5997\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 30.8108\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 42.5270\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 367us/step - loss: 12.6840\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 275us/step - loss: 11.3589\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 5.6452\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 277us/step - loss: 3.1574\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 277us/step - loss: 3.8534\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 268us/step - loss: 2.2411\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 1.5633\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 1.6301\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 1.3703\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.9324\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.7703\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.6725\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.6684\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.6106\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5508\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 275us/step - loss: 0.5667\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 285us/step - loss: 0.5664\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5513\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 269us/step - loss: 0.5431\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5482\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5459\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5438\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5438\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5446\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5401\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5426\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5419\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5501\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5413\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5426\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5412\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5427\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5441\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 419us/step - loss: 0.5420\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5432\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5422\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5402\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5419\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 270us/step - loss: 0.5421\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 275us/step - loss: 0.5406\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 281us/step - loss: 0.5423\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5463\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 271us/step - loss: 0.5449\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5440\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 273us/step - loss: 0.5421\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5421\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5405\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5401\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5404\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5426\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5404\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5402\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5396\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5387\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5417\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5418\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5398\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5406\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5442\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5406\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5417\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 273us/step - loss: 0.5432\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5415\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5432\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5416\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5405\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5400\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5398\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5432\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5428\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5455\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5405\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5413\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5413\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5402\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.5397\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5400\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5410\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 291us/step - loss: 0.5420\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 268us/step - loss: 0.5445\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5426\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 308us/step - loss: 0.5403\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 294us/step - loss: 0.5396\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5398\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5397\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5421\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5410\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 278us/step - loss: 0.5373\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5403\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 278us/step - loss: 0.5404\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 286us/step - loss: 0.5389\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5421\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 270us/step - loss: 0.5435\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5420\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5392\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5420\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.08306324059966985, total= 3.3min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "665/665 [==============================] - 114s 171ms/step - loss: 28.5359\n",
      "Epoch 2/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 14.6559\n",
      "Epoch 3/100\n",
      "665/665 [==============================] - 0s 234us/step - loss: 10.1135\n",
      "Epoch 4/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 13.8436\n",
      "Epoch 5/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 8.5693\n",
      "Epoch 6/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 2.902 - 0s 298us/step - loss: 2.5421\n",
      "Epoch 7/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 1.0793\n",
      "Epoch 8/100\n",
      "665/665 [==============================] - 0s 233us/step - loss: 2.3075\n",
      "Epoch 9/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.6057\n",
      "Epoch 10/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.5694\n",
      "Epoch 11/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.5179\n",
      "Epoch 12/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4317\n",
      "Epoch 13/100\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4351\n",
      "Epoch 14/100\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4256\n",
      "Epoch 15/100\n",
      "665/665 [==============================] - 0s 271us/step - loss: 0.4182\n",
      "Epoch 16/100\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4164\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4200\n",
      "Epoch 18/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4238\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4188\n",
      "Epoch 20/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4059\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4052\n",
      "Epoch 22/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4060\n",
      "Epoch 23/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4038\n",
      "Epoch 24/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4042\n",
      "Epoch 25/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4089\n",
      "Epoch 26/100\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4067\n",
      "Epoch 27/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4010\n",
      "Epoch 28/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4087\n",
      "Epoch 29/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4042\n",
      "Epoch 30/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4050\n",
      "Epoch 31/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4025\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4081\n",
      "Epoch 33/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3996\n",
      "Epoch 34/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4021\n",
      "Epoch 35/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3994\n",
      "Epoch 36/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3981\n",
      "Epoch 37/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4009\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3999\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.3988\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4013\n",
      "Epoch 41/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.3997\n",
      "Epoch 42/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4022\n",
      "Epoch 43/100\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4016\n",
      "Epoch 44/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4009\n",
      "Epoch 45/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4002\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3989\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.3993\n",
      "Epoch 48/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3989\n",
      "Epoch 49/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4022\n",
      "Epoch 50/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4000\n",
      "Epoch 51/100\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4024\n",
      "Epoch 52/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3974\n",
      "Epoch 53/100\n",
      "665/665 [==============================] - 0s 235us/step - loss: 0.4021\n",
      "Epoch 54/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4088\n",
      "Epoch 55/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4009\n",
      "Epoch 56/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4015\n",
      "Epoch 57/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4011\n",
      "Epoch 58/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4017\n",
      "Epoch 59/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4010\n",
      "Epoch 60/100\n",
      "665/665 [==============================] - 0s 285us/step - loss: 0.3997\n",
      "Epoch 61/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3998\n",
      "Epoch 62/100\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4002\n",
      "Epoch 63/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4018\n",
      "Epoch 64/100\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4003\n",
      "Epoch 65/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4014\n",
      "Epoch 66/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4023\n",
      "Epoch 67/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4007\n",
      "Epoch 68/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4054\n",
      "Epoch 69/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3995\n",
      "Epoch 70/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3993\n",
      "Epoch 71/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3995\n",
      "Epoch 72/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4019\n",
      "Epoch 73/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4002\n",
      "Epoch 74/100\n",
      "665/665 [==============================] - 0s 219us/step - loss: 0.4001\n",
      "Epoch 75/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4005\n",
      "Epoch 76/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4000\n",
      "Epoch 77/100\n",
      "665/665 [==============================] - 0s 247us/step - loss: 0.4015\n",
      "Epoch 78/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4005\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3999\n",
      "Epoch 80/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3991\n",
      "Epoch 81/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3992\n",
      "Epoch 82/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4005\n",
      "Epoch 83/100\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.3984\n",
      "Epoch 84/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3988\n",
      "Epoch 85/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4004\n",
      "Epoch 86/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4017\n",
      "Epoch 87/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3981\n",
      "Epoch 88/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4034\n",
      "Epoch 89/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4028\n",
      "Epoch 90/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4027\n",
      "Epoch 91/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3990\n",
      "Epoch 92/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3988\n",
      "Epoch 93/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4012\n",
      "Epoch 94/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4027\n",
      "Epoch 95/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4008\n",
      "Epoch 96/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4003\n",
      "Epoch 97/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4073\n",
      "Epoch 98/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4038\n",
      "Epoch 99/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4016\n",
      "Epoch 100/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4060\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.006425097232458876, total= 3.4min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "996/996 [==============================] - 122s 122ms/step - loss: 36.1695\n",
      "Epoch 2/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 7.7939\n",
      "Epoch 3/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 3.6597\n",
      "Epoch 4/100\n",
      "996/996 [==============================] - 0s 236us/step - loss: 1.1479\n",
      "Epoch 5/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.7608\n",
      "Epoch 6/100\n",
      "996/996 [==============================] - 0s 226us/step - loss: 0.4930\n",
      "Epoch 7/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3814\n",
      "Epoch 8/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3503\n",
      "Epoch 9/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3234\n",
      "Epoch 10/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3238\n",
      "Epoch 11/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3224\n",
      "Epoch 12/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3225\n",
      "Epoch 13/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3215\n",
      "Epoch 14/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3200\n",
      "Epoch 15/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3184\n",
      "Epoch 16/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3194\n",
      "Epoch 17/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3196\n",
      "Epoch 18/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3189\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 223us/step - loss: 0.3182\n",
      "Epoch 20/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3182\n",
      "Epoch 21/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3160\n",
      "Epoch 22/100\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3152\n",
      "Epoch 23/100\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3144\n",
      "Epoch 24/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3152\n",
      "Epoch 25/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3155\n",
      "Epoch 26/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3208\n",
      "Epoch 27/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3176\n",
      "Epoch 28/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3215\n",
      "Epoch 29/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3178\n",
      "Epoch 30/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3142\n",
      "Epoch 31/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3168\n",
      "Epoch 32/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3152\n",
      "Epoch 33/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3154\n",
      "Epoch 34/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3143\n",
      "Epoch 35/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3160\n",
      "Epoch 36/100\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3177\n",
      "Epoch 37/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3163\n",
      "Epoch 38/100\n",
      "996/996 [==============================] - 0s 211us/step - loss: 0.3165\n",
      "Epoch 39/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3169\n",
      "Epoch 40/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3138\n",
      "Epoch 41/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3175\n",
      "Epoch 42/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3196\n",
      "Epoch 43/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3209\n",
      "Epoch 44/100\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3177\n",
      "Epoch 45/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3179\n",
      "Epoch 46/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3199\n",
      "Epoch 47/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3221\n",
      "Epoch 48/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3237\n",
      "Epoch 49/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3217\n",
      "Epoch 50/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3178\n",
      "Epoch 51/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3179\n",
      "Epoch 52/100\n",
      "996/996 [==============================] - 0s 236us/step - loss: 0.3153\n",
      "Epoch 53/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3223\n",
      "Epoch 54/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3181\n",
      "Epoch 55/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3232\n",
      "Epoch 56/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3163\n",
      "Epoch 57/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3172\n",
      "Epoch 58/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3193\n",
      "Epoch 59/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3156\n",
      "Epoch 60/100\n",
      "996/996 [==============================] - 0s 209us/step - loss: 0.3145\n",
      "Epoch 61/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3144\n",
      "Epoch 62/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3141\n",
      "Epoch 63/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3131\n",
      "Epoch 64/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3137\n",
      "Epoch 65/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3154\n",
      "Epoch 66/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3139\n",
      "Epoch 67/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3126\n",
      "Epoch 68/100\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3146\n",
      "Epoch 69/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3135\n",
      "Epoch 70/100\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3143\n",
      "Epoch 71/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3133\n",
      "Epoch 72/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3140\n",
      "Epoch 73/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3149\n",
      "Epoch 74/100\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3171 0s - loss: 0.31\n",
      "Epoch 75/100\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3184\n",
      "Epoch 76/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3169\n",
      "Epoch 77/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3149\n",
      "Epoch 78/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3162\n",
      "Epoch 79/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3155\n",
      "Epoch 80/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3159\n",
      "Epoch 81/100\n",
      "996/996 [==============================] - 0s 212us/step - loss: 0.3146\n",
      "Epoch 82/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3138\n",
      "Epoch 83/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3147\n",
      "Epoch 84/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3154\n",
      "Epoch 85/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3135\n",
      "Epoch 86/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3149\n",
      "Epoch 87/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3133\n",
      "Epoch 88/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3138\n",
      "Epoch 89/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3167\n",
      "Epoch 90/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3185\n",
      "Epoch 91/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3150\n",
      "Epoch 92/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3147\n",
      "Epoch 93/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3146\n",
      "Epoch 94/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3216\n",
      "Epoch 95/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3183\n",
      "Epoch 96/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3189\n",
      "Epoch 97/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3150\n",
      "Epoch 98/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3145\n",
      "Epoch 99/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3157\n",
      "Epoch 100/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3168\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.1, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.003578737621773742, total= 3.6min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 115s 345ms/step - loss: 0.9781\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.6315\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 324us/step - loss: 0.5940\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 322us/step - loss: 0.6023\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5848\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5723\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5601\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5554\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 411us/step - loss: 0.5486\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5474\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5517\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5455\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5441\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5432\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5441\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5438\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 285us/step - loss: 0.5472\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5455\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5446\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 268us/step - loss: 0.5435\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5518\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5480\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5450\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5483\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5457\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5405\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 271us/step - loss: 0.5435\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5468\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5443\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5425\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5442\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5479\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5440\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5460\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5476\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5422\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 271us/step - loss: 0.5451\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5428\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5478\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5476\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5468\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5501\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5488\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5457\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 252us/step - loss: 0.5465\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 254us/step - loss: 0.5483\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5446\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5438\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5423\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5458\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5457\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5504\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5467\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5427\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5483\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5473\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 257us/step - loss: 0.5410\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5422\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 249us/step - loss: 0.5422\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5453\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 251us/step - loss: 0.5500\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5510\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5455\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5435\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5437\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5438\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5432\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5464\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5426\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5442\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5499\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5477\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5443\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5440\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 267us/step - loss: 0.5411\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5396\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5437\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 259us/step - loss: 0.5424\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 247us/step - loss: 0.5404\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5448\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5461\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5466\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 266us/step - loss: 0.5425\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 258us/step - loss: 0.5428\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5426\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 265us/step - loss: 0.5430\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5401\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 273us/step - loss: 0.5420\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 260us/step - loss: 0.5442\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 256us/step - loss: 0.5427\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 253us/step - loss: 0.5435\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 298us/step - loss: 0.5419\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 261us/step - loss: 0.5421\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5407\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 255us/step - loss: 0.5408\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 264us/step - loss: 0.5437\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5419\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 263us/step - loss: 0.5420\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 262us/step - loss: 0.5454\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 272us/step - loss: 0.5440\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.08742727594228583, total= 3.2min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "665/665 [==============================] - 119s 179ms/step - loss: 0.4989\n",
      "Epoch 2/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4235\n",
      "Epoch 3/100\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4125\n",
      "Epoch 4/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4078\n",
      "Epoch 5/100\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4027\n",
      "Epoch 6/100\n",
      "665/665 [==============================] - 0s 269us/step - loss: 0.4000\n",
      "Epoch 7/100\n",
      "665/665 [==============================] - 0s 240us/step - loss: 0.4027\n",
      "Epoch 8/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4018\n",
      "Epoch 9/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4009\n",
      "Epoch 10/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4019\n",
      "Epoch 11/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4013\n",
      "Epoch 12/100\n",
      "665/665 [==============================] - 0s 234us/step - loss: 0.4011\n",
      "Epoch 13/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4023\n",
      "Epoch 14/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4037\n",
      "Epoch 15/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4022\n",
      "Epoch 16/100\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.4005\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4028\n",
      "Epoch 18/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4018\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4028\n",
      "Epoch 20/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4019\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4016\n",
      "Epoch 22/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4015\n",
      "Epoch 23/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4008\n",
      "Epoch 24/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4008\n",
      "Epoch 25/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4016\n",
      "Epoch 26/100\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4031\n",
      "Epoch 27/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3991\n",
      "Epoch 28/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4024\n",
      "Epoch 29/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4023\n",
      "Epoch 30/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4020\n",
      "Epoch 31/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4041\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4048\n",
      "Epoch 33/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4032\n",
      "Epoch 34/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4028\n",
      "Epoch 35/100\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4003\n",
      "Epoch 36/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4025\n",
      "Epoch 37/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3996\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3998\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3999\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4028\n",
      "Epoch 41/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3996\n",
      "Epoch 42/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4033\n",
      "Epoch 43/100\n",
      "665/665 [==============================] - 0s 240us/step - loss: 0.4009\n",
      "Epoch 44/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3996\n",
      "Epoch 45/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3990\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4021\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3994\n",
      "Epoch 48/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3995\n",
      "Epoch 49/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4003\n",
      "Epoch 50/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4028\n",
      "Epoch 51/100\n",
      "665/665 [==============================] - 0s 221us/step - loss: 0.4018\n",
      "Epoch 52/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3999\n",
      "Epoch 53/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3990\n",
      "Epoch 54/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3992\n",
      "Epoch 55/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4005\n",
      "Epoch 56/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.4001\n",
      "Epoch 57/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3999\n",
      "Epoch 58/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.4019\n",
      "Epoch 59/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3992\n",
      "Epoch 60/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.4006\n",
      "Epoch 61/100\n",
      "665/665 [==============================] - 0s 236us/step - loss: 0.4018\n",
      "Epoch 62/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4005\n",
      "Epoch 63/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.4014\n",
      "Epoch 64/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3985\n",
      "Epoch 65/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3989\n",
      "Epoch 66/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3997\n",
      "Epoch 67/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3994\n",
      "Epoch 68/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3990\n",
      "Epoch 69/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3987\n",
      "Epoch 70/100\n",
      "665/665 [==============================] - 0s 231us/step - loss: 0.3989\n",
      "Epoch 71/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3986\n",
      "Epoch 72/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.4004\n",
      "Epoch 73/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4021\n",
      "Epoch 74/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3984\n",
      "Epoch 75/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4009\n",
      "Epoch 76/100\n",
      "665/665 [==============================] - 0s 220us/step - loss: 0.4000\n",
      "Epoch 77/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4006\n",
      "Epoch 78/100\n",
      "665/665 [==============================] - 0s 233us/step - loss: 0.4002\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.4010\n",
      "Epoch 80/100\n",
      "665/665 [==============================] - 0s 246us/step - loss: 0.3982\n",
      "Epoch 81/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3993\n",
      "Epoch 82/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4008\n",
      "Epoch 83/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3998\n",
      "Epoch 84/100\n",
      "665/665 [==============================] - 0s 225us/step - loss: 0.3983\n",
      "Epoch 85/100\n",
      "665/665 [==============================] - 0s 227us/step - loss: 0.3996\n",
      "Epoch 86/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3997\n",
      "Epoch 87/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3985\n",
      "Epoch 88/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.4006\n",
      "Epoch 89/100\n",
      "665/665 [==============================] - 0s 229us/step - loss: 0.3989\n",
      "Epoch 90/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3987\n",
      "Epoch 91/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3982\n",
      "Epoch 92/100\n",
      "665/665 [==============================] - 0s 224us/step - loss: 0.3988\n",
      "Epoch 93/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.4000\n",
      "Epoch 94/100\n",
      "665/665 [==============================] - 0s 226us/step - loss: 0.3995\n",
      "Epoch 95/100\n",
      "665/665 [==============================] - 0s 223us/step - loss: 0.4000\n",
      "Epoch 96/100\n",
      "665/665 [==============================] - 0s 230us/step - loss: 0.3979\n",
      "Epoch 97/100\n",
      "665/665 [==============================] - 0s 236us/step - loss: 0.3987\n",
      "Epoch 98/100\n",
      "665/665 [==============================] - 0s 228us/step - loss: 0.3995\n",
      "Epoch 99/100\n",
      "665/665 [==============================] - 0s 232us/step - loss: 0.4000\n",
      "Epoch 100/100\n",
      "665/665 [==============================] - 0s 222us/step - loss: 0.3996\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=-0.0074857368255509815, total= 3.5min\n",
      "[CV] keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64 \n",
      "Epoch 1/100\n",
      "996/996 [==============================] - 114s 115ms/step - loss: 0.4339\n",
      "Epoch 2/100\n",
      "996/996 [==============================] - 0s 240us/step - loss: 0.3439\n",
      "Epoch 3/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3287\n",
      "Epoch 4/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3255\n",
      "Epoch 5/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3242\n",
      "Epoch 6/100\n",
      "996/996 [==============================] - 0s 226us/step - loss: 0.3205\n",
      "Epoch 7/100\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3201\n",
      "Epoch 8/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3204\n",
      "Epoch 9/100\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3225\n",
      "Epoch 10/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3243\n",
      "Epoch 11/100\n",
      "996/996 [==============================] - 0s 226us/step - loss: 0.3206\n",
      "Epoch 12/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3208\n",
      "Epoch 13/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3202\n",
      "Epoch 14/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3189\n",
      "Epoch 15/100\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3216\n",
      "Epoch 16/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3208\n",
      "Epoch 17/100\n",
      "996/996 [==============================] - 0s 225us/step - loss: 0.3172\n",
      "Epoch 18/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3180\n",
      "Epoch 19/100\n",
      "996/996 [==============================] - 0s 225us/step - loss: 0.3188\n",
      "Epoch 20/100\n",
      "996/996 [==============================] - 0s 226us/step - loss: 0.3181\n",
      "Epoch 21/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3229\n",
      "Epoch 22/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3268\n",
      "Epoch 23/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3239\n",
      "Epoch 24/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3194\n",
      "Epoch 25/100\n",
      "996/996 [==============================] - 0s 227us/step - loss: 0.3165\n",
      "Epoch 26/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3176\n",
      "Epoch 27/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3205\n",
      "Epoch 28/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3215\n",
      "Epoch 29/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3177\n",
      "Epoch 30/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3171\n",
      "Epoch 31/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3167\n",
      "Epoch 32/100\n",
      "996/996 [==============================] - 0s 215us/step - loss: 0.3165\n",
      "Epoch 33/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3174\n",
      "Epoch 34/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3162\n",
      "Epoch 35/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3186\n",
      "Epoch 36/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3175\n",
      "Epoch 37/100\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3160\n",
      "Epoch 38/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3157\n",
      "Epoch 39/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3187\n",
      "Epoch 40/100\n",
      "996/996 [==============================] - 0s 213us/step - loss: 0.3204\n",
      "Epoch 41/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3167\n",
      "Epoch 42/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3187\n",
      "Epoch 43/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3168\n",
      "Epoch 44/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3172\n",
      "Epoch 45/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3194\n",
      "Epoch 46/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3195\n",
      "Epoch 47/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3180\n",
      "Epoch 48/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3188\n",
      "Epoch 49/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3166\n",
      "Epoch 50/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3176\n",
      "Epoch 51/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3166\n",
      "Epoch 52/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3152\n",
      "Epoch 53/100\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3175\n",
      "Epoch 54/100\n",
      "996/996 [==============================] - 0s 235us/step - loss: 0.3163\n",
      "Epoch 55/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3188\n",
      "Epoch 56/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3176\n",
      "Epoch 57/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3156\n",
      "Epoch 58/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3151\n",
      "Epoch 59/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3175\n",
      "Epoch 60/100\n",
      "996/996 [==============================] - 0s 214us/step - loss: 0.3170\n",
      "Epoch 61/100\n",
      "996/996 [==============================] - 0s 216us/step - loss: 0.3159\n",
      "Epoch 62/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3156\n",
      "Epoch 63/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3158\n",
      "Epoch 64/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3136\n",
      "Epoch 65/100\n",
      "996/996 [==============================] - 0s 223us/step - loss: 0.3151\n",
      "Epoch 66/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3171\n",
      "Epoch 67/100\n",
      "996/996 [==============================] - 0s 223us/step - loss: 0.3157\n",
      "Epoch 68/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3172\n",
      "Epoch 69/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3149\n",
      "Epoch 70/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3142\n",
      "Epoch 71/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3156\n",
      "Epoch 72/100\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3167\n",
      "Epoch 73/100\n",
      "996/996 [==============================] - 0s 225us/step - loss: 0.3129\n",
      "Epoch 74/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3148\n",
      "Epoch 75/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3161\n",
      "Epoch 76/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3139\n",
      "Epoch 77/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3149\n",
      "Epoch 78/100\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3163\n",
      "Epoch 79/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3180\n",
      "Epoch 80/100\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3154\n",
      "Epoch 81/100\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3175\n",
      "Epoch 82/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3148\n",
      "Epoch 83/100\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3145\n",
      "Epoch 84/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3146\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 0s 230us/step - loss: 0.3139\n",
      "Epoch 86/100\n",
      "996/996 [==============================] - 0s 219us/step - loss: 0.3135\n",
      "Epoch 87/100\n",
      "996/996 [==============================] - 0s 227us/step - loss: 0.3146\n",
      "Epoch 88/100\n",
      "996/996 [==============================] - 0s 224us/step - loss: 0.3141\n",
      "Epoch 89/100\n",
      "996/996 [==============================] - 0s 220us/step - loss: 0.3144\n",
      "Epoch 90/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3153\n",
      "Epoch 91/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3153\n",
      "Epoch 92/100\n",
      "996/996 [==============================] - 0s 218us/step - loss: 0.3148\n",
      "Epoch 93/100\n",
      "996/996 [==============================] - 0s 217us/step - loss: 0.3155\n",
      "Epoch 94/100\n",
      "996/996 [==============================] - 0s 232us/step - loss: 0.3140\n",
      "Epoch 95/100\n",
      "996/996 [==============================] - 0s 225us/step - loss: 0.3138\n",
      "Epoch 96/100\n",
      "996/996 [==============================] - 0s 229us/step - loss: 0.3145\n",
      "Epoch 97/100\n",
      "996/996 [==============================] - 0s 221us/step - loss: 0.3137\n",
      "Epoch 98/100\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3141\n",
      "Epoch 99/100\n",
      "996/996 [==============================] - 0s 222us/step - loss: 0.3139\n",
      "Epoch 100/100\n",
      "996/996 [==============================] - 0s 226us/step - loss: 0.3161\n",
      "[CV]  keras_model=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1a746452e8>, keras_model__activation=linear, keras_model__batch_size=100, keras_model__epochs=100, keras_model__loss=<function logcosh at 0x1a14774f28>, keras_model__lr=0.001, keras_model__size1=64, keras_model__size2=64, keras_model__size3=64, score=0.0006082171244431445, total= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed: 556.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1327/1327 [==============================] - 131s 99ms/step - loss: 0.3293\n",
      "Epoch 2/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.3022\n",
      "Epoch 3/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.3051\n",
      "Epoch 4/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2882\n",
      "Epoch 5/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2913\n",
      "Epoch 6/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2850\n",
      "Epoch 7/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2858\n",
      "Epoch 8/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2834\n",
      "Epoch 9/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2857\n",
      "Epoch 10/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2810\n",
      "Epoch 11/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2810\n",
      "Epoch 12/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2806\n",
      "Epoch 13/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2818\n",
      "Epoch 14/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2778\n",
      "Epoch 15/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2794\n",
      "Epoch 16/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2793\n",
      "Epoch 17/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2803\n",
      "Epoch 18/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2774\n",
      "Epoch 19/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2779\n",
      "Epoch 20/20\n",
      "1327/1327 [==============================] - 3s 2ms/step - loss: 0.2795\n"
     ]
    }
   ],
   "source": [
    "batch_size = [10,50,100]\n",
    "epochs = [10,20,30,40,50,100]\n",
    "lr=[0.01,0.1,0.001]\n",
    "size1=[64]\n",
    "size2=[64]\n",
    "size3=[64]\n",
    "activation=['linear']\n",
    "loss=[losses.logcosh]\n",
    "params=[param_grid,]\n",
    "param_grid = dict(keras_model=[KerasRegressor(build_fn=create_model_deep_learning2)],\n",
    "                 keras_model__batch_size=batch_size,\n",
    "                  keras_model__epochs=epochs,\n",
    "                 keras_model__lr=lr,\n",
    "                  keras_model__size1=size1,\n",
    "                  keras_model__size2=size2,\n",
    "                  keras_model__size3=size3,\n",
    "                  keras_model__activation=activation,\n",
    "                  keras_model__loss=loss\n",
    "                 )\n",
    "\n",
    "\n",
    "grid2 = GridSearchCV(estimator=pipe, \n",
    "                    param_grid=params,\n",
    "                    scoring=scoring_fnc,\n",
    "                    cv=cvts,\n",
    "                    error_score=np.NaN,\n",
    "                    verbose=6,\n",
    "                    n_jobs=1\n",
    "                   )  \n",
    "\n",
    "grid2 = grid2.fit(X_train,y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=[]\n",
    "data_row=['MLP',\n",
    "                grid2.best_score_,\n",
    "                grid2.best_estimator_\n",
    "                ]\n",
    "data_list.append(data_row)\n",
    "score=pd.DataFrame(data_list,columns=columns)\n",
    "score.set_index(['Regressor'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keras_model': <keras.wrappers.scikit_learn.KerasRegressor at 0x1a746452e8>,\n",
       " 'keras_model__activation': 'linear',\n",
       " 'keras_model__batch_size': 10,\n",
       " 'keras_model__epochs': 20,\n",
       " 'keras_model__loss': <function keras.losses.logcosh>,\n",
       " 'keras_model__lr': 0.001,\n",
       " 'keras_model__size1': 64,\n",
       " 'keras_model__size2': 64,\n",
       " 'keras_model__size3': 64}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6889ef50517e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/deep_learning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-6889ef50517e>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/deep_learning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;31m# else tmp is empty, and we're done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;31m# else tmp is empty, and we're done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyfinance/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "def save_model(model,filename):\n",
    "    joblib.dump(model, filename) \n",
    "    \n",
    "save_model(grid, 'models/deep_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
